{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqGcgHlZGgQypaF0FTHIz9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorial/Eran2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kf3zWHF5Pl2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "\n",
        "git clone https://github.com/eth-sri/ERAN.git\n",
        "\n",
        "sudo apt install m4\n",
        "sudo apt install build-essential\n",
        "sudo apt install autoconf\n",
        "sudo apt install libtool\n",
        "sudo apt install texlive-latex-base\n",
        "\n",
        "cd ERAN\n",
        "sudo bash ./install.sh\n",
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall -y pillow\n",
        "%pip install pillow\n",
        "\n",
        "# Currently you have to do this and restart the runtime\n",
        "# This needs to go by removing pillow from the requirements.txt before installing it or installing the packages manually"
      ],
      "metadata": {
        "id": "l5ZRw3BK6XUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "%pip install onnx onnxruntime\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.onnx\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/iris_trainer.py'}\n",
        "import iris_trainer\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/plots.py'}\n",
        "import plots\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/zonotpy/main/src/zonotope.py'}\n",
        "from zonotope import zono\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/zonotpy/main/src/interval_abstraction.py'}\n",
        "import interval_abstraction as ia\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/zonotpy/main/src/nn_functions.py'}\n",
        "import nn_functions as zf"
      ],
      "metadata": {
        "id": "tQpEBnbI5z_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, number_of_neurons):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_dim, number_of_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(number_of_neurons, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "names, feature_names, X, y, X_scaled, X_train, X_test, y_train, y_test = iris_trainer.load_dataset()\n",
        "\n",
        "model = iris_trainer.train_model(\n",
        "    NeuralNetwork(input_dim=X_train.shape[1], output_dim=3, number_of_neurons=10), \n",
        "    epochs=100, \n",
        "    X_train=X_train, \n",
        "    X_test=X_test, \n",
        "    y_train=y_train, \n",
        "    y_test=y_test)\n",
        "\n",
        "plots.show_plots(names, feature_names, X, y, title = 'Ground Truth')\n",
        "plots.show_plots(names, feature_names, X, iris_trainer.predict(X_scaled, model), title = 'Classification from our network')"
      ],
      "metadata": {
        "id": "qEZG7ZZg6I0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0])\n",
        "print(y[0])"
      ],
      "metadata": {
        "id": "I9EbbJN9fnVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_parameters = [param.cpu().detach().numpy() for param in model.parameters()]\n",
        "weights = model_parameters[0::2]\n",
        "print(weights)\n",
        "biases = model_parameters[1::2]\n",
        "print(biases)"
      ],
      "metadata": {
        "id": "pqDhTNOJ8C6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = \"iris_net.onnx\"\n",
        "dummy_input=torch.randn(1, 4)\n",
        "\n",
        "# set model to eval mode\n",
        "model.eval()\n",
        "\n",
        "# create a dummy input in the shape of the input values\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "torch.onnx.export(model,\n",
        "                  dummy_input,\n",
        "                  model_filename,\n",
        "                  export_params=True,\n",
        "                  verbose=False,\n",
        "                  input_names=['data'],\n",
        "                  output_names=['classification'],\n",
        "                  )"
      ],
      "metadata": {
        "id": "fnldKAA2AiSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile input_box.txt\n",
        "[5.1, 5.11]\n",
        "[3.5, 3.51]\n",
        "[1.4, 1.41]\n",
        "[0.2, 0.21]"
      ],
      "metadata": {
        "id": "Sg1JB7r4Az_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile zonotype_example.txt\n",
        "4\n",
        "3\n",
        "5.1 0.03 0.0\n",
        "3.5 0.0 0.03\n",
        "1.4 0.03 0.0 \n",
        "0.2 0.0 0.03"
      ],
      "metadata": {
        "id": "GAcpKOZaA5-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd ERAN/tf_verify/\n",
        "\n",
        "python3 . --netname ../../iris_net.onnx --zonotope ../../zonotype_example.txt --input_box ../../input_box.txt --domain deepzono --debug true "
      ],
      "metadata": {
        "id": "1GnAWwRBBuuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  if x > 0: return x\n",
        "  return 0\n",
        "\n",
        "input_nodes = [5.1, 3.5, 1.4, 0.2]\n",
        "\n",
        "def calculate_point(input_node):\n",
        "  hidden_nodes = []\n",
        "  for i in range(10):\n",
        "    z = 0\n",
        "    for w in range(4):\n",
        "      z = z + (input_nodes[w] * weights[0][i][w])\n",
        "    hidden_nodes.append(z)\n",
        "\n",
        "  for i in range(10):\n",
        "    hidden_nodes[i] = hidden_nodes[i] + biases[0][i]\n",
        "\n",
        "\n",
        "  for i in range(10):\n",
        "    hidden_nodes[i] = relu(hidden_nodes[i])\n",
        "\n",
        "\n",
        "  output_nodes = []\n",
        "  for i in range(3):\n",
        "    z = 0\n",
        "    for w in range(10):\n",
        "      z = z + (hidden_nodes[w] * weights[1][i][w])\n",
        "    output_nodes.append(z)\n",
        "\n",
        "  for i in range(3):\n",
        "    output_nodes[i] = output_nodes[i] + biases[1][i]\n",
        "\n",
        "  return output_nodes"
      ],
      "metadata": {
        "id": "c3HK_PgyBPpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_plot():\n",
        "  fig, ax = plt.subplots(2, 2)\n",
        "\n",
        "  fig.set_size_inches(18, 14)\n",
        "\n",
        "  ax[0][0].set_title(\"Input\")\n",
        "  ax[0][0].set_xlim(4, 8)\n",
        "  ax[0][0].set_ylim(1.5, 4.7)\n",
        "  ax[0][1].set_title(\"Output\")\n",
        "  ax[0][1].set_xlim(4, 8)\n",
        "  ax[0][1].set_ylim(1.5, 4.7)\n",
        "\n",
        "  ax[1][0].set_title(\"Input\")\n",
        "  ax[1][0].set_xlim(0.8, 7.1)\n",
        "  ax[1][0].set_ylim(-1.2, 3.8)\n",
        "  ax[1][1].set_title(\"Output\")\n",
        "  ax[1][1].set_xlim(0.8, 7.1)\n",
        "  ax[1][1].set_ylim(-1.2, 3.8)\n",
        "  return fig, ax\n",
        "\n",
        "fig, ax = create_plot()\n",
        "\n",
        "input = zono(values = np.array([[5.1, 0.1, 0], [3.5, 0, 0.1], [1.4, 0.1, 0], [0.2, 0, 0.1]]))\n",
        "print(input.to_intervals())\n",
        "k1, k2 = input.split()\n",
        "i1, i2 = k1.split()\n",
        "i3, i4 = k2.split()\n",
        "\n",
        "input_nodes = [i1, i2, i3, i4]\n",
        "\n",
        "k1.visualize(shape=True, fig=fig, ax=ax[0][0])\n",
        "k2.visualize(shape=True, fig=fig, ax=ax[1][0])\n",
        "\n",
        "hidden_nodes = []\n",
        "for i in range(10):\n",
        "  z = zono()\n",
        "  for w in range(4):\n",
        "    z = z + (input_nodes[w] * weights[0][i][w])\n",
        "  hidden_nodes.append(z)\n",
        "\n",
        "for i in range(10):\n",
        "  hidden_nodes[i] = hidden_nodes[i] + zono(values = np.array([[biases[0][i]]]))\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  hidden_nodes[i] = zf.relu(hidden_nodes[i])\n",
        "\n",
        "\n",
        "output_nodes = []\n",
        "for i in range(3):\n",
        "  z = zono()\n",
        "  for w in range(10):\n",
        "    z = z + (hidden_nodes[w] * weights[1][i][w])\n",
        "  output_nodes.append(z)\n",
        "\n",
        "for i in range(3):\n",
        "  output_nodes[i] = output_nodes[i] + zono(values = np.array([[biases[1][i]]]))\n",
        "\n",
        "output = output_nodes[0].combine(output_nodes[1]).combine(output_nodes[2])\n",
        "\n",
        "print(output.to_intervals())\n",
        "print(output)\n",
        "\n",
        "print(output.upper_bound(1))\n",
        "print(output.lower_bound(1))\n",
        "\n",
        "print(output.upper_bound(2))\n",
        "print(output.lower_bound(2))\n",
        "\n",
        "print(output.upper_bound(3))\n",
        "print(output.lower_bound(3))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0S1LudCR8FRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9mLa1iYJzyaW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}