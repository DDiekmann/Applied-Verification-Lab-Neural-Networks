{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Verification_by_abstraction_with_eran.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorials/Verification_by_abstraction_with_eran.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial for Neural Network Verification with ERAN\n",
        "\n",
        "---\n",
        "\n",
        "*This tutorial gives an overview of the features of ERAN. \\\\\n",
        "\"ETH Robustness Analyzer for Neural Networks (ERAN) is a state-of-the-art sound, precise, scalable, and extensible analyzer based on abstract interpretation for the complete and incomplete verification\". \\\\\n",
        "First, we will use the example of a neural network trained on the IRIS dataset to show how abstract verification can be performed using zonotopes. For this purpose, a network is first trained on the data, then saved in ONNX format, and then verified with ERAN. \\\\\n",
        "Second, we try to verify the **robustness** of a classification Network trained on the MNIST dataset.*\n",
        "\n",
        "Important Links:\n",
        "- [ERANs Github Repo](https://github.com/eth-sri/eran)\n",
        "- [ERANs documentation](https://files.sri.inf.ethz.ch/eran/docs/eran_manual.pdf)\n",
        "\n",
        "---\n",
        "\n",
        "**This is an interactive tutorial. So feel free to experiment and change stuff. In every spot, we think it would be interesting to change some stuff around we put this little icon.**\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Edit_icon_%28the_Noun_Project_30184%29.svg/1024px-Edit_icon_%28the_Noun_Project_30184%29.svg.png\" alt=\"drawing\" width=\"50\"/>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4sgHPyzZd9Sq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![img](https://raw.githubusercontent.com/eth-sri/eran/master/overview.png)"
      ],
      "metadata": {
        "id": "ORqUKV3lET-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preperation\n",
        "\n",
        "First, we have to prepare our working environment. This takes around 7 minutes.\n",
        "\n",
        "If you want to, you can take the time to look at the theoretical background for abstract verification in this [book](https://arxiv.org/pdf/2109.10317.pdf). It gives an introduction to different forms of verification of neural networks. Chapter 9 explains the basics of zonotope abstraction, which is used in this tutorial."
      ],
      "metadata": {
        "id": "5hdDqmYjIUdG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "First, we need to install some required packages. \\\\\n",
        "(We are using a fork of ERAN here, because of a bug in their code. This will change in the future, should the bug be fixed)"
      ],
      "metadata": {
        "id": "0GX9xgN5EjXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "\n",
        "git clone https://github.com/DDiekmann/eran.git\n",
        "\n",
        "sudo apt install m4\n",
        "sudo apt install build-essential\n",
        "sudo apt install autoconf\n",
        "sudo apt install libtool\n",
        "sudo apt install texlive-latex-base\n",
        "\n",
        "cd eran\n",
        "sudo bash ./install.sh\n",
        "pip install -r requirements.txt\n",
        "pip install onnx onnxruntime"
      ],
      "metadata": {
        "id": "YT7GCZXCeIsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Next, we need to import the required libraries."
      ],
      "metadata": {
        "id": "aUGl-42VIYZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.onnx\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/iris_trainer.py'}\n",
        "import iris_trainer\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/mnist_trainer.py'}\n",
        "import mnist_trainer\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/plots.py'}\n",
        "import plots\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/zonotpy/main/src/zonotope.py'}\n",
        "from zonotope import zono"
      ],
      "metadata": {
        "id": "a7ryCxcGehat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training of a simple neural network\n",
        "\n",
        "In this section, we will first define a neural network and train it on the [IRIS dataset](https://archive.ics.uci.edu/ml/datasets/iris). This will be saved in ONNX format."
      ],
      "metadata": {
        "id": "tC_p5OAYIoOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the Neural Network\n",
        "We define a network with one linear layer and ReLU as an activation function. \n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Edit_icon_%28the_Noun_Project_30184%29.svg/1024px-Edit_icon_%28the_Noun_Project_30184%29.svg.png\" alt=\"drawing\" width=\"50\"/>"
      ],
      "metadata": {
        "id": "be6Gj0sIHE5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, number_of_neurons):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_dim, number_of_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(number_of_neurons, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "qEZG7ZZg6I0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "The model is trained on the iris dataset."
      ],
      "metadata": {
        "id": "hdGIwABcHTK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names, feature_names, X, y, X_scaled, X_train, X_test, y_train, y_test = iris_trainer.load_dataset()\n",
        "\n",
        "model = iris_trainer.train_model(\n",
        "    NeuralNetwork(input_dim=X_train.shape[1], output_dim=3, number_of_neurons=10), \n",
        "    epochs=200, \n",
        "    X_train=X_train, \n",
        "    X_test=X_test, \n",
        "    y_train=y_train, \n",
        "    y_test=y_test)"
      ],
      "metadata": {
        "id": "5VAdEWM9G49w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization\n",
        "The plots below show the ground truth values and the classification made by the network on the data. "
      ],
      "metadata": {
        "id": "JFG2Y6b2HbHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plots.show_plots(names, feature_names, X_scaled, y, title = 'Ground Truth')\n",
        "plots.show_plots(names, feature_names, X_scaled, iris_trainer.predict(X_scaled, model), title = 'Classification from our network')"
      ],
      "metadata": {
        "id": "ZrGC024sG8lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the network\n",
        "The network is then exported to an ONNX file."
      ],
      "metadata": {
        "id": "qX8ZXCSXH8yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = \"iris_net.onnx\"\n",
        "dummy_input=torch.randn(1, 4)\n",
        "\n",
        "# set model to eval mode\n",
        "model.eval()\n",
        "\n",
        "# create a dummy input in the shape of the input values\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "torch.onnx.export(model,\n",
        "                  dummy_input,\n",
        "                  model_filename,\n",
        "                  export_params=True,\n",
        "                  verbose=False,\n",
        "                  input_names=['data'],\n",
        "                  output_names=['classification'],\n",
        "                  )"
      ],
      "metadata": {
        "id": "fnldKAA2AiSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verifications with Zonotope Abstraction\n",
        "\n",
        "In the following steps we define a zonotope for abstract verification of the network with ERAN.\n",
        "The verification will then be performed using ERAN on the network with the defined zonotope."
      ],
      "metadata": {
        "id": "jWvx85c5c-9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the zonotope\n",
        "In order to use ERAN on a custom dataset and network, one needs to define the zonotope used in abstract verification. \\\n",
        "For an explanation on zonotopes you can take a look at this [website](https://mitadmissions.org/blogs/entry/what-is-a-zonotope/). \\\n",
        "As described in the [manual of ERAN](https://files.sri.inf.ethz.ch/eran/docs/eran_manual.pdf), \"the zonotope file\n",
        "has two integers followed by a number of floats. The numbers can be separated by spaces, commas, or newlines. The first integer denotes the input dimension (e.g. 784 for MNIST).\n",
        "The second integer is one plus the number of error terms of the zonotope. The number of floats is the two integers multiplied. Looking at an input of $i = [x0, x1, ... , xk]$, the file has all $\\alpha$ values of the affine forms following each other.\""
      ],
      "metadata": {
        "id": "ZHEXXGZ2IGjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first want a small zonotope surrounding a point in the dataset. The chance, that we can successfully verify the robustness of the network here is probably high. \\\n",
        "Therefore, we take the first value of X and Y:"
      ],
      "metadata": {
        "id": "tgCyWrSBKmd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_scaled[0])\n",
        "print(y[0])"
      ],
      "metadata": {
        "id": "I9EbbJN9fnVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the input values are roughly $[-0.9, 1.02, -1.34, -1.32]$. The classification label for that input is $0$. If we visualize this in the graph of our ground truth data, we can see, that there is some space around it, which should only be classified as 'setosa'. \n",
        "\n",
        "*The point is marked by the red cross.*"
      ],
      "metadata": {
        "id": "qGeEb24MLBC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "fig.set_size_inches(18, 7)\n",
        "\n",
        "plots.show_plots(names, feature_names, X_scaled, y, title = 'Ground Truth', fig=fig, ax1= ax[0], ax2=ax[1])\n",
        "ax[0].plot(X_scaled[0][0], X_scaled[0][1], marker=\"X\", markersize=14, markerfacecolor=\"red\")\n",
        "ax[1].plot(X_scaled[0][2], X_scaled[0][3], marker=\"X\", markersize=14, markerfacecolor=\"red\")"
      ],
      "metadata": {
        "id": "PiKiU2oUeBWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now describe our zonotope. If you are not familiar with zonotope description with generators you can find some information in this [book](https://arxiv.org/pdf/2109.10317.pdf) in chapter 9. \n",
        "\n",
        "**Let's start with a small zonotope. Which is defined as follows:** "
      ],
      "metadata": {
        "id": "L1d65NndKFTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile small_zonotope_example.txt\n",
        "4\n",
        "3\n",
        "-0.90068117 0.03 0.0 \n",
        "1.01900435 0.0 0.03 \n",
        "-1.34022653  0.03 0.0 \n",
        "-1.3154443  0.0 0.03"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAcpKOZaA5-K",
        "outputId": "36862544-b1c2-406b-9e9f-8d7de955acc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting small_zonotope_example.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This zonotope creates a zonotope in 4 dimensions, which is hard to look at for us humans. But we can view it in the already seen graphs. For this, we have to zoom in a lot, because the zonotope is very small."
      ],
      "metadata": {
        "id": "lYQLqKp-gfi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "fig.set_size_inches(18, 7)\n",
        "\n",
        "plots.show_plots(names, feature_names, X_scaled[:5], y[:5], title = 'Ground Truth', fig=fig, ax1= ax[0], ax2=ax[1])\n",
        "\n",
        "z = zono.from_file(\"small_zonotope_example.txt\")\n",
        "z1, z2 = z.split()\n",
        "z1.visualize(shape = True, fig=fig, ax=ax[0], shape_color='yellow')\n",
        "z2.visualize(shape = True, fig=fig, ax=ax[1], shape_color='yellow')"
      ],
      "metadata": {
        "id": "unk299UtgqBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract verification with ERAN\n",
        "Now we can run the verification of ERAN on the model with the use of the defined zonotope. \n",
        "\n",
        "For this following parameters have to be provided:\n",
        "* --netname: the location of the ONNX file \n",
        "* --zonotope: the location of the zonotope file we just created \n",
        "* --domain: which domain should be used (we use the domain 'deepzono', if you want to have a look at other domains, the manual will help you) "
      ],
      "metadata": {
        "id": "cpTXbfcYKJxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd eran/tf_verify/\n",
        "\n",
        "python3 . --netname ../../iris_net.onnx --zonotope ../../small_zonotope_example.txt --domain deepzono"
      ],
      "metadata": {
        "id": "bJ218kHX6mfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The verification returns multiple pieces of information.\n",
        "\n",
        "First, we can see, for our input-zonotope robustness could be verified. In addition, we are given the 'nlb' (lower bound) and 'nub' (upper bound) of our output zonotope.\n",
        "\n",
        "Because the lower bound in our first dimension is higher than the upper bounds in the second and third dimensions, our network will classify all points in our input zonotope as 'setosa'. This is what we expected.\n",
        "\n",
        "But what if we make it bigger? 😲\n"
      ],
      "metadata": {
        "id": "TbkeURhekE1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another zonotope\n",
        "In the next step, we select the same point as before as the center of the zonotope but make the zonotope significantly larger. What can we expect from the verification? \n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Edit_icon_%28the_Noun_Project_30184%29.svg/1024px-Edit_icon_%28the_Noun_Project_30184%29.svg.png\" alt=\"drawing\" width=\"50\"/>"
      ],
      "metadata": {
        "id": "y6b1VAehLh8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile big_zonotope_example.txt\n",
        "4\n",
        "3\n",
        "-0.90068117 2 0 0 0\n",
        "1.01900435 0 2 0 0 \n",
        "-1.34022653 0 0 2 0 \n",
        "-1.3154443 0 0 0 2"
      ],
      "metadata": {
        "id": "NnsV0OUL6Rbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "fig.set_size_inches(18, 7)\n",
        "\n",
        "plots.show_plots(names, feature_names, X_scaled, y, title = 'Ground Truth', fig=fig, ax1= ax[0], ax2=ax[1])\n",
        "\n",
        "z = zono.from_file(\"big_zonotope_example.txt\")\n",
        "z1, z2 = z.split()\n",
        "z1.visualize(shape = True, fig=fig, ax=ax[0], shape_color=\"yellow\")\n",
        "z2.visualize(shape = True, fig=fig, ax=ax[1], shape_color=\"yellow\")"
      ],
      "metadata": {
        "id": "T_czkAOqnKH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd eran/tf_verify/\n",
        "\n",
        "python3 . --netname ../../iris_net.onnx --zonotope ../../big_zonotope_example.txt --domain deepzono --debug true "
      ],
      "metadata": {
        "id": "1GnAWwRBBuuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the robustness of the network could not be verified with a larger zonotope. \n",
        "\n",
        "Maybe you can find some more examples and that way investigate the robustness of this very small network."
      ],
      "metadata": {
        "id": "8F-70HbjMXLc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verification of a bit more complex neural network"
      ],
      "metadata": {
        "id": "XPlDEXUNK3HV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the Neural Network\n",
        "\n",
        "We define a network with one linear layer and ReLU as an activation function. \n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Edit_icon_%28the_Noun_Project_30184%29.svg/1024px-Edit_icon_%28the_Noun_Project_30184%29.svg.png\" alt=\"drawing\" width=\"50\"/>"
      ],
      "metadata": {
        "id": "cOjZCOQwIaUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, number_of_neurons):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, number_of_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(number_of_neurons, number_of_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(number_of_neurons, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "5p4IEz_ClDFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "The model is then trained on the MNIST dataset."
      ],
      "metadata": {
        "id": "kVONMGHjrT0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader = mnist_trainer.load_mnist_dataset(batch_size=64)\n",
        "\n",
        "model = mnist_trainer.train_model(\n",
        "    NeuralNetwork(input_dim=28*28, output_dim=10, number_of_neurons=20), \n",
        "    epochs=3, \n",
        "    train_dataloader=train_dataloader,\n",
        "    test_dataloader=test_dataloader,\n",
        "    )"
      ],
      "metadata": {
        "id": "cp4tgOYXmrkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the network\n",
        "The network is then like before exported as an ONNX file."
      ],
      "metadata": {
        "id": "1jgcNfKMIfWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = \"mnist_net.onnx\"\n",
        "dummy_input=torch.randn(1, 28, 28)\n",
        "\n",
        "# set model to eval mode\n",
        "model.eval()\n",
        "\n",
        "# create a dummy input in the shape of the input values\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "torch.onnx.export(model,\n",
        "                  dummy_input,\n",
        "                  model_filename,\n",
        "                  export_params=True,\n",
        "                  verbose=False,\n",
        "                  input_names=['image'],\n",
        "                  output_names=['classification'],\n",
        "                  )"
      ],
      "metadata": {
        "id": "6r3kJO7lmwSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verification"
      ],
      "metadata": {
        "id": "250PCShAIhG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another option Eran gives us is to simply apply an epsilon (infinity norm) value for the robustness verification. *You can have a look into our Tutorials for SMT-Based Verifications for a deeper look into the usage of an epsilon.*\n",
        "\n",
        "For this following parameters have to be provided:\n",
        "* --netname: the location of the ONNX file \n",
        "* --epsilon: our epsilon \n",
        "* --domain: which domain should be used (we use the domain 'deepzono', if you want to have a look at other domains, the manual will help you)\n",
        "* --dataset: the dataset on which the training data is based (Eran provides three different datasets) \n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Edit_icon_%28the_Noun_Project_30184%29.svg/1024px-Edit_icon_%28the_Noun_Project_30184%29.svg.png\" alt=\"drawing\" width=\"50\"/>"
      ],
      "metadata": {
        "id": "7FE2anjSsQMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "cd eran/tf_verify/\n",
        "\n",
        "python3 . --netname ../../mnist_net.onnx --epsilon 0.03 --domain deepzono --dataset mnist"
      ],
      "metadata": {
        "id": "cNYPaOIsm7nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The verification returns multiple pieces of information.\n",
        "\n",
        "First, we can see, that from 100 tested input images only 97 were correctly predicted by our network, which is to be expected with an accuracy of roughly 93%.\n",
        "\n",
        "Of these 97 only 62 could be verified to be robust in the are defined by our epsilon.\n",
        "\n",
        "---\n",
        "\n",
        "If we are more interested in a specific area of the input space, we could create a zonotope. But with 178 input variables, this can be a hard task.\n",
        "\n",
        "We just use one that is provided. If you want to have a look at it, you cant print the first 50 lines by commenting out the \"%%capture\"."
      ],
      "metadata": {
        "id": "gTfYcnTwtnf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget --no-cache --backups=1 {'https://github.com/eth-sri/eran/files/3653882/zonotope_example.txt'}\n",
        "\n",
        "with open(\"zonotope_example.txt\") as myfile:\n",
        "    head = [next(myfile) for x in range(50)]\n",
        "for l in head:\n",
        "  print(l)"
      ],
      "metadata": {
        "id": "nCLa0iZy3A6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can run the verification of ERAN on the model with the use of the defined zonotope like we have seen before."
      ],
      "metadata": {
        "id": "7D792uDzxGz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd eran/tf_verify/\n",
        "\n",
        "python3 . --netname ../../mnist_net.onnx --zonotope ../../zonotope_example.txt --domain deepzono"
      ],
      "metadata": {
        "id": "Nuc6bcH-vuhY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}