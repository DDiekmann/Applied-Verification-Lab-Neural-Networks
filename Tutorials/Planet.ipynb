{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Planet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorials/Planet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial for Neural Network Verification using Planet\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*As an example we try to verify the adversarial robustness of a classification Network trained on the MNIST dataset. The model is trained using [Caffe](https://caffe.berkeleyvision.org/) and the verification is done with [Planet](https://arxiv.org/abs/1705.01320).*\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LHNCbwmKwJ-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Planet\n",
        "[Github Repository](https://github.com/progirep/planet)"
      ],
      "metadata": {
        "id": "8Ht-gLaou9-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify neural networks with planet, we first clone the planet Repository from github to obtain planet."
      ],
      "metadata": {
        "id": "XU1sMtUdfK9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZedEeKnXjHc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Clone the repo\n",
        "!git clone https://github.com/progirep/planet.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a script to convert the neural network description in to the \"prototxt\" format (produced by Caffe) into a json file, so we download it as well.\n",
        "Similarly we download a second script to generate a database in HDF5 format from comma-separated value files"
      ],
      "metadata": {
        "id": "TYV5zdsHfqvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!cd tools\n",
        "!wget https://gist.github.com/progirep/fd7d2dc120862faa984a70f503611013/raw/260e1e76cebd0ea58bf1a03b64c3f1e0002fc677/csv_to_hdf5_supervised_classification.py \n",
        "\n",
        "!wget https://raw.githubusercontent.com/vadimkantorov/caffemodel2json/3a8fd443bf1596dad5f517aecdef08a81bf73bfe/caffemodel2json.py"
      ],
      "metadata": {
        "id": "H3Qz6yJ2Ymkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we intall the needed packages in order to build PLANET."
      ],
      "metadata": {
        "id": "Q1Y0JRlUf-H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# install packages in order to build PLANET\n",
        "!sudo apt-get install libglpk-dev\n",
        "!sudo apt-get install qt5-qmake\n",
        "!sudo apt-get install valgrind\n",
        "!sudo apt-get install libltdl-dev\n",
        "!sudo apt-get install protobuf-compiler"
      ],
      "metadata": {
        "id": "FiERp9lPZpRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can change into the src directory and trigger the build process with make."
      ],
      "metadata": {
        "id": "jeZiQlLLgIQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# compile the source code\n",
        "%cd planet/src\n",
        "%ls\n",
        "!qmake Tool.pro\n",
        "!make"
      ],
      "metadata": {
        "id": "azIQnanwahJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Caffe - Currently not working in Python\n",
        "\n",
        "Following [this tutorial](https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb). Caution: this takes 5 minutes."
      ],
      "metadata": {
        "id": "684Qyid6YTHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now install Caffe and Yices using apt."
      ],
      "metadata": {
        "id": "WEO5NH2rg_7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caffe currently doesnt work in Python, but you can train your model on cli.\n",
        "\n",
        "%%capture\n",
        "\n",
        "# install Caffe and Yices\n",
        "# change root path of #CAFFE and #YICES\n",
        "!sudo apt install caffe-cuda\n",
        "!sudo add-apt-repository ppa:sri-csl/formal-methods -qq\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install yices2"
      ],
      "metadata": {
        "id": "g8PelEMlajl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/BVLC/caffe.git"
      ],
      "metadata": {
        "id": "PzUPIFFZYkiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also install the needed libraries."
      ],
      "metadata": {
        "id": "rG5SMniginfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "!sudo apt-get install libgflags2.2 \n",
        "!sudo apt-get install libgflags-dev\n",
        "!sudo apt-get install libgoogle-glog-dev\n",
        "!sudo apt-get install libhdf5-100\n",
        "!sudo apt-get install libhdf5-serial-dev\n",
        "!sudo apt-get install libhdf5-dev\n",
        "!sudo apt-get install libhdf5-cpp-100\n",
        "!sudo apt-get install libprotobuf-dev protobuf-compiler"
      ],
      "metadata": {
        "id": "J2juacyoYrKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /usr -iname \"*hdf5.so\"\n",
        "# got: /usr/lib/x86_64-linux-gnu/hdf5/serial\n",
        "!find /usr -iname \"*hdf5_hl.so\""
      ],
      "metadata": {
        "id": "BBaRB7xuZACp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the shared libraries for hdf5, we create symbolic links."
      ],
      "metadata": {
        "id": "YcIV53fRivt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial.so /usr/lib/x86_64-linux-gnu/libhdf5.so\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so /usr/lib/x86_64-linux-gnu/libhdf5_hl.so"
      ],
      "metadata": {
        "id": "MaRpc2_JZEdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the path for our HDF5 libs"
      ],
      "metadata": {
        "id": "xkmnQER9i_0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!find /usr -iname \"*hdf5.h*\" # got:\n",
        "# /usr/include/hdf5/serial/hdf5.h \n",
        "# /usr/include/opencv2/flann/hdf5.h\n",
        "# Let's try the first one.\n",
        "%env CPATH=\"/usr/include/hdf5/serial/\"\n",
        "#fatal error: hdf5.h: No such file or directory"
      ],
      "metadata": {
        "id": "yocwisfyZLaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt-get install libleveldb-dev\n",
        "!sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "!sudo apt-get install libsnappy-dev"
      ],
      "metadata": {
        "id": "oelKebsrZM_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build caffe from source files."
      ],
      "metadata": {
        "id": "3JXTpkNWZV1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $CPATH"
      ],
      "metadata": {
        "id": "oXGdHIdKZYMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now change into the Coffe directory and build the shared Coffe libraries as well as the CPP object files"
      ],
      "metadata": {
        "id": "8aSyGeAwj_BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd caffe\n",
        "\n",
        "!ls\n",
        "!make clean\n",
        "!cp Makefile.config.example Makefile.config"
      ],
      "metadata": {
        "id": "XUc1y_V3ZaiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/-gencode arch=compute_20/#-gencode arch=compute_20/' Makefile.config #old cuda versions won't compile \n",
        "!sed -i 's/\\/usr\\/local\\/include/\\/usr\\/local\\/include \\/usr\\/include\\/hdf5\\/serial\\//'  Makefile.config #one of the 4 things needed to fix hdf5 issues\n",
        "!sed -i 's/# OPENCV_VERSION := 3/OPENCV_VERSION := 3/' Makefile.config #We actually use opencv 4.1.2, but it's similar enough to opencv 3.\n",
        "!sed -i 's/code=compute_61/code=compute_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75/' Makefile.config #support for new GPUs"
      ],
      "metadata": {
        "id": "jadFlxc6ZkDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make all -j 4 # -j would use all availiable cores, but RAM related errors occur"
      ],
      "metadata": {
        "id": "zXC_OPCEZmlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should now see the newly created shared libraries and Caffe object files."
      ],
      "metadata": {
        "id": "f0rl9mBxkQf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -iname \"*caffe*\""
      ],
      "metadata": {
        "id": "mZrkU74_8fgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Caffe model on MNIST"
      ],
      "metadata": {
        "id": "sjhA_H6Qi1Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train our model, we have to download the mnist dataset."
      ],
      "metadata": {
        "id": "KcSo_R9ykZsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloads mnist dataset\n",
        "\n",
        "%cd /content/caffe/\n",
        "\n",
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "!cp -rv MNIST/raw/* data/mnist/"
      ],
      "metadata": {
        "id": "Mim2_gdsnB4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates mnist_test_lmdb and mnist_train_lmdb\n",
        "\n",
        "!/content/caffe/examples/mnist/create_mnist.sh"
      ],
      "metadata": {
        "id": "Wmq4yNR1nFcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we copy the output to the corresponding folder."
      ],
      "metadata": {
        "id": "IA7jI_C-kzMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy lmdbs to planet folder\n",
        "\n",
        "%cp -a /content/caffe/examples/mnist/mnist_test_lmdb /content/planet/casestudies/MNIST/\n",
        "%cp -a /content/caffe/examples/mnist/mnist_train_lmdb /content/planet/casestudies/MNIST/"
      ],
      "metadata": {
        "id": "L4LUHluFAoFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define our neural network"
      ],
      "metadata": {
        "id": "QRMEodfNuJ2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define the net and its structure with the individual layers."
      ],
      "metadata": {
        "id": "f5gTkTOak7Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/lenet_train_test.prototext\n",
        "name: \"LeNet\"\n",
        "layer {\n",
        "  name: \"mnist\"\n",
        "  type: \"Data\"\n",
        "  top: \"data\"\n",
        "  top: \"label\"\n",
        "  include {\n",
        "    phase: TRAIN\n",
        "  }\n",
        "  transform_param {\n",
        "    scale: 0.00390625\n",
        "  }\n",
        "  data_param {\n",
        "    source: \"mnist_train_lmdb\"\n",
        "    batch_size: 64\n",
        "    backend: LMDB\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"mnist\"\n",
        "  type: \"Data\"\n",
        "  top: \"data\"\n",
        "  top: \"label\"\n",
        "  include {\n",
        "    phase: TEST\n",
        "  }\n",
        "  transform_param {\n",
        "    scale: 0.00390625\n",
        "  }\n",
        "  data_param {\n",
        "    source: \"mnist_test_lmdb\"\n",
        "    batch_size: 100\n",
        "    backend: LMDB\n",
        "  }\n",
        "}\n",
        "\n",
        "layer {\n",
        "    name: \"reshapeA\"\n",
        "    type: \"Reshape\"\n",
        "    bottom: \"data\"\n",
        "    top: \"reshapeA\"\n",
        "    reshape_param {\n",
        "      shape {\n",
        "        dim: -1  # copy the dimension from below\n",
        "        dim: 1  # copy the dimension from below\n",
        "        dim: 28  # copy the dimension from below\n",
        "        dim: 28 # infer it from the other dimensions\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "layer {\n",
        "  name: \"conv1\"\n",
        "  type: \"Convolution\"\n",
        "  bottom: \"reshapeA\"\n",
        "  top: \"conv1\"\n",
        "  param {\n",
        "    lr_mult: 1\n",
        "  }\n",
        "  param {\n",
        "    lr_mult: 2\n",
        "  }\n",
        "  convolution_param {\n",
        "    num_output: 3\n",
        "    kernel_size: 4\n",
        "    stride: 2\n",
        "    weight_filler {\n",
        "      type: \"xavier\"\n",
        "    }\n",
        "    bias_filler {\n",
        "      type: \"constant\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"pool1\"\n",
        "  type: \"Pooling\"\n",
        "  bottom: \"conv1\"\n",
        "  top: \"pool1\"\n",
        "  pooling_param {\n",
        "    pool: MAX\n",
        "    kernel_size: 4\n",
        "    stride: 3\n",
        "  }\n",
        "}\n",
        "\n",
        "layer {\n",
        "    name: \"reshapeB\"\n",
        "    type: \"Reshape\"\n",
        "    bottom: \"pool1\"\n",
        "    top: \"reshapeB\"\n",
        "    reshape_param {\n",
        "      shape {\n",
        "        dim: -1  # copy the dimension from below\n",
        "        dim: 48 # infer it from the other dimensions\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "layer {\n",
        "  name: \"ip1\"\n",
        "  type: \"InnerProduct\"\n",
        "  bottom: \"reshapeB\"\n",
        "  top: \"ip1\"\n",
        "  param {\n",
        "    lr_mult: 1\n",
        "  }\n",
        "  param {\n",
        "    lr_mult: 2\n",
        "  }\n",
        "  inner_product_param {\n",
        "    num_output: 8\n",
        "    weight_filler {\n",
        "      type: \"xavier\"\n",
        "    }\n",
        "    bias_filler {\n",
        "      type: \"constant\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"relu1\"\n",
        "  type: \"ReLU\"\n",
        "  bottom: \"ip1\"\n",
        "  top: \"relu1\"\n",
        "}\n",
        "layer {\n",
        "  name: \"ip2\"\n",
        "  type: \"InnerProduct\"\n",
        "  bottom: \"relu1\"\n",
        "  top: \"ip2\"\n",
        "  param {\n",
        "    lr_mult: 1\n",
        "  }\n",
        "  param {\n",
        "    lr_mult: 2\n",
        "  }\n",
        "  inner_product_param {\n",
        "    num_output: 10\n",
        "    weight_filler {\n",
        "      type: \"xavier\"\n",
        "    }\n",
        "    bias_filler {\n",
        "      type: \"constant\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"accuracy\"\n",
        "  type: \"Accuracy\"\n",
        "  bottom: \"ip2\"\n",
        "  bottom: \"label\"\n",
        "  top: \"accuracy\"\n",
        "}\n",
        "layer {\n",
        "  name: \"loss\"\n",
        "  type: \"SoftmaxWithLoss\"\n",
        "  bottom: \"ip2\"\n",
        "  bottom: \"label\"\n",
        "  top: \"loss\"\n",
        "}"
      ],
      "metadata": {
        "id": "P_6ze7ZxuNcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define our training "
      ],
      "metadata": {
        "id": "cFfk8Cr9uf4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/lenet_solver.prototxt\n",
        "# The train/test net protocol buffer definition\n",
        "net: \"lenet_train_test.prototxt\"\n",
        "# test_iter specifies how many forward passes the test should carry out.\n",
        "# In the case of MNIST, we have test batch size 100 and 100 test iterations,\n",
        "# covering the full 10,000 testing images.\n",
        "test_iter: 100\n",
        "# Carry out testing every 500 training iterations.\n",
        "test_interval: 1000\n",
        "# The base learning rate, momentum and the weight decay of the network.\n",
        "base_lr: 0.01\n",
        "momentum: 0.9\n",
        "weight_decay: 0.0005\n",
        "# The learning rate policy\n",
        "lr_policy: \"inv\"\n",
        "gamma: 0.0001\n",
        "power: 0.75\n",
        "# Display every 100 iterations\n",
        "display: 1000\n",
        "# The maximum number of iterations\n",
        "max_iter: 20000\n",
        "# solver mode: CPU or GPU\n",
        "solver_mode: CPU"
      ],
      "metadata": {
        "id": "xvK34bjquj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train our model using Caffe"
      ],
      "metadata": {
        "id": "-qSefwU1vFba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "!/content/caffe/build/tools/caffe train --solver=/content/lenet_solver.prototxt $@"
      ],
      "metadata": {
        "id": "HQno6KNxnHM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training results in a .caffemodel file, which now describes our trained model. To verify it with PLANET, we have to convert it to the right input format:\n",
        "\n",
        "*.caffemodel -> .json -> .rlv*"
      ],
      "metadata": {
        "id": "EiA9fgUwuJMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Caffe model to Planet input file"
      ],
      "metadata": {
        "id": "H46WPknAXiRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/caffe/\n",
        "!make pycaffe\n",
        "!make distribute"
      ],
      "metadata": {
        "id": "Xc0-CX_tcxXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env CAFFE_ROOT=/content/caffe\n",
        "%env PYTHONPATH=/content/caffe/python:$PYTHONPATH"
      ],
      "metadata": {
        "id": "iAu_kL44eDcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we run into a problem; Caffe does not find the previously generated shared object file _caffe.so, which is wrapped in Python code using python 2.7. Therefore even changing the directory leads to a compatibility issue with the Python 2.7 compiled .so file and our Code in Python 3."
      ],
      "metadata": {
        "id": "UxUl65E0llnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore we have to download the corresponding file and run this offline with python 2.7. The corresponding output file can thean be upoaded again and fed into the next steps."
      ],
      "metadata": {
        "id": "nBSjl-5FmslS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "import argparse\n",
        "import tempfile\n",
        "import subprocess\n",
        "from google.protobuf.descriptor import FieldDescriptor as FD\n",
        "\n",
        "# inspired by https://github.com/dpp-name/protobuf-json/blob/master/protobuf_json.py\n",
        "def pb2json(pb, print_arrays):\n",
        "\t_ftype2js = {\n",
        "\t\tFD.TYPE_DOUBLE: float,\n",
        "\t\tFD.TYPE_FLOAT: float,\n",
        "\t\tFD.TYPE_INT64: long,\n",
        "\t\tFD.TYPE_UINT64: long,\n",
        "\t\tFD.TYPE_INT32: int,\n",
        "\t\tFD.TYPE_FIXED64: float,\n",
        "\t\tFD.TYPE_FIXED32: float,\n",
        "\t\tFD.TYPE_BOOL: bool,\n",
        "\t\tFD.TYPE_STRING: unicode,\n",
        "\t\tFD.TYPE_BYTES: lambda x: x.encode('string_escape'),\n",
        "\t\tFD.TYPE_UINT32: int,\n",
        "\t\tFD.TYPE_ENUM: int,\n",
        "\t\tFD.TYPE_SFIXED32: float,\n",
        "\t\tFD.TYPE_SFIXED64: float,\n",
        "\t\tFD.TYPE_SINT32: int,\n",
        "\t\tFD.TYPE_SINT64: long,\n",
        "\t\tFD.TYPE_MESSAGE: lambda x: pb2json(x, print_arrays = print_arrays),\n",
        "\t\t'unknown' : lambda x: 'Unknown field type: %s' % x\n",
        "\t}\n",
        "\tjs = {}\n",
        "\tfor field, value in pb.ListFields():\n",
        "\t\tftype = _ftype2js[field.type] if field.type in _ftype2js else _ftype2js['unknown']\n",
        "\t\tif field.label == FD.LABEL_REPEATED:\n",
        "\t\t\tjs_value = map(ftype, value)\n",
        "\t\t\tif not print_arrays and (field.name == 'data' and len(js_value) > 8):\n",
        "\t\t\t\thead_n = 5\n",
        "\t\t\t\tjs_value = js_value[:head_n] + ['(%d elements more)' % (len(js_value) - head_n)]\n",
        "\t\telse:\n",
        "\t\t\tjs_value = ftype(value)\n",
        "\t\tjs[field.name] = js_value\n",
        "\treturn js\n",
        "\n",
        "from caffe import *\n",
        "\n",
        "caffemodel_file = '/content/planet/casestudies/MNIST/lenet_solver_iter_50000.caffemodel'\n",
        "\n",
        "deserialized = caffe_pb2.NetParameter()\n",
        "deserialized.ParseFromString(open(caffemodel_file, 'rb').read())\n",
        "\n",
        "json.dump(pb2json(deserialized, args.data), sys.stdout, indent = 2)\n"
      ],
      "metadata": {
        "id": "ZwgmxWD4Xk-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caffe to JSON converter in Python3\n",
        "### TODO caffe doesnt work in python currently\n",
        "\n"
      ],
      "metadata": {
        "id": "QW1BFNkwCuA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import argparse\n",
        "import tempfile\n",
        "import subprocess\n",
        "from google.protobuf.descriptor import FieldDescriptor as FD\n",
        "\n",
        "# inspired by https://github.com/dpp-name/protobuf-json/blob/master/protobuf_json.py\n",
        "def pb2json(pb, print_arrays):\n",
        "\t_ftype2js = {\n",
        "        FD.TYPE_DOUBLE: float,\n",
        "\t\tFD.TYPE_FLOAT: float,\n",
        "\t\tFD.TYPE_INT64: int,\n",
        "\t\tFD.TYPE_UINT64: int,\n",
        "\t\tFD.TYPE_INT32: int,\n",
        "\t\tFD.TYPE_FIXED64: float,\n",
        "\t\tFD.TYPE_FIXED32: float,\n",
        "\t\tFD.TYPE_BOOL: bool,\n",
        "\t\tFD.TYPE_STRING: str,\n",
        "\t\tFD.TYPE_BYTES: lambda x: x.encode('string_escape'),\n",
        "\t\tFD.TYPE_UINT32: int,\n",
        "\t\tFD.TYPE_ENUM: int,\n",
        "\t\tFD.TYPE_SFIXED32: float,\n",
        "\t\tFD.TYPE_SFIXED64: float,\n",
        "\t\tFD.TYPE_SINT32: int,\n",
        "\t\tFD.TYPE_SINT64: int,\n",
        "\t\tFD.TYPE_MESSAGE: lambda x: pb2json(x, print_arrays = print_arrays),\n",
        "\t\t'unknown' : lambda x: 'Unknown field type: %s' % x\n",
        "\t}\n",
        "\tjs = {}\n",
        "\tfor field, value in pb.ListFields():\n",
        "\t\tftype = _ftype2js[field.type] if field.type in _ftype2js else _ftype2js['unknown']\n",
        "\t\tif field.label == FD.LABEL_REPEATED:\n",
        "\t\t\tjs_value = list(map(ftype, value))\n",
        "\t\t\tif not print_arrays and (field.name == 'data' and len(js_value) > 8):\n",
        "\t\t\t\thead_n = 5\n",
        "\t\t\t\tjs_value = js_value[:head_n] + ['(%d elements more)' % (len(js_value) - head_n)]\n",
        "\t\telse:\n",
        "\t\t\tjs_value = ftype(value)\n",
        "\t\tjs[field.name] = js_value\n",
        "\treturn js\n",
        "\n",
        "from caffe.proto import caffe_pb2\n",
        "\n",
        "caffe_file = \"lenet_solver_iter_50000.caffemodel\"\n",
        "\n",
        "deserialized = caffe_pb2.NetParameter()\n",
        "deserialized.ParseFromString(open(caffe_file, 'rb').read())\n",
        "\n",
        "# print(deserialized)\n",
        "# json dump to console\n",
        "json.dump(pb2json(deserialized, \"store_true\"), sys.stdout, indent = 2)\n",
        "\n",
        "# json dump to file\n",
        "with open(\"caffemodel_mnist.json\", \"w\") as f:\n",
        "    json.dump(pb2json(deserialized, \"store_true\"), f, indent = 2)"
      ],
      "metadata": {
        "id": "FMEP4fLMCtlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON to RLV converter in Python3"
      ],
      "metadata": {
        "id": "aZ1j-mNVCU2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to covert the output in JSON format into the RLV format which can be red by planet. For this we simply use the script from the original author and rewrite it to work with python 3."
      ],
      "metadata": {
        "id": "772XKg33nBkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap --no-stderr\n",
        "with open('output.rlv', 'w') as f:\n",
        "    f.write(cap.stdout)\n",
        "\n",
        "import os, sys\n",
        "import json\n",
        "# import operator\n",
        "from functools import reduce\n",
        "from pprint import pprint\n",
        "\n",
        "# Read input file\n",
        "if len(sys.argv) < 2:\n",
        "    print(sys.stderr, \"Error: Expected JSON input file name!\")\n",
        "\n",
        "\"\"\"\n",
        "with open(sys.argv[1]) as data_file:    \n",
        "    data = json.load(data_file)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"caffemodel_mnist.json\") as data_file:    \n",
        "    data = json.load(data_file)\n",
        "\n",
        "data = data[\"layer\"]\n",
        "\n",
        "# Neuron lookup table: layer--->Neuron names\n",
        "neurons = {}\n",
        "\n",
        "\n",
        "# Function for recursively processing layers\n",
        "def recurseProcessLayer(dataLineName,dataLineWidth):\n",
        "    '''Returns the neuron names. DataLineWidth may be unknown.'''\n",
        "\n",
        "    # DAG Caching\n",
        "    if dataLineName in neurons:\n",
        "        return neurons[dataLineName]\n",
        "        \n",
        "    # Search for the producer of this layer\n",
        "    for layer in data:\n",
        "        if dataLineName in layer[\"top\"]:\n",
        "\n",
        "            # This is the layer to be processed\n",
        "            # ---> Proceed according to type.\n",
        "            if layer[\"type\"]==\"Split\":\n",
        "                assert len(layer[\"bottom\"])==1\n",
        "                return recurseProcessLayer(layer[\"bottom\"][0],dataLineWidth)\n",
        "            elif layer[\"type\"]==\"InnerProduct\":\n",
        "                \n",
        "                # Get output dimension\n",
        "                outputLineWidth = layer[\"inner_product_param\"][\"num_output\"]\n",
        "                if dataLineWidth!=None:\n",
        "                    assert outputLineWidth==dataLineWidth\n",
        "                \n",
        "                # Now get input dimension and blob data\n",
        "                inputLineWidth = None\n",
        "                biasWeights = None\n",
        "                inputWeights = None\n",
        "                for blob in layer[\"blobs\"]:\n",
        "                    if len(blob[\"shape\"][\"dim\"])==1:\n",
        "                        biasWeights = blob[\"data\"]\n",
        "                    elif len(blob[\"shape\"][\"dim\"])==2:\n",
        "                        inputLineWidth = blob[\"shape\"][\"dim\"][1]\n",
        "                        inputWeights = blob[\"data\"]\n",
        "                        assert blob[\"shape\"][\"dim\"][0]==outputLineWidth\n",
        "                    else:\n",
        "                        assert False\n",
        "                assert inputLineWidth != None\n",
        "                \n",
        "                # Now get input\n",
        "                assert len(layer[\"bottom\"])==1\n",
        "                inputNeurons = recurseProcessLayer(layer[\"bottom\"][0],inputLineWidth)\n",
        "                \n",
        "                # Produce outputs\n",
        "                outputNeurons = []\n",
        "                for i in range(0,outputLineWidth):\n",
        "                    outputNeurons.append(dataLineName+\"X\"+str(i))\n",
        "                    sys.stdout.write(\"Linear \"+dataLineName+\"X\"+str(i)+\" \"+str(biasWeights[i]))\n",
        "                    for j in range(0,len(inputNeurons)):\n",
        "                        sys.stdout.write(\" \"+str(inputWeights[i*inputLineWidth+j])+\" \"+str(inputNeurons[j]))\n",
        "                    sys.stdout.write(\"\\n\")\n",
        "                \n",
        "                neurons[dataLineName] = outputNeurons\n",
        "                return outputNeurons\n",
        "                \n",
        "                \n",
        "            elif layer[\"type\"]==\"ReLU\":\n",
        "            \n",
        "                # RELU: Get Input\n",
        "                assert len(layer[\"bottom\"])==1\n",
        "                inputNeurons = recurseProcessLayer(layer[\"bottom\"][0],dataLineWidth)\n",
        "                \n",
        "                # Produce outputs\n",
        "                outputNeurons = []\n",
        "                for i in range(0,len(inputNeurons)):\n",
        "                    outputNeurons.append(dataLineName+\"X\"+str(i))\n",
        "                    sys.stdout.write(\"ReLU \"+dataLineName+\"X\"+str(i)+\" 0.0 1.0 \"+str(inputNeurons[i])+\"\\n\")\n",
        "                \n",
        "                neurons[dataLineName] = outputNeurons\n",
        "                return outputNeurons\n",
        "                \n",
        "                \n",
        "                \n",
        "            elif layer[\"type\"]==\"Convolution\":\n",
        "                \n",
        "                # Convolution\n",
        "                \n",
        "                # ---> Load weights and biasses\n",
        "                dimWeights = None\n",
        "                weights = None\n",
        "                biasses = None\n",
        "                for blob in layer[\"blobs\"]:\n",
        "                    size = blob[\"shape\"][\"dim\"]\n",
        "                    params = blob[\"data\"]\n",
        "                    if len(size)==1:\n",
        "                        biasses = params\n",
        "                    else:\n",
        "                        dimWeights = size\n",
        "                        weights = params\n",
        "                        \n",
        "                # ---> Other parameters\n",
        "                #--------> Read Stride\n",
        "                if \"stride\" in layer[\"convolution_param\"]:\n",
        "                    stride = layer[\"convolution_param\"][\"stride\"]\n",
        "                    assert len(stride)==1\n",
        "                    stride = stride + stride\n",
        "                else:\n",
        "                    if \"stride_w\" in layer[\"convolution_param\"]:\n",
        "                        if \"stride_h\" in layer[\"convolution_param\"]:\n",
        "                            stride = [layer[\"convolution_param\"][\"stride_w\"],layer[\"convolution_param\"][\"stride_h\"]]\n",
        "                        else:\n",
        "                            stride = [layer[\"convolution_param\"][\"stride_w\"],1]\n",
        "                    else:\n",
        "                        if \"stride_h\" in layer[\"convolution_param\"]:\n",
        "                            stride = [1,layer[\"convolution_param\"][\"stride_h\"]]\n",
        "                        else:\n",
        "                            stride = [1,1]\n",
        "                \n",
        "                #--------> Read Kernel Size\n",
        "                if \"kernel_size\" in layer[\"convolution_param\"]:\n",
        "                    kernel_size = layer[\"convolution_param\"][\"kernel_size\"]\n",
        "                    assert len(kernel_size)==1\n",
        "                    kernel_size = kernel_size + kernel_size\n",
        "                else:\n",
        "                    kernel_size = [layer[\"convolution_param\"][\"kernel_w\"],layer[\"convolution_param\"][\"kernel_h\"]]\n",
        "\n",
        "                #--------> Read PAD\n",
        "                if \"pad\" in layer[\"convolution_param\"]:\n",
        "                    padding = layer[\"convolution_param\"][\"pad\"]\n",
        "                    assert len(padding)==1\n",
        "                    padding = padding + padding\n",
        "                else:\n",
        "                    if \"pad_w\" in layer[\"convolution_param\"]:\n",
        "                        if \"pad_h\" in layer[\"convolution_param\"]:\n",
        "                            padding = [layer[\"convolution_param\"][\"pad_w\"],layer[\"convolution_param\"][\"pad_h\"]]\n",
        "                        else:\n",
        "                            padding = [layer[\"convolution_param\"][\"pad_w\"],0]\n",
        "                    else:\n",
        "                        if \"pad_h\" in layer[\"convolution_param\"]:\n",
        "                            padding = [0,layer[\"convolution_param\"][\"pad_h\"]]\n",
        "                        else:\n",
        "                            padding = [0,0]\n",
        "\n",
        "                num_output = layer[\"convolution_param\"][\"num_output\"]\n",
        "                num_input_channels = dimWeights[1]\n",
        "                \n",
        "                # Rest is unimplemented for the time being.\n",
        "                # assert dimWeights[0]==1 #---> This is for the *outgoing* num_outputs\n",
        "                # assert dimWeights[1]==1 #----> This is for the incoming colors or features\n",
        "                \n",
        "                # Check for some unsupported features\n",
        "                if \"bias_term\" in layer[\"convolution_param\"]:\n",
        "                    print(sys.stderr, \"Error: Only the default 'bias_term' value is supported for convolution layers\")\n",
        "                    sys.exit(1)\n",
        "\n",
        "                if \"group\" in layer[\"convolution_param\"]:\n",
        "                    print(sys.stderr, \"Error: Only the default 'group' value is supported for convolution layers\")\n",
        "                    sys.exit(1)\n",
        "                \n",
        "                # ---> Read input\n",
        "                inputNeurons = recurseProcessLayer(layer[\"bottom\"][0],None)\n",
        "                \n",
        "                # ---> Unflatten weights\n",
        "                def unflatten(neurons,remainingDimensions):\n",
        "                    if len(remainingDimensions)==1:\n",
        "                        return (neurons[0:remainingDimensions[0]],neurons[remainingDimensions[0]:])\n",
        "                    else:\n",
        "                        res = []\n",
        "                        for a in range(0,remainingDimensions[0]):\n",
        "                            (d,neurons) = unflatten(neurons,remainingDimensions[1:])\n",
        "                            res.append(d)\n",
        "                        return (res,neurons)\n",
        "                \n",
        "                (unflattenedWeights,rest) = unflatten(weights,dimWeights)\n",
        "                assert rest==[]\n",
        "                \n",
        "                # Compute convolution\n",
        "                resultingNeurons = []\n",
        "                for i in range(0,num_output):\n",
        "                    ysize = len(inputNeurons[0])\n",
        "                    xsize = len(inputNeurons[0][0])\n",
        "                    thisBlock = []\n",
        "                    for y in range(-1*padding[1],ysize-kernel_size[1]+1+padding[1],stride[1]):\n",
        "                        thisLine = []                    \n",
        "                        for x in range(-1*padding[0],xsize-kernel_size[0]+1+padding[0],stride[0]):\n",
        "                            thisLine.append(dataLineName+\"X\"+str(i)+\"X\"+str(x)+\"X\"+str(y))\n",
        "                            localInputs = []\n",
        "                            for c in range(0,num_input_channels):\n",
        "                                for b in range(0,kernel_size[1]):\n",
        "                                    for a in range(0,kernel_size[0]):\n",
        "                                        if y+b>=0 and y+b<len(inputNeurons[c]):\n",
        "                                            if x+a>=0 and x+a<len(inputNeurons[c][y+b]):\n",
        "                                                localInputs.append(str(unflattenedWeights[i][c][b][a])+\" \"+inputNeurons[c][y+b][x+a]) \n",
        "                            sys.stdout.write(\"Linear \"+thisLine[-1]+\" \"+str(biasses[i])+\" \"+\" \".join(localInputs)+\"\\n\")\n",
        "                        thisBlock.append(thisLine)\n",
        "                    resultingNeurons.append(thisBlock)\n",
        "                    \n",
        "                return resultingNeurons\n",
        "\n",
        "            elif layer[\"type\"]==\"HDF5Data\":\n",
        "            \n",
        "                # Input layer\n",
        "                assert dataLineWidth!=None\n",
        "                \n",
        "                outputNeurons = []\n",
        "                for i in range(0,dataLineWidth):\n",
        "                    outputNeurons.append(\"inX\"+str(i))\n",
        "                    sys.stdout.write(\"Input inX\"+str(i)+\"\\n\")\n",
        "\n",
        "                neurons[dataLineName] = outputNeurons\n",
        "                return outputNeurons\n",
        "                \n",
        "            elif layer[\"type\"]==\"Data\":\n",
        "            \n",
        "                # Input layer\n",
        "                assert dataLineWidth!=None\n",
        "                \n",
        "                # We assume normalization by a factor of 1/256.0 here.\n",
        "                assert layer['transform_param']['scale'] == 0.00390625\n",
        "\n",
        "                outputNeurons = []\n",
        "                for i in range(0,dataLineWidth):\n",
        "                    outputNeurons.append(\"inX\"+str(i))\n",
        "                    sys.stdout.write(\"Input inX\"+str(i)+\"\\n\")\n",
        "\n",
        "                neurons[dataLineName] = outputNeurons\n",
        "                return outputNeurons\n",
        "                \n",
        "            elif layer[\"type\"]==\"Reshape\":\n",
        "            \n",
        "                # Reshape layer\n",
        "                outputDimension = layer['reshape_param']['shape']['dim']\n",
        "                # print layer\n",
        "                assert outputDimension[0]==-1 # The first dimension is always the sample points\n",
        "                \n",
        "                nofInputs = 1\n",
        "                for a in outputDimension[1:]:\n",
        "                    nofInputs *= a\n",
        "                inputNeurons = recurseProcessLayer(layer[\"bottom\"][0],nofInputs)\n",
        "\n",
        "                \n",
        "                # Ok, first flatten input Neurons\n",
        "                def flat(neurons):\n",
        "                    if type(neurons)==str or type(neurons)==str:\n",
        "                        return [neurons]\n",
        "                    else:\n",
        "                        l = []\n",
        "                        for a in neurons:\n",
        "                            l.extend(flat(a))\n",
        "                        return l\n",
        "                \n",
        "                # Ok, first flatten input Neurons\n",
        "                #def flat(neurons):\n",
        "                #    if type(neurons)==str or type(neurons)==unicode or type(neurons)==int:\n",
        "                #        return [neurons]\n",
        "                #    else:\n",
        "                #        l = []\n",
        "                #        for a in neurons:\n",
        "                #            l.append(flat(a))\n",
        "                #        return [a for j in zip(*l) for a in j ]\n",
        "\n",
        "                flattenedNeurons = flat(inputNeurons)\n",
        "                \n",
        "                # Ok, now reshape\n",
        "                def unflatten(neurons,remainingDimensions):\n",
        "                    if len(remainingDimensions)==1:\n",
        "                        return (neurons[0:remainingDimensions[0]],neurons[remainingDimensions[0]:])\n",
        "                    else:\n",
        "                        res = []\n",
        "                        for a in range(0,remainingDimensions[0]):\n",
        "                            (d,neurons) = unflatten(neurons,remainingDimensions[1:])\n",
        "                            res.append(d)\n",
        "                        return (res,neurons)\n",
        "                \n",
        "                # Ok, now reshape\n",
        "                #def unflatten(neurons,selection,dimensions):\n",
        "                #    if len(selection)==len(dimensions):\n",
        "                #        index = 0\n",
        "                #        factor = 1\n",
        "                #        for i in range(0,len(selection)):\n",
        "                #            index += factor*selection[i]\n",
        "                #            factor *= dimensions[i]\n",
        "                #        return neurons[index]\n",
        "                #    else:\n",
        "                #        res = []\n",
        "                #        for a in range(0,dimensions[len(selection)]):\n",
        "                #            res.append(unflatten(neurons,selection+[a],dimensions))\n",
        "                #        return res\n",
        "\n",
        "                \n",
        "                (unflattenedNeurons,rest) = unflatten(flattenedNeurons,outputDimension[1:])\n",
        "                assert rest==[]\n",
        "                # print outputDimension\n",
        "                # print inputNeurons\n",
        "                # print flattenedNeurons\n",
        "                # print \"-----UF:->\",unflattenedNeurons\n",
        "                assert len(flattenedNeurons)==reduce(operator.mul, outputDimension[1:], 1)\n",
        "                              \n",
        "                return unflattenedNeurons\n",
        "\n",
        "            elif layer[\"type\"]==\"Pooling\":\n",
        "            \n",
        "                # Reshape layer\n",
        "                inputNeurons = recurseProcessLayer(layer[\"bottom\"][0],None)\n",
        "                \n",
        "                assert layer[\"pooling_param\"][\"pool\"]==0 # Must be a MAXPOOL (for the time being)\n",
        "                \n",
        "                # ---> Other parameters\n",
        "                #--------> Read Stride\n",
        "                if \"stride\" in layer[\"pooling_param\"]:\n",
        "                    # Why is the \"stride\" here an int, but for the Convolution layer is a list?\n",
        "                    stride = layer[\"pooling_param\"][\"stride\"]\n",
        "                    if isinstance(stride,list):\n",
        "                        assert len(stride)==1\n",
        "                        stride = stride + stride\n",
        "                    else:\n",
        "                        stride = [stride,stride]\n",
        "                else:\n",
        "                    if \"stride_w\" in layer[\"pooling_param\"]:\n",
        "                        if \"stride_h\" in layer[\"pooling_param\"]:\n",
        "                            stride = [layer[\"pooling_param\"][\"stride_w\"],layer[\"pooling_param\"][\"stride_h\"]]\n",
        "                        else:\n",
        "                            stride = [layer[\"pooling_param\"][\"stride_w\"],1]\n",
        "                    else:\n",
        "                        if \"stride_h\" in layer[\"pooling_param\"]:\n",
        "                            stride = [1,layer[\"pooling_param\"][\"stride_h\"]]\n",
        "                        else:\n",
        "                            stride = [1,1]\n",
        "                \n",
        "                #--------> Read Kernel Size\n",
        "                if \"kernel_size\" in layer[\"pooling_param\"]:\n",
        "                    # Why is the \"kernel_size\" here an int, but for the Convolution layer is a list?\n",
        "                    kernel_size = layer[\"pooling_param\"][\"kernel_size\"]\n",
        "                    if isinstance(kernel_size,list):\n",
        "                        assert len(kernel_size)==1\n",
        "                        kernel_size = kernel_size + kernel_size\n",
        "                    else:\n",
        "                        kernel_size = [kernel_size,kernel_size]\n",
        "                else:\n",
        "                    kernel_size = [layer[\"pooling_param\"][\"kernel_w\"],layer[\"pooling_param\"][\"kernel_h\"]]\n",
        "\n",
        "                #--------> Read PAD\n",
        "                if \"pad\" in layer[\"pooling_param\"]:\n",
        "                    padding = layer[\"pooling_param\"][\"pad\"]\n",
        "                    assert len(padding)==1\n",
        "                    padding = padding + padding\n",
        "                else:\n",
        "                    if \"pad_w\" in layer[\"pooling_param\"]:\n",
        "                        if \"pad_h\" in layer[\"pooling_param\"]:\n",
        "                            padding = [layer[\"pooling_param\"][\"pad_w\"],layer[\"pooling_param\"][\"pad_h\"]]\n",
        "                        else:\n",
        "                            padding = [layer[\"pooling_param\"][\"pad_w\"],0]\n",
        "                    else:\n",
        "                        if \"pad_h\" in layer[\"pooling_param\"]:\n",
        "                            padding = [0,layer[\"pooling_param\"][\"pad_h\"]]\n",
        "                        else:\n",
        "                            padding = [0,0]\n",
        "\n",
        "                \n",
        "                # Here, we assume that the \"inputNeurons\" array is three-dimensional:\n",
        "                # - color channel\n",
        "                # - X channel\n",
        "                # - Y channel\n",
        "                resultingNeurons = []\n",
        "                for i,channel in enumerate(inputNeurons):\n",
        "                    ysize = len(channel)\n",
        "                    xsize = len(channel[0])\n",
        "                    thisBlock = []\n",
        "                    for y in range(-1*padding[1],ysize-kernel_size[1]+1+padding[1],stride[1]):\n",
        "                        thisLine = []                    \n",
        "                        for x in range(-1*padding[0],xsize-kernel_size[0]+1+padding[0],stride[0]):\n",
        "                            thisLine.append(dataLineName+\"X\"+str(i)+\"X\"+str(x)+\"X\"+str(y))\n",
        "                            localInputs = []\n",
        "                            for b in range(0,kernel_size[1]):\n",
        "                                for a in range(0,kernel_size[0]):\n",
        "                                    if y+b>=0 and y+b<len(channel):\n",
        "                                        if x+a>=0 and x+a<len(channel[y+b]):\n",
        "                                            localInputs.append(channel[y+b][x+a]) \n",
        "                            sys.stdout.write(\"MaxPool \"+thisLine[-1]+\" \"+\" \".join(localInputs)+\"\\n\")\n",
        "                        thisBlock.append(thisLine)\n",
        "                    resultingNeurons.append(thisBlock)\n",
        "                return resultingNeurons                    \n",
        "                    \n",
        "            else:\n",
        "                raise RuntimeError(\"Unsupported Layer Type: \"+layer[\"type\"])\n",
        "            \n",
        "    raise \"Error: Data Line \"+dataLineName+\" not found.\"\n",
        "\n",
        "\n",
        "# Process the Accuracy layer\n",
        "foundAccurracyLayer = False\n",
        "for layer in data:\n",
        "    if layer['type'] == 'Accuracy':\n",
        "        foundAccurracyLayer = True\n",
        "        outputs = recurseProcessLayer(layer[\"bottom\"][0],None)\n",
        "        for i in range(0,len(outputs)):\n",
        "            sys.stdout.write(\"Linear outX\"+str(i)+\" 0.0 1.0 \"+outputs[i]+\"\\n\")\n",
        "                \n",
        "if not foundAccurracyLayer:\n",
        "    print(sys.stderr, \"Warning: No 'Accuracy' layer found, hence nothing was translated.\")"
      ],
      "metadata": {
        "id": "VhZoZYycCQSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run planet with your RLV file"
      ],
      "metadata": {
        "id": "i1cmxBBICojK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the converted rlv file we now add the input constraints for our verification"
      ],
      "metadata": {
        "id": "nwZGoGahnnR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add contraints on Input Variables for Planet\n",
        "%cd /content/\n",
        "\n",
        "with open(\"output.rlv\", \"ab\") as f:\n",
        "  for i in range(28*28):\n",
        "    linebreak = bytes(\"\\n\", \"utf-8\")\n",
        "    assert_lowerbound = bytes(\"Assert <= 0.0 1.0 inX\" + str(i), \"utf-8\")\n",
        "    assert_upperbound = bytes(\"Assert >= 1.0 1.0 inX\" + str(i), \"utf-8\")\n",
        "\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_lowerbound)\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_upperbound)"
      ],
      "metadata": {
        "id": "5V2ezS_Dwy9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verify Robustness with Planet"
      ],
      "metadata": {
        "id": "prLQbKiridL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-mnist"
      ],
      "metadata": {
        "id": "l-Lee6NzpFFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import MNIST\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data = MNIST(\"/content/caffe/data/mnist/\")\n",
        "\n",
        "imgs, labels = data.load_training()\n",
        "\n",
        "img = np.asarray(imgs[0]).reshape(28, 28)\n",
        "pixels = np.asarray(imgs[0])\n",
        "\n",
        "plt.title(\"Label: {}\".format(labels[0]))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "cB0NIuWMiaz6",
        "outputId": "112fd5c6-0a9e-4d4d-eb61-7c847c34186a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f215cad82d0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download converted files\n",
        "!wget https://cloudstorage.uni-oldenburg.de/s/Fs5BdYLNGtpnxq3/download/output.rlv -O /content/output.rlv\n",
        "!wget https://cloudstorage.uni-oldenburg.de/s/FwYjDb9zjDE4x7W/download/caffemodel_mnist.json -O /content/caffemodel_output.json"
      ],
      "metadata": {
        "id": "X1jmu4Pgw--g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# targetDigit, maxDifferencePerPixel, maxUnsmoothnessInNoise \n",
        "# Obtain a digit image that is close to a given one, that resolves to the given target digit, \n",
        "# where every pixel is at most maxDifferencePerPixel away from the initial image \n",
        "# and the maximal noise difference between two adjacent pixels is maxUnsmoothnessInNoise. \n",
        "# The last two parameters should be >=0 and <=1 (such as, e.g., 0.05 for 5% deviation)\"\n",
        "maxDifferencePerPixel = 0.1\n",
        "targetDigit = 5\n",
        "maxUnsmoothnessInNoise = 0.05\n",
        "\n",
        "def addBounds(i, l_bound, u_bound):\n",
        "  with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "    linebreak = bytes(\"\\n\", \"utf-8\")\n",
        "    assert_lowerbound = bytes(\"Assert <= {} 1.0 inX{}\".format(l_bound, i), \"utf-8\")\n",
        "    assert_upperbound = bytes(\"Assert >= {} 1.0 inX{}\".format(u_bound, i), \"utf-8\")\n",
        "\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_lowerbound)\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_upperbound)\n",
        "\n",
        "# constraints for input neurons  \n",
        "for i in range(28*28):\n",
        "  # exclude outer pixels, because there are no neighbours\n",
        "  x = i % 28\n",
        "  y = int(i / 28)\n",
        "\n",
        "  if x<3 or x>24 or y<3 or y>24:\n",
        "    border = 0.0\n",
        "  else:\n",
        "    border = maxDifferencePerPixel\n",
        "\n",
        "  lower_bound = max(0.0, pixels[i]/256.0 - border)\n",
        "  upper_bound = min(1.0, pixels[i]/256.0 + border) \n",
        "  addBounds(i, lower_bound, upper_bound)\n",
        "\n",
        "# constraints for output neurons\n",
        "for i in range(10):\n",
        "  if i == targetDigit:\n",
        "    continue\n",
        "  with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "    assertion = \"\\nAssert >= -0.000001 1.0 outX{} -1.0 outX{}\".format(i, targetDigit)\n",
        "    f.write(bytes(assertion, \"utf-8\"))\n",
        "\n",
        "# constraints for smoothness\n",
        "for x in range(28):\n",
        "  for y in range(28):\n",
        "    if y < 27:\n",
        "      pixelDiff = (pixels[y*28+x] - pixels[(y+1)*28+x]) / 256.0\n",
        "      ass1 = \"\\nAssert <= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff-maxUnsmoothnessInNoise), (y*28+x), (y+1)*28+x)\n",
        "      ass2 = \"\\nAssert >= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff+maxUnsmoothnessInNoise), (y*28+x), (y+1)*28+x)\n",
        "      with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "        f.write(bytes(ass1, \"utf-8\"))\n",
        "        f.write(bytes(ass2, \"utf-8\"))\n",
        "    if x < 27: \n",
        "      pixelDiff = (pixels[y*28+x] - pixels[y*28+x+1]) / 256.0\n",
        "      ass1 = \"\\nAssert <= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff-maxUnsmoothnessInNoise), (y*28+x), (y*28+x+1))\n",
        "      ass2 = \"\\nAssert >= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff+maxUnsmoothnessInNoise), (y*28+x), (y*28+x+1))\n",
        "      with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "        f.write(bytes(ass1, \"utf-8\"))\n",
        "        f.write(bytes(ass2, \"utf-8\"))\n",
        "\n",
        "print(\"FINISHED ADDING CONSTRAINTS!\")"
      ],
      "metadata": {
        "id": "2fteFaDxrWRR",
        "outputId": "d4aad3f3-b734-4eae-e69a-6d6e3b376d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINISHED ADDING CONSTRAINTS!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes assert conditions and empty lines\n",
        "!sed -i \"/Assert/d\" /content/output.rlv\n",
        "!sed -i \"/^$/d\" /content/output.rlv "
      ],
      "metadata": {
        "id": "nVLvoMLsvtqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run planet and save the output in a text file, so we can parse it for values later"
      ],
      "metadata": {
        "id": "yK_eR4X6C6YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap --no-stderr\n",
        "!/content/planet/src/planet /content/output.rlv\n",
        "\n",
        "with open(\"/content/planet_output.txt\", \"w\") as f:\n",
        "  f.write(cap.stdout)"
      ],
      "metadata": {
        "id": "bDjicShU-4HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sat = False\n",
        "valLineFound = False\n",
        "values = {}\n",
        "\n",
        "# parse the planet output\n",
        "with open(\"/content/planet_output.txt\", \"r\") as f:\n",
        "  for line in f.readlines():\n",
        "    line = line.strip()\n",
        "\n",
        "    if line == \"SAT\":\n",
        "      sat = True\n",
        "    elif line == \"Valuation:\":\n",
        "      valLineFound = True\n",
        "    elif line.startswith(\"- \") and valLineFound:\n",
        "      parts = line.split(\" \")\n",
        "      \n",
        "      assert parts[0] == \"-\"\n",
        "      assert parts[3] == \"/\"\n",
        "\n",
        "      # DEBUG prints\n",
        "      # print(parts[1][:len(parts[1])-1])\n",
        "      # print(parts[2])\n",
        "      # break\n",
        "      # builds a dictionary with the calculated values\n",
        "      # e.g. values[inX0] = 0.0\n",
        "      values[parts[1][:len(parts[1])-1]] = float(parts[2])\n",
        "\n",
        "# create adverserial example\n",
        "if sat:\n",
        "  outImg = Image.new(\"L\", (28, 28))\n",
        "  for y in range(28):\n",
        "    for x in range(28):\n",
        "      outImg.putpixel((x, y), int(256*values[\"inX{}\".format(y*28 + x)]))\n",
        "\n",
        "  #plt.title(\"Label: {}\".format(labels[0]))\n",
        "  plt.imshow(outImg)"
      ],
      "metadata": {
        "id": "jkHsIUtnAFA6",
        "outputId": "3987fb71-b565-43b0-9fe1-dc7027b8740c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQfElEQVR4nO3dfYwd5XXH8d/xeo2NebMxXgxsbEMNxCkKgY0hASVUpIkhbQHRWlgVoSXKUhoqUkVtEa0IVRUJIV4URQHV2AYnIkSogWIpxMVxaSlKsLxQB8xLYtfYMcbYgBF+f9nd0z92jBbYeWZ9587O9Z7vR1rt3Tl37hzd3d/OvfeZmcfcXQBGvzF1NwBgZBB2IAjCDgRB2IEgCDsQxNiR3Ng4O8rHa+JIbhIIZZ9264Dvt6FqpcJuZnMlfU9Sm6SF7n5H6v7jNVEX2KVlNgkgYaWvyK01/DLezNok/UDSZZJmS5pvZrMbfTwA1Srznn2OpHXuvt7dD0j6iaQrmtMWgGYrE/ZTJW0a9PMb2bIPMbNuM+sxs56D2l9icwDKqPzTeHdf4O5d7t7VrqOq3hyAHGXCvllS56CfT8uWAWhBZcK+StIsM5tpZuMkXSNpaXPaAtBsDQ+9uXuvmd0k6T80MPS22N1fblpnAJqq1Di7uz8p6ckm9QKgQhwuCwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAECN6KekqjT19RrLeu35DZevXue2i9evcdtH6VW+7jKJtH4nYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEKNmnF19fXV30JLGjB9fav06jwE4kpV93qrAnh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHghg14+y9GzeVW7/EuGfd48Vltt/XcXy5jXd8Oln+3cUTc2u9E05Jrntg1t5k/feu/d9kveNXx+XWbj75F8l11x7oSNa/u2h+sn7Knb9M1utQKuxmtkHSTkl9knrdvasZTQFovmbs2f/A3d9pwuMAqBDv2YEgyobdJT1lZs+bWfdQdzCzbjPrMbOeg9pfcnMAGlX2ZfzF7r7ZzKZKWm5mr7n7M4Pv4O4LJC2QpONsspfcHoAGldqzu/vm7Ps2SY9LmtOMpgA0X8NhN7OJZnbsoduSvixpTbMaA9BcZV7Gd0h63MwOPc6P3X1ZU7pqQCtf/7xv05vJ+q5PTU3Wt3xjWrI+c07+MQa/3Xhyct37v/CjZL1KJ7XtTNbPau9P1m9Z9cVk/Y8mrcytPb9vRnLdhesvStbH7kqWW/J89obD7u7rJaWPqADQMhh6A4Ig7EAQhB0IgrADQRB2IIjRc4prwVBG26RJpdZPefdz6eGtv37y2WR96thfJ+tzj278MONl049qeN1mSPc+Lrnu5//2r5L1MX3pAzL/86zzc2szHns7ue6Ube8m633vrk3We5PVerBnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgRs04e9WnuKYc//Bzyfp//83ZyfqfTVnV8LYl6b/2Vvc/e3d/epz+1X3py0HPPfq1hrc9adVbyXrR7zT/ItYDl0Muo8zfi8SUzQAqRNiBIAg7EARhB4Ig7EAQhB0IgrADQYyacXbtSU/vW6TMOHzbCelpj1+/bVayfuPVn0zW7UD6f/J9lz2UrKeMt4PJ+vfnXtbwY0vSV6Z8Nre2bn5qJFw6W+lx9jKqvtRz3dN4D4U9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EMXrG2Y+eUGr1Mucn2+T0NeknrHsnWT/zhg0Nb1uSbnzga7m117/6QHLdsxbdmKzPWP+rhnr6wPr80tnvzEiuWuU021Vrxd4K9+xmttjMtpnZmkHLJpvZcjNbm31P/7UDqN1wXsY/JGnuR5bdImmFu8+StCL7GUALKwy7uz8jaftHFl8haUl2e4mkK5vcF4Ama/Q9e4e7b8luvyWpI++OZtYtqVuSxuvoBjcHoKzSn8a7u0vKnWHP3Re4e5e7d7Wr3kkGgcgaDftWM5smSdn3bc1rCUAVGg37UknXZbevk/REc9oBUBUbeBWeuIPZI5IukTRF0lZJ35H075IelfQJSRslzXP3j36I9zHH2WS/wC4t2fKRp+w1xou8cU/+MQbLzkuPsz+x66xk/fHZJzXU03C04lj0kW6lr9AO325D1Qo/oHP3+TmleKkFjmAcLgsEQdiBIAg7EARhB4Ig7EAQo+YU17EzPpGs9274XXr9EsNAdU4XLUmn3D7kSIsk6bZ//Upy3atP7EnW/fNfStbb33o/Wa9y+KzOobsjcdiQPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFF4imszRT3Ftawy4/C7Zk9N1uff+bNk/bW905L1pc+dn6xPfiF/f3LiopKXqcbHpE5xZc8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0GMmnH2UX0+e39/uj6m8f/Ze2ZNSdaffnBhsr5sT+Oz/Nz4zLXJ+pnXp8+1b+Xz2YtU1Rvj7AAIOxAFYQeCIOxAEIQdCIKwA0EQdiCIUTPOjsYUjRe/99mTk/X35+1M1u/+9L8dbksfuOnx65P1M/7+ufQDlPjbbtVx9CKlxtnNbLGZbTOzNYOW3W5mm81sdfZ1eTMbBtB8w3kZ/5CkuUMsv9fdz82+nmxuWwCarTDs7v6MpO0j0AuACpX5gO4mM3sxe5k/Ke9OZtZtZj1m1nNQ+0tsDkAZjYb9fklnSDpX0hZJd+fd0d0XuHuXu3e1q/GTJgCU01DY3X2ru/e5e7+kByTNaW5bAJqtobCb2eDrC18laU3efQG0hsJxdjN7RNIlkqZI2irpO9nP50pySRsk3eDuW4o21tLns0/vTNb7t76dX9u3L7lukbrndy+jd8qxyfrrVx6TW7t33oPJdduU/tt8bX/6mvY//9QJ+Y89KfdjJkmSTTo+WS/Su2FT+g79faUeP09qnH1s0cruPn+IxYtKdwVgRHG4LBAEYQeCIOxAEIQdCIKwA0EUfhp/pCgaWitcf2PBUEmFyp4OWeYy12WNfSd9iuushfn1fX86LrnuxDHpw6s729OnbNj5F+XX3tudXLe0iobWymDPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBjJpx9qJTXH1v+jRUm3h0M9s5LKnTZyVpTMdJlW27aIx/5zUXJuvvz0zvL/58/orc2tXH7EiuWzQd9LL3zknWx+zYm6yn+O49ybqNSx8jMGbixGS9f3fF4/xDYM8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0GMmnH2suezt3VMTdbLjMOXvRR0mfPd91x1QbLu96X/3//POfcl68v3Tjjsng4pGkff5+3J+vQJ7ybrb/Y1fnxC39ZtDa/bqtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQo2acvexYddG4aurxqx5H77vkvGR9+yfzx6uX3XpXct0X9k9O1suMoxfp05AzC3/gnxZ9LVmf/uibDW+77O+sb3N6hvK2U9PTSZedK6ARhXt2M+s0s6fN7BUze9nMbs6WTzaz5Wa2NvuenvAaQK2G8zK+V9K33X22pAslfdPMZku6RdIKd58laUX2M4AWVRh2d9/i7i9kt3dKelXSqZKukLQku9sSSVdW1SSA8g7rPbuZzZD0GUkrJXW4+6E3Lm9J6shZp1tStySNV33XeQOiG/an8WZ2jKSfSvqWu3/oSoHu7pJ8qPXcfYG7d7l7V7vSJz4AqM6wwm5m7RoI+sPu/li2eKuZTcvq0ySNvtOEgFGk8GW8mZmkRZJedfd7BpWWSrpO0h3Z9ycq6XCYqh7KKPP4BzrTAxVtJx6brP/z4oXJ+s7+/OGxqW3pSxqX9S/rvpqsj7s3f2hvwvr0lMvT+xofWpPK/c6K1m074fjKtl2V4bxnv0jStZJeMrPV2bJbNRDyR83s65I2SppXTYsAmqEw7O7+rJR79MOlzW0HQFU4XBYIgrADQRB2IAjCDgRB2IEgwpziWjgFb8Glog925I+rTrkrfRnrOzu/n6yfNvaYZL34f/L+3ErR5Zpv+82fJOu7n01fjnnGjzcl670be3JrVvA7Kyv1N+E7dibX9T3p6Z79YG/D25Za9BRXAKMDYQeCIOxAEIQdCIKwA0EQdiAIwg4EMWrG2YvGLbf/5eeS9Xe/eCBZv+WCn+fWuo9Pn3e9en966uHTSv4WfrZnfG7t7x68Prlu53d/mayfdPrB9Mbb2pLlMpfgLtKKY9mH9K/fXdu287BnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgRs04e9GY694/3pGsr7/w4WQ9dV540TnjC7d8KVl/5akzk/X+c9LnXk+f91JubebpBddeLzlWXfS8V7WuVK63wnU7T0tv+43N6fVnTk+vz/nsAKpC2IEgCDsQBGEHgiDsQBCEHQiCsANBmLun72DWKemHkjokuaQF7v49M7td0jckvZ3d9VZ3fzL1WMfZZL/AmPgVqMpKX6Edvn3IWZeHc1BNr6Rvu/sLZnaspOfNbHlWu9fd72pWowCqM5z52bdI2pLd3mlmr0o6terGADTXYb1nN7MZkj4jaWW26CYze9HMFpvZpJx1us2sx8x6DiamKQJQrWGH3cyOkfRTSd9y9x2S7pd0hqRzNbDnv3uo9dx9gbt3uXtXu9LHkAOozrDCbmbtGgj6w+7+mCS5+1Z373P3fkkPSJpTXZsAyioMu5mZpEWSXnX3ewYtnzbobldJWtP89gA0y3A+jb9I0rWSXjKz1dmyWyXNN7NzNTAct0HSDZV0CKAphvNp/LOShhq3S46pA2gtHEEHBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IovBS0k3dmNnbkjYOWjRF0jsj1sDhadXeWrUvid4a1czeprv7SUMVRjTsH9u4WY+7d9XWQEKr9taqfUn01qiR6o2X8UAQhB0Iou6wL6h5+ymt2lur9iXRW6NGpLda37MDGDl179kBjBDCDgRRS9jNbK6Z/cbM1pnZLXX0kMfMNpjZS2a22sx6au5lsZltM7M1g5ZNNrPlZrY2+z7kHHs19Xa7mW3OnrvVZnZ5Tb11mtnTZvaKmb1sZjdny2t97hJ9jcjzNuLv2c2sTdJvJf2hpDckrZI0391fGdFGcpjZBkld7l77ARhm9gVJuyT90N1/P1t2p6Tt7n5H9o9ykrv/Q4v0drukXXVP453NVjRt8DTjkq6U9Beq8blL9DVPI/C81bFnnyNpnbuvd/cDkn4i6Yoa+mh57v6MpO0fWXyFpCXZ7SUa+GMZcTm9tQR33+LuL2S3d0o6NM14rc9doq8RUUfYT5W0adDPb6i15nt3SU+Z2fNm1l13M0PocPct2e23JHXU2cwQCqfxHkkfmWa8ZZ67RqY/L4sP6D7uYnc/T9Jlkr6ZvVxtST7wHqyVxk6HNY33SBlimvEP1PncNTr9eVl1hH2zpM5BP5+WLWsJ7r45+75N0uNqvamotx6aQTf7vq3mfj7QStN4DzXNuFrguatz+vM6wr5K0iwzm2lm4yRdI2lpDX18jJlNzD44kZlNlPRltd5U1EslXZfdvk7SEzX28iGtMo133jTjqvm5q336c3cf8S9Jl2vgE/n/k/SPdfSQ09fpkn6dfb1cd2+SHtHAy7qDGvhs4+uSTpS0QtJaSb+QNLmFevuRpJckvaiBYE2rqbeLNfAS/UVJq7Ovy+t+7hJ9jcjzxuGyQBB8QAcEQdiBIAg7EARhB4Ig7EAQhB0IgrADQfw//hp9BMP0uR8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Current TODO:\n",
        "The Output Variables are not constrained, we probably need to do that next!"
      ],
      "metadata": {
        "id": "erMO_H9_yauq"
      }
    }
  ]
}