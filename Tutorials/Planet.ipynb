{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Planet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorials/Planet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial for Neural Network Verification using Planet\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*As an example we try to verify the adversarial robustness of a classification Network trained on the MNIST dataset. The model is trained using [Caffe](https://caffe.berkeleyvision.org/) and the verification is done with [Planet](https://arxiv.org/abs/1705.01320).*\n",
        "\n",
        "---\n",
        "\n",
        "Planet is a powerful tool for the verification neural networks. However, the toolchain is quite outdated and not suitable for Google Colab. Neither Caffe nor Python 2.7 works in Colab. We managed to convert the scripts to Python 3, but the Caffe problem still remains. \n",
        "\n",
        "To elevate Planet from research software to becoming really useable, a converter from a standard format such as [ONNX](https://github.com/onnx/onnx) to Planet's .rlv input file is needed. This way, one could build networks with different frameworks and convert them to ONNX and then to Planet for verification\n"
      ],
      "metadata": {
        "id": "LHNCbwmKwJ-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Planet\n",
        "[Github Repository](https://github.com/progirep/planet)"
      ],
      "metadata": {
        "id": "8Ht-gLaou9-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify neural networks with planet, we first clone the planet Repository from github to obtain planet."
      ],
      "metadata": {
        "id": "XU1sMtUdfK9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZedEeKnXjHc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Clone the repo\n",
        "!git clone https://github.com/progirep/planet.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we intall the needed packages in order to build PLANET."
      ],
      "metadata": {
        "id": "Q1Y0JRlUf-H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# install packages in order to build PLANET\n",
        "!sudo apt-get install libglpk-dev\n",
        "!sudo apt-get install qt5-qmake\n",
        "!sudo apt-get install valgrind\n",
        "!sudo apt-get install libltdl-dev\n",
        "!sudo apt-get install protobuf-compiler"
      ],
      "metadata": {
        "id": "FiERp9lPZpRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can change into the src directory and trigger the build process with make."
      ],
      "metadata": {
        "id": "jeZiQlLLgIQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# compile the source code\n",
        "%cd planet/src\n",
        "%ls\n",
        "!qmake Tool.pro\n",
        "!make"
      ],
      "metadata": {
        "id": "azIQnanwahJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Caffe - Currently not working in Python\n",
        "\n",
        "Following [this tutorial](https://colab.research.google.com/github/Huxwell/caffe-colab/blob/main/caffe_details.ipynb). Caution: this takes 5 minutes."
      ],
      "metadata": {
        "id": "684Qyid6YTHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now install Caffe and Yices using apt."
      ],
      "metadata": {
        "id": "WEO5NH2rg_7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caffe currently doesnt work in Python, but you can train your model on cli.\n",
        "\n",
        "%%capture\n",
        "\n",
        "# install Caffe and Yices\n",
        "# change root path of #CAFFE and #YICES\n",
        "!sudo apt install caffe-cuda\n",
        "!sudo add-apt-repository ppa:sri-csl/formal-methods -qq\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install yices2"
      ],
      "metadata": {
        "id": "g8PelEMlajl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/BVLC/caffe.git"
      ],
      "metadata": {
        "id": "PzUPIFFZYkiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also install the needed libraries."
      ],
      "metadata": {
        "id": "rG5SMniginfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "!sudo apt-get install libgflags2.2 \n",
        "!sudo apt-get install libgflags-dev\n",
        "!sudo apt-get install libgoogle-glog-dev\n",
        "!sudo apt-get install libhdf5-100\n",
        "!sudo apt-get install libhdf5-serial-dev\n",
        "!sudo apt-get install libhdf5-dev\n",
        "!sudo apt-get install libhdf5-cpp-100\n",
        "!sudo apt-get install libprotobuf-dev protobuf-compiler"
      ],
      "metadata": {
        "id": "J2juacyoYrKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /usr -iname \"*hdf5.so\"\n",
        "# got: /usr/lib/x86_64-linux-gnu/hdf5/serial\n",
        "!find /usr -iname \"*hdf5_hl.so\""
      ],
      "metadata": {
        "id": "BBaRB7xuZACp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the shared libraries for hdf5, we create symbolic links."
      ],
      "metadata": {
        "id": "YcIV53fRivt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial.so /usr/lib/x86_64-linux-gnu/libhdf5.so\n",
        "!ln -s /usr/lib/x86_64-linux-gnu/libhdf5_serial_hl.so /usr/lib/x86_64-linux-gnu/libhdf5_hl.so"
      ],
      "metadata": {
        "id": "MaRpc2_JZEdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the path for our HDF5 libs"
      ],
      "metadata": {
        "id": "xkmnQER9i_0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!find /usr -iname \"*hdf5.h*\" # got:\n",
        "# /usr/include/hdf5/serial/hdf5.h \n",
        "# /usr/include/opencv2/flann/hdf5.h\n",
        "# Let's try the first one.\n",
        "%env CPATH=\"/usr/include/hdf5/serial/\"\n",
        "#fatal error: hdf5.h: No such file or directory"
      ],
      "metadata": {
        "id": "yocwisfyZLaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt-get install libleveldb-dev\n",
        "!sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "!sudo apt-get install libsnappy-dev"
      ],
      "metadata": {
        "id": "oelKebsrZM_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build caffe from source files."
      ],
      "metadata": {
        "id": "3JXTpkNWZV1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $CPATH"
      ],
      "metadata": {
        "id": "oXGdHIdKZYMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now change into the Coffe directory and build the shared Coffe libraries as well as the CPP object files"
      ],
      "metadata": {
        "id": "8aSyGeAwj_BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd caffe\n",
        "\n",
        "!ls\n",
        "!make clean\n",
        "!cp Makefile.config.example Makefile.config"
      ],
      "metadata": {
        "id": "XUc1y_V3ZaiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/-gencode arch=compute_20/#-gencode arch=compute_20/' Makefile.config #old cuda versions won't compile \n",
        "!sed -i 's/\\/usr\\/local\\/include/\\/usr\\/local\\/include \\/usr\\/include\\/hdf5\\/serial\\//'  Makefile.config #one of the 4 things needed to fix hdf5 issues\n",
        "!sed -i 's/# OPENCV_VERSION := 3/OPENCV_VERSION := 3/' Makefile.config #We actually use opencv 4.1.2, but it's similar enough to opencv 3.\n",
        "!sed -i 's/code=compute_61/code=compute_61 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75/' Makefile.config #support for new GPUs"
      ],
      "metadata": {
        "id": "jadFlxc6ZkDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!make all -j 4 # -j would use all availiable cores, but RAM related errors occur"
      ],
      "metadata": {
        "id": "zXC_OPCEZmlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should now see the newly created shared libraries and Caffe object files."
      ],
      "metadata": {
        "id": "f0rl9mBxkQf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!find / -iname \"*caffe*\""
      ],
      "metadata": {
        "id": "mZrkU74_8fgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Caffe model on MNIST"
      ],
      "metadata": {
        "id": "sjhA_H6Qi1Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train our model, we have to download the mnist dataset."
      ],
      "metadata": {
        "id": "KcSo_R9ykZsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloads mnist dataset\n",
        "\n",
        "%cd /content/caffe/\n",
        "\n",
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "!cp -rv MNIST/raw/* data/mnist/"
      ],
      "metadata": {
        "id": "Mim2_gdsnB4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates mnist_test_lmdb and mnist_train_lmdb\n",
        "\n",
        "!/content/caffe/examples/mnist/create_mnist.sh"
      ],
      "metadata": {
        "id": "Wmq4yNR1nFcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we copy the output to the corresponding folder."
      ],
      "metadata": {
        "id": "IA7jI_C-kzMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy lmdbs to planet folder\n",
        "\n",
        "%cp -a /content/caffe/examples/mnist/mnist_test_lmdb /content/planet/casestudies/MNIST/\n",
        "%cp -a /content/caffe/examples/mnist/mnist_train_lmdb /content/planet/casestudies/MNIST/"
      ],
      "metadata": {
        "id": "L4LUHluFAoFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define our neural network"
      ],
      "metadata": {
        "id": "QRMEodfNuJ2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define the net and its structure with the individual layers, based on Planet's [example](https://github.com/progirep/planet/blob/master/casestudies/MNIST/lenet_train_test.prototxt).\n",
        "\n",
        "Our net is a set of layers connected in a computation graph – a directed acyclic graph (DAG) to be exact. \n",
        "In Caffe, the net is defined as a set of layers and their connections in a plaintext modeling language. \n",
        "\n",
        "The net begins with a data layer that loads the MNIST data. After that, a reshape layer is used to change the dimensions of the input to match those of MNIST. Next up is a convolution layer and a corresponding pooling layer. A ReLU layer with 8 neurons followed by a softmax loss layer with 10 neuron gives us the output. \n",
        "\n",
        "The inner product layers in between are used to fully connect the layers. The accuracy is computed by the accuracy layer, this layer doesn't have a backward step."
      ],
      "metadata": {
        "id": "f5gTkTOak7Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/caffe/examples/mnist/lenet_train_test.prototxt\n",
        "name: \"LeNet\"\n",
        "layer {\n",
        "  name: \"mnist\"\n",
        "  type: \"Data\"\n",
        "  top: \"data\"\n",
        "  top: \"label\"\n",
        "  include {\n",
        "    phase: TRAIN\n",
        "  }\n",
        "  transform_param {\n",
        "    scale: 0.00390625\n",
        "  }\n",
        "  data_param {\n",
        "    source: \"/content/caffe/examples/mnist/mnist_train_lmdb\"\n",
        "    batch_size: 64\n",
        "    backend: LMDB\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"mnist\"\n",
        "  type: \"Data\"\n",
        "  top: \"data\"\n",
        "  top: \"label\"\n",
        "  include {\n",
        "    phase: TEST\n",
        "  }\n",
        "  transform_param {\n",
        "    scale: 0.00390625\n",
        "  }\n",
        "  data_param {\n",
        "    source: \"/content/caffe/examples/mnist/mnist_test_lmdb\"\n",
        "    batch_size: 100\n",
        "    backend: LMDB\n",
        "  }\n",
        "}\n",
        "\n",
        "layer {\n",
        "    name: \"reshapeA\"\n",
        "    type: \"Reshape\"\n",
        "    bottom: \"data\"\n",
        "    top: \"reshapeA\"\n",
        "    reshape_param {\n",
        "      shape {\n",
        "        dim: -1  # copy the dimension from below\n",
        "        dim: 1  # copy the dimension from below\n",
        "        dim: 28  # copy the dimension from below\n",
        "        dim: 28 # infer it from the other dimensions\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "layer {\n",
        "  name: \"conv1\"\n",
        "  type: \"Convolution\"\n",
        "  bottom: \"reshapeA\"\n",
        "  top: \"conv1\"\n",
        "  param {\n",
        "    lr_mult: 1\n",
        "  }\n",
        "  param {\n",
        "    lr_mult: 2\n",
        "  }\n",
        "  convolution_param {\n",
        "    num_output: 3\n",
        "    kernel_size: 4\n",
        "    stride: 2\n",
        "    weight_filler {\n",
        "      type: \"xavier\"\n",
        "    }\n",
        "    bias_filler {\n",
        "      type: \"constant\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"pool1\"\n",
        "  type: \"Pooling\"\n",
        "  bottom: \"conv1\"\n",
        "  top: \"pool1\"\n",
        "  pooling_param {\n",
        "    pool: MAX\n",
        "    kernel_size: 4\n",
        "    stride: 3\n",
        "  }\n",
        "}\n",
        "\n",
        "layer {\n",
        "    name: \"reshapeB\"\n",
        "    type: \"Reshape\"\n",
        "    bottom: \"pool1\"\n",
        "    top: \"reshapeB\"\n",
        "    reshape_param {\n",
        "      shape {\n",
        "        dim: -1  # copy the dimension from below\n",
        "        dim: 48 # infer it from the other dimensions\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "layer {\n",
        "  name: \"ip1\"\n",
        "  type: \"InnerProduct\"\n",
        "  bottom: \"reshapeB\"\n",
        "  top: \"ip1\"\n",
        "  param {\n",
        "    lr_mult: 1\n",
        "  }\n",
        "  param {\n",
        "    lr_mult: 2\n",
        "  }\n",
        "  inner_product_param {\n",
        "    num_output: 8\n",
        "    weight_filler {\n",
        "      type: \"xavier\"\n",
        "    }\n",
        "    bias_filler {\n",
        "      type: \"constant\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"relu1\"\n",
        "  type: \"ReLU\"\n",
        "  bottom: \"ip1\"\n",
        "  top: \"relu1\"\n",
        "}\n",
        "layer {\n",
        "  name: \"ip2\"\n",
        "  type: \"InnerProduct\"\n",
        "  bottom: \"relu1\"\n",
        "  top: \"ip2\"\n",
        "  param {\n",
        "    lr_mult: 1\n",
        "  }\n",
        "  param {\n",
        "    lr_mult: 2\n",
        "  }\n",
        "  inner_product_param {\n",
        "    num_output: 10\n",
        "    weight_filler {\n",
        "      type: \"xavier\"\n",
        "    }\n",
        "    bias_filler {\n",
        "      type: \"constant\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "layer {\n",
        "  name: \"accuracy\"\n",
        "  type: \"Accuracy\"\n",
        "  bottom: \"ip2\"\n",
        "  bottom: \"label\"\n",
        "  top: \"accuracy\"\n",
        "}\n",
        "layer {\n",
        "  name: \"loss\"\n",
        "  type: \"SoftmaxWithLoss\"\n",
        "  bottom: \"ip2\"\n",
        "  bottom: \"label\"\n",
        "  top: \"loss\"\n",
        "}"
      ],
      "metadata": {
        "id": "P_6ze7ZxuNcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define our training \n",
        "\n",
        "We will train our net on 10,000 images for 20,000 iterations with a variable, decaying learning rate."
      ],
      "metadata": {
        "id": "cFfk8Cr9uf4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/caffe/examples/mnist/lenet_solver.prototxt\n",
        "# The train/test net protocol buffer definition\n",
        "net: \"examples/mnist/lenet_train_test.prototxt\"\n",
        "# test_iter specifies how many forward passes the test should carry out.\n",
        "# In the case of MNIST, we have test batch size 100 and 100 test iterations,\n",
        "# covering the full 10,000 testing images.\n",
        "test_iter: 100\n",
        "# Carry out testing every 500 training iterations.\n",
        "test_interval: 1000\n",
        "# The base learning rate, momentum and the weight decay of the network.\n",
        "base_lr: 0.01\n",
        "momentum: 0.9\n",
        "weight_decay: 0.0005\n",
        "# The learning rate policy\n",
        "lr_policy: \"inv\"\n",
        "gamma: 0.0001\n",
        "power: 0.75\n",
        "# Display every 100 iterations\n",
        "display: 1000\n",
        "# The maximum number of iterations\n",
        "max_iter: 20000\n",
        "# solver mode: CPU or GPU\n",
        "solver_mode: CPU"
      ],
      "metadata": {
        "id": "xvK34bjquj0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train our model using Caffe"
      ],
      "metadata": {
        "id": "-qSefwU1vFba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "!/content/caffe/build/tools/caffe train --solver=/content/caffe/examples/mnist/lenet_solver.prototxt $@"
      ],
      "metadata": {
        "id": "HQno6KNxnHM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training results in a .caffemodel file (under /content/caffe/examples/mnist/lenet_solver_iter_20000.caffemodel), which now describes our trained model. To verify it with PLANET, we have to convert it to the right input format:\n",
        "\n",
        "*.caffemodel -> .json -> .rlv*"
      ],
      "metadata": {
        "id": "EiA9fgUwuJMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Caffe model to Planet input file"
      ],
      "metadata": {
        "id": "H46WPknAXiRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we run into a problem; the Python scripts for converting the model are importing the caffe module, but in Colab this does not work. Caffe does not find the previously generated shared object file _caffe.so, which is wrapped in Python code using python 2.7. Therefore even changing the directory leads to a compatibility issue with the Python 2.7 compiled .so file and our Code in Python 3."
      ],
      "metadata": {
        "id": "UxUl65E0llnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore we have to download the corresponding file and run this offline. The corresponding output file can then be uploaded again and fed into the next steps. The Python functions can be found [here](https://github.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/lib/planet_helper_functions.py)."
      ],
      "metadata": {
        "id": "nBSjl-5FmslS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Caffe to JSON converter in Python3\n",
        "\n",
        "Run the function `caffeModelToJson()`.\n"
      ],
      "metadata": {
        "id": "QW1BFNkwCuA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JSON to RLV converter in Python3"
      ],
      "metadata": {
        "id": "aZ1j-mNVCU2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to convert the output in JSON format into the RLV format which can be read by planet. For this we simply use the script from the original author and rewrite it to work with python 3.\n",
        "\n",
        "Run the function `jsonToRlv()`."
      ],
      "metadata": {
        "id": "772XKg33nBkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verify Robustness with Planet\n",
        "\n",
        "Because the conversion doesn't work right away in Colab, we will download the files from GitHub. These files have been generated locally."
      ],
      "metadata": {
        "id": "prLQbKiridL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/output.rlv -O /content/output.rlv\n",
        "!wget https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/caffemodel_mnist.json -O /content/caffemodel_output.json"
      ],
      "metadata": {
        "id": "X1jmu4Pgw--g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the converted rlv file we now add the input constraints for our verification"
      ],
      "metadata": {
        "id": "nwZGoGahnnR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add contraints on Input Variables for Planet\n",
        "%cd /content/\n",
        "\n",
        "with open(\"output.rlv\", \"ab\") as f:\n",
        "  for i in range(28*28):\n",
        "    linebreak = bytes(\"\\n\", \"utf-8\")\n",
        "    assert_lowerbound = bytes(\"Assert <= 0.0 1.0 inX\" + str(i), \"utf-8\")\n",
        "    assert_upperbound = bytes(\"Assert >= 1.0 1.0 inX\" + str(i), \"utf-8\")\n",
        "\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_lowerbound)\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_upperbound)"
      ],
      "metadata": {
        "id": "5V2ezS_Dwy9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-mnist"
      ],
      "metadata": {
        "id": "l-Lee6NzpFFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist import MNIST\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data = MNIST(\"/content/caffe/data/mnist/\")\n",
        "\n",
        "imgs, labels = data.load_training()\n",
        "\n",
        "img = np.asarray(imgs[0]).reshape(28, 28)\n",
        "pixels = np.asarray(imgs[0])\n",
        "\n",
        "plt.title(\"Label: {}\".format(labels[0]))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "cB0NIuWMiaz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# targetDigit, maxDifferencePerPixel, maxUnsmoothnessInNoise \n",
        "# Obtain a digit image that is close to a given one, that resolves to the given target digit, \n",
        "# where every pixel is at most maxDifferencePerPixel away from the initial image \n",
        "# and the maximal noise difference between two adjacent pixels is maxUnsmoothnessInNoise. \n",
        "# The last two parameters should be >=0 and <=1 (such as, e.g., 0.05 for 5% deviation)\"\n",
        "maxDifferencePerPixel = 0.1\n",
        "targetDigit = 5\n",
        "maxUnsmoothnessInNoise = 0.05\n",
        "\n",
        "def addBounds(i, l_bound, u_bound):\n",
        "  with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "    linebreak = bytes(\"\\n\", \"utf-8\")\n",
        "    assert_lowerbound = bytes(\"Assert <= {} 1.0 inX{}\".format(l_bound, i), \"utf-8\")\n",
        "    assert_upperbound = bytes(\"Assert >= {} 1.0 inX{}\".format(u_bound, i), \"utf-8\")\n",
        "\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_lowerbound)\n",
        "    f.write(linebreak)\n",
        "    f.write(assert_upperbound)\n",
        "\n",
        "# constraints for input neurons  \n",
        "for i in range(28*28):\n",
        "  # exclude outer pixels, because there are no neighbours\n",
        "  x = i % 28\n",
        "  y = int(i / 28)\n",
        "\n",
        "  if x<3 or x>24 or y<3 or y>24:\n",
        "    border = 0.0\n",
        "  else:\n",
        "    border = maxDifferencePerPixel\n",
        "\n",
        "  lower_bound = max(0.0, pixels[i]/256.0 - border)\n",
        "  upper_bound = min(1.0, pixels[i]/256.0 + border) \n",
        "  addBounds(i, lower_bound, upper_bound)\n",
        "\n",
        "# constraints for output neurons\n",
        "for i in range(10):\n",
        "  if i == targetDigit:\n",
        "    continue\n",
        "  with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "    assertion = \"\\nAssert >= -0.000001 1.0 outX{} -1.0 outX{}\".format(i, targetDigit)\n",
        "    f.write(bytes(assertion, \"utf-8\"))\n",
        "\n",
        "# constraints for smoothness\n",
        "for x in range(28):\n",
        "  for y in range(28):\n",
        "    if y < 27:\n",
        "      pixelDiff = (pixels[y*28+x] - pixels[(y+1)*28+x]) / 256.0\n",
        "      ass1 = \"\\nAssert <= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff-maxUnsmoothnessInNoise), (y*28+x), (y+1)*28+x)\n",
        "      ass2 = \"\\nAssert >= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff+maxUnsmoothnessInNoise), (y*28+x), (y+1)*28+x)\n",
        "      with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "        f.write(bytes(ass1, \"utf-8\"))\n",
        "        f.write(bytes(ass2, \"utf-8\"))\n",
        "    if x < 27: \n",
        "      pixelDiff = (pixels[y*28+x] - pixels[y*28+x+1]) / 256.0\n",
        "      ass1 = \"\\nAssert <= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff-maxUnsmoothnessInNoise), (y*28+x), (y*28+x+1))\n",
        "      ass2 = \"\\nAssert >= {} 1.0 inX{} -1.0 inX{}\".format((pixelDiff+maxUnsmoothnessInNoise), (y*28+x), (y*28+x+1))\n",
        "      with open(\"/content/output.rlv\", \"ab\") as f:\n",
        "        f.write(bytes(ass1, \"utf-8\"))\n",
        "        f.write(bytes(ass2, \"utf-8\"))\n",
        "\n",
        "print(\"FINISHED ADDING CONSTRAINTS!\")"
      ],
      "metadata": {
        "id": "2fteFaDxrWRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run planet and save the output in a text file, so we can parse it for values later. This has to be run twice, because Colab returns an error the first time."
      ],
      "metadata": {
        "id": "yK_eR4X6C6YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture cap --no-stderr\n",
        "!/content/planet/src/planet /content/output.rlv\n",
        "\n",
        "with open(\"/content/planet_output.txt\", \"w\") as f:\n",
        "  f.write(cap.stdout)"
      ],
      "metadata": {
        "id": "bDjicShU-4HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sat = False\n",
        "valLineFound = False\n",
        "values = {}\n",
        "\n",
        "# parse the planet output\n",
        "with open(\"/content/planet_output.txt\", \"r\") as f:\n",
        "  for line in f.readlines():\n",
        "    line = line.strip()\n",
        "\n",
        "    if line == \"SAT\":\n",
        "      sat = True\n",
        "    elif line == \"Valuation:\":\n",
        "      valLineFound = True\n",
        "    elif line.startswith(\"- \") and valLineFound:\n",
        "      parts = line.split(\" \")\n",
        "      \n",
        "      assert parts[0] == \"-\"\n",
        "      assert parts[3] == \"/\"\n",
        "\n",
        "      # DEBUG prints\n",
        "      # print(parts[1][:len(parts[1])-1])\n",
        "      # print(parts[2])\n",
        "      # break\n",
        "      # builds a dictionary with the calculated values\n",
        "      # e.g. values[inX0] = 0.0\n",
        "      values[parts[1][:len(parts[1])-1]] = float(parts[2])\n",
        "\n",
        "# create adverserial example\n",
        "if sat:\n",
        "  outImg = Image.new(\"L\", (28, 28))\n",
        "  for y in range(28):\n",
        "    for x in range(28):\n",
        "      outImg.putpixel((x, y), int(256*values[\"inX{}\".format(y*28 + x)]))\n",
        "\n",
        "  #plt.title(\"Label: {}\".format(labels[0]))\n",
        "  plt.imshow(outImg)"
      ],
      "metadata": {
        "id": "jkHsIUtnAFA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our adversarial example.\n",
        "\n",
        "If you want to try different Asserts, the next cell removes all Asserts from the output.rlv file."
      ],
      "metadata": {
        "id": "Xl8y9toZwZro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes assert conditions and empty lines\n",
        "!sed -i \"/Assert/d\" /content/output.rlv\n",
        "!sed -i \"/^$/d\" /content/output.rlv "
      ],
      "metadata": {
        "id": "nVLvoMLsvtqv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}