{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorials/adversarial_example_iris_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EANjAB09ya41"
   },
   "source": [
    "# TODO\n",
    "- explanations and documentation (mostly done)\n",
    "- rectangle plot (done)\n",
    "- upper bound for epsilon \n",
    "- Transpose? (done)\n",
    "- second example for fixed_input_y (done)\n",
    "- fix error in method find_adversarial_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvjqBedigGT5"
   },
   "source": [
    "# Tutorial: Neural network verification with SMT solver Z3\n",
    "\n",
    "In this tutorial, you will learn how to verify the adversarial robustness of a neural network with an SMT solver. First, a neural network for classification is implemented. Then, the model is verified using the [theorem prover Z3 from Microsoft Research](https://github.com/Z3Prover/z3).\n",
    "\n",
    "The Jupyter Notebook can be executed in Google Colab or on a local machine where Python and the packages jupyter, PyTorch, scikit-learn, matplotlib, numpy and tqdm are installed. The notebook can be executed using a CUDA GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLfqLvsfgLB8"
   },
   "source": [
    "Using pip, the z3 solver is downloaded and installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWF6jABWwH_B",
    "outputId": "7808a5d0-653f-421b-f72e-e732682bfe4a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%pip install z3-solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To carry out the individual steps, some Python libraries are imported.\n",
    "First, import Z3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for SMT-based verification\n",
    "from z3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMauJvpWLJtD"
   },
   "source": [
    "[PyTorch](https://pytorch.org/) is a machine learning framework for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INBFX6hvLyxu"
   },
   "outputs": [],
   "source": [
    "# imports for pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qGmjPbuMM93"
   },
   "source": [
    "In addition, the [scikit-learn](https://scikit-learn.org/stable/) library is used to import the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNpJOVpWMXv0"
   },
   "outputs": [],
   "source": [
    "# imports for sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66mb5wR2MZ9w"
   },
   "source": [
    "Some other libraries provide extended functionalities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCsqsBSE2mY3"
   },
   "outputs": [],
   "source": [
    "# import for progress bar\n",
    "import tqdm\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# for plots\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# for measuring runtime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO71uVM2tZwz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data set\n",
    "\n",
    "Training and test data must be available to train the ML model. The dataset is downloaded, then scaled and split into train and test set using scikit-learn.\n",
    "\n",
    "In this tutorial the [Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) is used to train the neural network. The data set consists of 3 different species of Iris flowers (Setosa, Versicolour, and Virginica). The input features are the sepal length, the sepal width, the petal length and the petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUzWjRQVsplE",
    "outputId": "49d18bd4-2f04-45df-caea-5796e607f320",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "  \n",
    "print(f\"Shape of X (data): {X.shape}\")\n",
    "print(f\"Shape of y (target): {y.shape} {y.dtype}\")\n",
    "print(f\"Example of x and y pair: {X[0]} {y[0]}\")\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(\"Shape of training set X\", X_train.shape)\n",
    "print(\"Shape of test set X\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFFc6c7YheLj"
   },
   "source": [
    "## Visualize data set\n",
    "\n",
    "The following show_plots function is used to plot the input features and their classification. The Rectangle plot is used later for visualizing the robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrfkEq_shgv6"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def show_plots(X, y, fixed_input = None, epsilon = None, title = ''):\n",
    "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "  fig.suptitle(title, fontsize=16)\n",
    "  for target, target_name in enumerate(names):\n",
    "      X_plot = X[y == target]\n",
    "      ax1.plot(X_plot[:, 0], X_plot[:, 1], \n",
    "              linestyle='none', \n",
    "              marker='o', \n",
    "              label=target_name)\n",
    "  ax1.set_xlabel(feature_names[0])\n",
    "  ax1.set_ylabel(feature_names[1])\n",
    "  ax1.axis('equal')\n",
    "  ax1.legend()\n",
    "\n",
    "  for target, target_name in enumerate(names):\n",
    "      X_plot = X[y == target]\n",
    "      ax2.plot(X_plot[:, 2], X_plot[:, 3], \n",
    "              linestyle='none', \n",
    "              marker='o', \n",
    "              label=target_name)\n",
    "  ax2.set_xlabel(feature_names[2])\n",
    "  ax2.set_ylabel(feature_names[3])\n",
    "  ax2.axis('equal')\n",
    "  ax2.legend()\n",
    "\n",
    "  if fixed_input is not None and epsilon is not None:\n",
    "    #add rectangle to plot -> shows infinity norm \n",
    "    ax1.add_patch(Rectangle((fixed_input[0] - epsilon, fixed_input[1] - epsilon), \n",
    "                            2*epsilon, 2*epsilon, \n",
    "                            edgecolor='pink',\n",
    "                            facecolor='none',      \n",
    "                            lw=4))\n",
    "    ax1.set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "\n",
    "    ax2.add_patch(Rectangle((fixed_input[2]-epsilon, fixed_input[3]-epsilon), \n",
    "                            2*epsilon, 2*epsilon, \n",
    "                            edgecolor='pink',\n",
    "                            facecolor='none',      \n",
    "                            lw=4))\n",
    "    ax2.set_aspect(\"equal\", adjustable=\"datalim\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following visualisation of the data set shows the correct classification of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "OOxEBcN3z2kF",
    "outputId": "1b9f5429-fb80-4a5a-8bb8-6005ee14d37f"
   },
   "outputs": [],
   "source": [
    "show_plots(X, y, title='Classification of input data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1RHVlUOgcce"
   },
   "source": [
    "## Define model\n",
    "\n",
    "The class NeuralNetwork (inherited of PyTorchÂ´s nn.Module) allows initializing a neural network with different layers.\n",
    "Here, we use a simple network with only three fully connected layers, because complex networks require high computational effort for verification. As activation function ReLU is used, because ReLU is piecewise linear and therefore easier for SMT based verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XS6KcOvgkjI",
    "outputId": "aabbbb10-6394-49b2-9f9b-9dd6b5e2e80e"
   },
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, number_of_neurons):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_dim, number_of_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(number_of_neurons, number_of_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(number_of_neurons, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_0_55YG73tT"
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to train the neural network using an optimizer and a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sugcndu9OaTj"
   },
   "outputs": [],
   "source": [
    "def train(X, y, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    # convert numpy array to pytorch tensor\n",
    "    X = Variable(torch.from_numpy(X)).float()\n",
    "    y = Variable(torch.from_numpy(y)).long()\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss = loss.item()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8U6G9huV8MO"
   },
   "source": [
    "The predict-function is used to generate the output of the ML model based on the learned weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vf2SKRe_OmrY"
   },
   "outputs": [],
   "source": [
    "def predict(X, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = Variable(torch.from_numpy(X)).float()\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        pred = pred.argmax(1)\n",
    "        pred = pred.cpu().detach().numpy()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzkbngYIWFMD"
   },
   "source": [
    "In the test-function, the output of the ML model for input values is compared with the expected (and correct) classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(X, y, model, loss_fn):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        X = Variable(torch.from_numpy(X)).float()\n",
    "        y = Variable(torch.from_numpy(y)).long()\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    correct /= X.shape[0]\n",
    "    return correct, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezkHFNY4WjIT"
   },
   "source": [
    "The following function is used to train the model over a number of epochs in order to increase the accuracy (on the test data) of the model.\n",
    "As loss function cross entropy and as optimizer Adam is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "se6iQ-3m05bp"
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "  loss_list     = np.zeros((epochs,))\n",
    "  accuracy_list = np.zeros((epochs,))\n",
    "\n",
    "  for epoch in tqdm.trange(epochs):\n",
    "    loss_list[epoch] = train(X_train, y_train, model, loss_fn, optimizer)\n",
    "    correct, test_loss = test(X_test, y_test, model, loss_fn)\n",
    "    accuracy_list[epoch] = correct\n",
    "  \n",
    "  print()\n",
    "  print(\"Done. Accuracy:\", accuracy_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmSZQ_YrW6t5"
   },
   "source": [
    "For reproducability a manual seed is used. Then, the model is initialized and trained via the defined functions. In this example, a neural network with 20 neurons in each layer is used. The number of epochs is set to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J812JwE09Zg",
    "outputId": "4817b865-606e-4a0c-d572-7a30d0d31efc"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model = NeuralNetwork(input_dim=X_train.shape[1], output_dim=3, number_of_neurons=20).to(device)\n",
    "print(model)\n",
    "\n",
    "train_model(model, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots show the expected classification and the classification of the neural network on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "ZIS92z7j4LaU",
    "outputId": "891f877a-8350-4461-8436-638baceca7b7"
   },
   "outputs": [],
   "source": [
    "show_plots(X, y, title = 'Expected classification')\n",
    "show_plots(X, predict(X_scaled, model), title = 'Actual classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn24qqA3tiYE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Adversarial robustness verification\n",
    "\n",
    "The next step will be to create a solver with Z3 in order to find Aversarial Examples. \"An adversarial example is an instance with small, intentional feature perturbations that cause a machine learning model to make a false prediction.\" (For more information on adversarial examples see [this article](https://christophm.github.io/interpretable-ml-book/adversarial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ya0UOSGhA43"
   },
   "source": [
    "The ML model was trained on the iris dataset in the previous section.\n",
    "Now the task is to recreate the model using the trained weights and the layers of the model. To do this, the learned weights and biases must first be extracted from the model. This is done by iterating over the layers and saving the weights and biases of the Linear Layers into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqsUPwfb4kLd"
   },
   "outputs": [],
   "source": [
    "def get_weights_and_biases_pytorch(model):\n",
    "  weights_and_biases = [param.cpu().detach().numpy() for param in model.parameters()]\n",
    "  weights = weights_and_biases[0::2]\n",
    "  biases = weights_and_biases[1::2]\n",
    "  return weights, biases\n",
    "\n",
    "\n",
    "weights, biases = get_weights_and_biases_pytorch(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0WP9GSyhKL-"
   },
   "source": [
    "To recreate the network with Z3, we have to manually define our activation function which in our case is the ReLU function. Note that the `If(..)`-function is imported from Z3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrgBiMwChOXy"
   },
   "outputs": [],
   "source": [
    "def Relu(x):\n",
    "    return np.vectorize(lambda y: If(y >= 0 , y, RealVal(0)))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAkaqwdqhVOd"
   },
   "source": [
    "The implementation of the neural network is based on pytorch. Therefore, the [Linear Layer of pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) is used. The calculation there is defined as:\n",
    "\\begin{equation}\n",
    "y = xA^{T}+b\n",
    "\\end{equation}\n",
    "where $ y $ is the current output, $x$ is the current input, $A$ is the weight of the layer and $b$ stands for the bias.\n",
    "Here, it's assumed that the model to verify has only fully connected layers with bias in every layer and relu between them. In the last layer, no ReLU activation is used.\n",
    "Now, it's possible to rebuild the network by using Z3 variables and previously extracted weights/biases trained by the network. The function iterates over each layer. This results in a Z3 formula for the net output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE5iTY365wnn"
   },
   "outputs": [],
   "source": [
    "def net(x, weights, biases):\n",
    "  output = x\n",
    "\n",
    "  for i, (weight, bias) in enumerate(zip(weights, biases)):\n",
    "    # apply formular used for nn.Linear in pytorch\n",
    "    output = output @ np.transpose(weight) + bias\n",
    "    # apply relu except in last layer\n",
    "    if i != len(weights) - 1:\n",
    "      output = Relu(output)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjswTTcO9aYc"
   },
   "source": [
    "To prove the adversarial robustness of the neural network:\n",
    "- fixed input $\\vec{y} âˆˆ \\mathbb{R}^m $\n",
    "- $ \\epsilon \\in \\mathbb{R} $\n",
    "- $ L_âˆ $-distance\n",
    "- $ ğ‘‰_ğ‘–={ğœˆ_1, â€¦, ğœˆ_ğ‘š } $\n",
    "- $ ğ‘‰_ğ‘œ={ğœˆ_1^â€², â€¦, ğœˆ_ğ‘›^â€² } $\n",
    "\n",
    "Precondition: $ \\varphi_{pre} â‰” â‹€_{i=1}^n ((x_{v_i} - y_i â‰¤ Îµ) âˆ§ (y_i - x_{v_i} â‰¤ Îµ)) $\n",
    "\n",
    "Assign (here the above net function is used): $ \\varphi_{assign} â‰” Ï†^N $\n",
    "\n",
    "Post condition: $ \\varphi_{post} â‰” â‹€_{i=1}^m x_{v'_i} â‰¤ x_{v'_l} $ for $ \\ell = \\arg\\max f_N(\\vec{y}) $\n",
    "\n",
    "\n",
    "Verification condition: $ \\psiâ‰”(Ï†_{pre} âˆ§ Ï†_{assign}) â‡’ Ï†_{post} $\n",
    "Proving robustness means proving the verification condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBY3e2Kw7Uq2"
   },
   "outputs": [],
   "source": [
    "def verify(fixed_input_y, fixed_input_y_class, epsilon, weights, biases):\n",
    "  input_size = fixed_input_y.shape[0]\n",
    "  x = RealVector(\"x\", input_size)\n",
    "\n",
    "  # pre-condition\n",
    "  # basically L_infinity-distance in boolean speak\n",
    "  and_parts = []\n",
    "  for i, x_vi in enumerate(x):\n",
    "    and_parts.append(And((x_vi - fixed_input_y[i]) <= epsilon, (fixed_input_y[i] - x_vi) <= epsilon))\n",
    "  pre_cond = And(and_parts)\n",
    "\n",
    "  # post-condition\n",
    "  # x_vo = x_v'\n",
    "  output = net(x, weights, biases)\n",
    "  and_parts = []\n",
    "  for i, x_vo in enumerate(output):\n",
    "    and_parts.append(x_vo <= output[fixed_input_y_class])\n",
    "  post_cond = And(and_parts)\n",
    "\n",
    "  verification_cond = Implies(pre_cond, post_cond)\n",
    "\n",
    "  print(\"Pre condition: \")\n",
    "  print(pre_cond)\n",
    "  print(\"Post condition: \")\n",
    "  print(post_cond)\n",
    "  print(\"--------------\")\n",
    "\n",
    "  prove(verification_cond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbHXdDw0ZBWh"
   },
   "source": [
    "Some input value $ \\vec{y} $ (here the first datapoint of the dataset) is fixed and an epsilon value (e. g. 0.5) is chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toXBusE57iQo"
   },
   "outputs": [],
   "source": [
    "fixed_input_y = X_scaled[0]\n",
    "fixed_input_y_class = y[0]\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNvAoFXLZJ-g"
   },
   "source": [
    "The robustness of the neural network with that specific input value and epsilon is verified/proven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0Uzopda7ZUh",
    "outputId": "65769f66-32c8-42d9-ff68-802328ecb669"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "verify(fixed_input_y, fixed_input_y_class, epsilon, weights, biases)\n",
    "print(f\"{((time.time() - start_time)/60):.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq5W316sY1Ut"
   },
   "source": [
    "Second example: Another input value $ \\vec{y_2} $ is fixed and a counterexample is found by Z3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-r-eotnY5y2",
    "outputId": "0196ae13-aef6-4fd8-d584-f4672c6a79b7"
   },
   "outputs": [],
   "source": [
    "fixed_input_y2 = X_scaled[50]\n",
    "fixed_input_y2_class = y[50]\n",
    "\n",
    "start_time = time.time()\n",
    "verify(fixed_input_y2, fixed_input_y2_class, epsilon, weights, biases)\n",
    "print(f\"{((time.time() - start_time)/60):.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8xujoQA8Ys7"
   },
   "source": [
    "## Prediction plots with epsilon\n",
    "\n",
    "Show the plots of the dataset (here scaled) and plot the $ L_âˆ $-distance of fixed input $ \\vec{y} $ as a square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "F9qPlsh77d6r",
    "outputId": "d42c3ac1-2ff8-443c-85d6-76a1ca2f20ba"
   },
   "outputs": [],
   "source": [
    "show_plots(X_scaled, y, title = 'Expected classification (scaled values)')\n",
    "show_plots(X_scaled, predict(X_scaled, model), fixed_input_y, epsilon, title = 'Actual classification (scaled values)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIYvrjk37kNW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11VVB4Uj8p13"
   },
   "source": [
    "## Task: find largest epsilon for robustness with binary search\n",
    "with a certain accuracy\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GyRTysoE83UV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6ftZQcs9Sea"
   },
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1bdvZ3w9UWX"
   },
   "source": [
    "### Verify with each neuron encoded seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjo9A2oZ9T0R"
   },
   "outputs": [],
   "source": [
    "def ReluSingleNeuron(x):\n",
    "  return If(x >= 0, x, RealVal(0))\n",
    "\n",
    "def verify_each_neuron(fixed_input_y, fixed_input_y_class, epsilon, weights, biases):\n",
    "  # Unpack weights of the trained model\n",
    "  input_size = fixed_input_y.shape[0]\n",
    "  neurons = []\n",
    "  x = RealVector(\"x\", input_size)\n",
    "  output  = [RealVector(f\"x{i}\", weight.shape[0]) for i, weight in enumerate(weights)]\n",
    "\n",
    "  # pre-condition\n",
    "  # basically L_infinity-distance in boolean speak\n",
    "  and_parts = []\n",
    "  for i, x_vi in enumerate(x):\n",
    "    and_parts.append(And((x_vi - fixed_input_y[i]) <= epsilon, (fixed_input_y[i] - x_vi) <= epsilon))\n",
    "  pre_cond = And(and_parts)\n",
    "  #print(pre_cond)\n",
    "\n",
    "  # assign\n",
    "  and_parts = []\n",
    "  # for each layer\n",
    "  for layer_i, (layer_output, layer_weights, layer_biases) in enumerate(zip(output, weights, biases)):\n",
    "    # for each neuron\n",
    "    for neuron_output, neuron_weights, neuron_bias in zip(layer_output, layer_weights, layer_biases):\n",
    "      if layer_i == 0:\n",
    "        # neuron input is net input\n",
    "        neuron_inputs = x\n",
    "      else:\n",
    "        # neuron input is output of previous layer\n",
    "        neuron_inputs = output[layer_i - 1]\n",
    "      and_parts.append(neuron_output == ReluSingleNeuron(neuron_weights @ neuron_inputs + neuron_bias))\n",
    "  assign = And(and_parts)\n",
    "\n",
    "  # post-condition\n",
    "  # x_vo = x_v'\n",
    "  and_parts = []\n",
    "  for i, x_vo in enumerate(output[-1]):\n",
    "    # l is the argmax of fixed_input_y\n",
    "    and_parts.append(x_vo <= output[-1][fixed_input_y_class])\n",
    "  post_cond = And(and_parts)\n",
    "\n",
    "  # verification conditions\n",
    "  verification_cond = Implies(And(pre_cond, assign), post_cond)\n",
    "\n",
    "  # prove using Z3\n",
    "  prove(verification_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "-skIa28D916V",
    "outputId": "4dafbf18-177a-4075-e839-5c06d7f49ee4"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "verify_each_neuron(fixed_input_y, fixed_input_y_class, epsilon, weights, biases)\n",
    "print(f\"{((time.time() - start_time)/60):.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx60TlqD-UUT"
   },
   "source": [
    "### Another approach: Create Solver to find Adversarial Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute value is defined as a helper function to aid in calculating the distance between 2 vectors when using z3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Abs(x):\n",
    "    ret = If(x <= 0, -x, x)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section we search the adversarial example to a sample of the dataset. Therefore a sample runs through the trained model to predict an outcome.\n",
    "The beforehand written function ```net(x)``` gets a manipulated input of the sample. A epsilon is added to every value of the input of the function.\n",
    "To generate a vector epsilon which will constitute our manipulation of the input data with z3 the solver has to be defined first and then the constraints of our vectors as well as the inputs and outputs are added to the solver. The solver then has to check the satisfiability of the given constraints and a model is returned and printed if a vector epsilon which has a taxicab norm smaller than the constant e and changes the category with the highest probability exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JR0iIrYdd9uH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_adversarial_example(num, s):\n",
    "   # predict outcome of inputs with network\n",
    "    sample = Variable(torch.from_numpy(X_test[num])).float()\n",
    "    y1 =  torch.argmax(model(sample)).tolist()\n",
    "    if (y1 == y_test[num]):\n",
    "      print(\"The ML model predicted the correct flower.\")\n",
    "    else:\n",
    "      print(\"The ML model predicted the wrong flower, for a correct example rerun the script.\")\n",
    "\n",
    "    epsilon = RealVector('epsilon', 4)\n",
    "    # new sample with a little difference e (adversarial example)\n",
    "    new_X = [x + e for (x, e) in zip(sample.cpu().detach().numpy(), epsilon)]\n",
    "    y2_pred = net(new_X)\n",
    "\n",
    "    e = 1\n",
    "    s.add(Sum([Abs(a) for a in epsilon]) < e)\n",
    "    # does work :\n",
    "    # s.add(torch.argmax(y1).cpu().detach().numpy() != y2_pred)\n",
    "    s.add(Or(y2_pred[0] > y2_pred[y1], y2_pred[1] > y2_pred[y1], y2_pred[2] > y2_pred[y1]))\n",
    "    res = s.check()\n",
    "    print(res)\n",
    "    if res == sat:\n",
    "        m = s.model()\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak4hXgNXcmFa"
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "  s = Solver()\n",
    "  find_adversarial_example(i, s)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "iris.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}