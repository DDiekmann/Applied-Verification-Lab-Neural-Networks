{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alpha-Beta-Crown.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYr8h3mp4nNGDv0s459S8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorials/Alpha_Beta_Crown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial for α,β-CROWN Robustness Verification \n",
        "\n"
      ],
      "metadata": {
        "id": "aYgyJk_R5281"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*This tutorial shows the robustness verification of a neural network trained on \n",
        "the MNIST dataset with use of α,β-CROWN.*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rz2u1ieA8NBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**α,β-CROWN**\n",
        "α,β-CROWN is an open-source neural network verifier. The code can be found on [their website](https://github.com/huanzhang12/alpha-beta-CROWN). "
      ],
      "metadata": {
        "id": "sOpfUe1C8xBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we will first go through the installation of α,β-CROWN and train our own network. This network is to be verified later in the tutorial. Therefore, the verfication must be configured first. "
      ],
      "metadata": {
        "id": "LfF1cvIX70Kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "n0Quth1B5Wbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This installation is based on another [tutorial](https://colab.research.google.com/drive/1mJTOmq2qHxMycHUzBepBN47QWcxda3ov#scrollTo=Y0toepwVIFTG). "
      ],
      "metadata": {
        "id": "Y8neFi6n5da9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will set up our miniconda environment. "
      ],
      "metadata": {
        "id": "A2WnHH7D8QdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "%env PYTHONPATH=\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "JV2OjHuS32CK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python in version 3.7 is installed into the environment. "
      ],
      "metadata": {
        "id": "mu9YAbJS8WHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "conda install --channel defaults conda python=3.7 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "id": "2r20b2Wg36Kd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import sys\n",
        "sys.path\n",
        "!ls /usr/local/lib/python3.7/dist-packages\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ],
      "metadata": {
        "id": "iVia-nO53826"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use the library, we have to clone the corresponding git-repository."
      ],
      "metadata": {
        "id": "clVssA098eAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/huanzhang12/alpha-beta-CROWN.git"
      ],
      "metadata": {
        "id": "R3m60hqD3_sQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The environment is created. "
      ],
      "metadata": {
        "id": "3mZvUGSX8rAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "# Remove the old environment, if necessary.\n",
        "conda env remove --name alpha-beta-crown\n",
        "conda env create -f alpha-beta-CROWN/complete_verifier/environment.yml  # install all dependents into the alpha-beta-crown environment"
      ],
      "metadata": {
        "id": "UThlPEBk4Ckw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd alpha-beta-CROWN/complete_verifier/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssVpobxp4GQa",
        "outputId": "5ef5f09c-b2f4-4134-e3b9-7defb165beec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alpha-beta-CROWN/complete_verifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As explained on [the website of the α,β-project](https://github.com/huanzhang12/alpha-beta-CROWN), it is nessasary to create a configuration file in order to load the data. "
      ],
      "metadata": {
        "id": "pgl_rkFY8uvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure verification"
      ],
      "metadata": {
        "id": "LK3JuZPt4-mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to verifiy a model. Therefore, we create a file called my_example_config.yaml which configures parameters for verification. \n",
        "The model is defined as followed: \n",
        "\n",
        "\n",
        "```\n",
        "def mnist_6_100():\n",
        "    model = nn.Sequential(\n",
        "        Flatten(),\n",
        "        nn.Linear(784,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "    return model\n",
        "```\n",
        "\n",
        "It contains six linear layers and uses the ReLU activation function."
      ],
      "metadata": {
        "id": "Z8U-YzCS9yAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with a very basic configuration file, which means that most parameters are set to default."
      ],
      "metadata": {
        "id": "fekbamk9Dm82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/my_example_config.yaml\n",
        "general:\n",
        "  # device to run verifier\n",
        "  device: cpu \n",
        "  # Complete verification verifier. \n",
        "  # \"bab\": branch and bound with beta-CROWN; \n",
        "  # \"mip\": mixed integer programming (MIP) formulation; \n",
        "  # \"bab-refine\": branch and bound with intermediate layer bounds computed by MIP.\n",
        "  complete_verifier: bab\n",
        "model:\n",
        "  # name of the model (provided by library, see above)\n",
        "  name: mnist_6_100\n",
        "  # Load pretrained model from this specified path.\n",
        "  path: models/eran/mnist_6_100_nat.pth\n",
        "data:\n",
        "  # Dataset name. Dataset must be defined in utils.py.\n",
        "  dataset: MNIST_ERAN_UN\n",
        "  # Std vector used in data preprocessing.\n",
        "  std: [1.0]\n",
        "  # Mean vector used in data preprocessing.\n",
        "  mean: [0.0]\n",
        "specification:\n",
        "  # Set perturbation size (Lp norm). \n",
        "  # If not set, a default value may be used based on dataset loader.\n",
        "  epsilon: 0.026\n",
        "solver:\n",
        "  alpha-crown:\n",
        "    # Number of iterations for alpha-CROWN incomplete verifier.\n",
        "    iteration: 20  \n",
        "attack:\n",
        "  # Early stop PGD when an adversarial example is found.\n",
        "  pgd_early_stop: true  "
      ],
      "metadata": {
        "id": "s1E0j7dbVvGg",
        "outputId": "ec4d6417-a726-41fc-f0cd-5358778b6480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting exp_configs/my_example_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verification of network with α,β-CROWN"
      ],
      "metadata": {
        "id": "ivgGYPZUMShY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we only have to run our verification. "
      ],
      "metadata": {
        "id": "y-uwErjZ-T4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we activate our environment.\n",
        "Then we call the robustness_verifier on our configured yaml-file. The robustness_verifier is a class provided by the α,β-CROWN-library for Lp norm robustness verification and is often used to certify the robustness of a neural network. \n",
        "By setting start to 0 and end to 3, we indicate that only images 0 to 3 from the dataset should be verified. This is done for performance reasons. \n",
        "We finish by deactivating the environment.\n"
      ],
      "metadata": {
        "id": "7mM9hCLY-bQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run.sh\n",
        "\n",
        "source activate alpha-beta-crown\n",
        "python robustness_verifier.py --config exp_configs/my_example_config.yaml --start 0 --end 3\n",
        "conda deactivate"
      ],
      "metadata": {
        "id": "1wOCa05uMept",
        "outputId": "4b12fe6f-1ca0-43cf-fa07-cf40ae5a0ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting run.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 run.sh\n",
        "!./run.sh"
      ],
      "metadata": {
        "id": "di2IgirTVxO0",
        "outputId": "02dcdb9d-64ca-4b5c-c8a5-dd3de45de86a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cpu\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: models/eran/mnist_6_100_nat.pth\n",
            "  name: mnist_6_100\n",
            "data:\n",
            "  start: 0\n",
            "  end: 3\n",
            "  num_outputs: 10\n",
            "  mean: [0.0]\n",
            "  std: [1.0]\n",
            "  pkl_path: null\n",
            "  dataset: MNIST_ERAN_UN\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: lp\n",
            "  norm: .inf\n",
            "  epsilon: 0.026\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 1\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 64\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 50\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 200000\n",
            "  decision_thresh: 0\n",
            "  timeout: 360\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: kfsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: before\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 30\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Sun Jun 12 09:51:55 2022 on 24e6990cabc8\n",
            "Sequential(\n",
            "  (0): Flatten()\n",
            "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (8): ReLU()\n",
            "  (9): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "/content/alpha-beta-CROWN/complete_verifier/utils.py:512: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)\n",
            "############################\n",
            "Sampled data loaded. No normalization used!\n",
            "Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])\n",
            "X range: tensor(1.) tensor(0.) tensor(0.1223)\n",
            "Note runnerup label is empty here!\n",
            "############################\n",
            "epsilon after preprocessing: tensor([[[[0.0260]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])\n",
            "Task length: 3\n",
            "saving results to Verified_ret_[mnist_6_100]_start=0_end=3_iter=50_b=64_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 7, correct label 7, image norm 72.3686294555664, logits tensor([-2.7419, -1.9715, -0.2067,  1.3752, -0.8952, -3.5481, -7.3186, 13.2074,\n",
            "        -4.4189,  3.8866], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 7, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([-2.3157, -1.4768, -0.3271,  1.2411, -0.7472, -2.6581, -5.9633, 10.4310,\n",
            "        -3.2570,  3.3437], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([12.7467, 11.9078, 10.7581,  9.1899, 11.1781, 13.0891, 16.3943,     inf,\n",
            "        13.6879,  7.0872], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[-2.7419, -1.9715, -0.2067,  1.3752, -0.8952, -3.5481, -7.3186, 13.2074,\n",
            "         -4.4189,  3.8866]], grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[4.7498, 3.7544, 2.8216, 1.2226, 5.1403, 5.2825, 7.9722, 4.6015, 0.9006]]) None\n",
            "verified with init bound!\n",
            "Result: image 0 verification success (with incomplete verifier)!\n",
            "Wall time: 0.9607770442962646\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 1 img ID: 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 2, correct label 2, image norm 113.13725280761719, logits tensor([-2.0595,  1.7575, 10.0782,  1.0748, -0.9482, -4.0839, -2.3911,  0.3436,\n",
            "        -0.9526, -4.9323], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 2, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([-2.2444,  1.8947,  8.5624,  1.2637, -1.0060, -3.4432, -2.2272,  0.5084,\n",
            "        -0.6859, -4.3616], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([10.8067,  6.6677,     inf,  7.2986,  9.5684, 12.0056, 10.7896,  8.0539,\n",
            "         9.2483, 12.9240], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[-2.0595,  1.7575, 10.0782,  1.0748, -0.9482, -4.0839, -2.3911,  0.3436,\n",
            "         -0.9526, -4.9323]], grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[0.6301, 0.1344, 0.4976, 2.1355, 2.5526, 2.1028, 1.8815, 1.7729, 3.6696]]) None\n",
            "verified with init bound!\n",
            "Result: image 1 verification success (with incomplete verifier)!\n",
            "Wall time: 0.9956364631652832\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 2 img ID: 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 1, correct label 1, image norm 38.709800720214844, logits tensor([-3.7012,  8.8913,  1.1001, -2.5765,  0.6640, -2.1244, -1.6588,  0.6820,\n",
            "         1.0836, -2.1354], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 1, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([-2.5066,  4.6664,  3.0370, -1.3275,  0.3423, -2.1316, -1.4005,  0.8540,\n",
            "         0.2753, -2.5059], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([7.1731,    inf, 1.6294, 5.9940, 4.3241, 6.7981, 6.0669, 3.8125, 4.3912,\n",
            "        7.1723], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[-3.7012,  8.8913,  1.1001, -2.5765,  0.6640, -2.1244, -1.6588,  0.6820,\n",
            "          1.0836, -2.1354]], grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[ -96.2690,  -93.0547,  -94.6280,  -90.1884,  -93.8622,  -79.2704,\n",
            "          -82.7055,  -85.5262, -107.9016]]) None\n",
            "best_l after optimization: 823.4061889648438 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.1600816249847412\n",
            "initial alpha-CROWN bounds: tensor([[ -96.2690,  -93.0547,  -94.6280,  -90.1884,  -93.8622,  -79.2704,\n",
            "          -82.7055,  -85.5262, -107.9016]], grad_fn=<AsStridedBackward>) None\n",
            "Sorted order for labels to attack: [2, 7, 4, 8, 3, 6, 5, 9, 0, 1]\n",
            "##### [2:2] Tested against 2 ######\n",
            "Initial alpha-CROWN with poor bound -107.9016342163086. We will run not branch and bound.\n",
            "Image 2 label 2 verification end, final lower bound -93.05474090576172, upper bound inf, time: 0.00040221214294433594\n",
            "2 -93.05474090576172\n",
            "Result: image 2 verification failure (with branch and bound).\n",
            "Wall time: 1.3872177600860596\n",
            "\n",
            "number of correctly classified examples: 3\n",
            "incorrectly classified idx (total 0): []\n",
            "attack success idx (total 0): []\n",
            "verification success idx (total 2): [0, 1]\n",
            "verification failure idx (total 1): [2]\n",
            "final verified acc: 66.66666666666666%[3]\n",
            "verifier is called on 3 examples.\n",
            "total verified: 2\n",
            "mean time [cnt:3] (excluding attack success): 0.14302794138590494\n",
            "______________________________________________________________________\n",
            "elapsed time: 6.182513952255249 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try configuration options"
      ],
      "metadata": {
        "id": "-3EjCYapS5Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "α,β-CROWN provides a number of different parameters that can be used for verification. An overview is given here: \n",
        "\n",
        "\n",
        "```\n",
        "general:\n",
        "  device: cuda  # Select device to run verifier, cpu or cuda (GPU).\n",
        "  seed: 100  # Random seed.\n",
        "  conv_mode: patches  # Convolution mode during bound propagation: \"patches\" mode (default) is very efficient, but may not support all architecture; \"matrix\" mode is slow but supports all architectures.\n",
        "  deterministic: false  # Run code in CUDA deterministic mode, which has slower performance but better reproducibility.\n",
        "  double_fp: false  # Use double precision floating point. GPUs with good double precision support are preferable (NVIDIA P100, V100, A100; AMD Radeon Instinc MI50, MI100).\n",
        "  loss_reduction_func: sum  # When batch size is not 1, this reduction function is applied to reduce the bounds into a single number (options are \"sum\" and \"min\").\n",
        "  mode: verified-acc  # Verify against all labels (\"verified-acc\" mode), or just the runnerup labels (\"runnerup\" mode), or using a specified label in dataset (\"speicify-target\" mode, only used for oval20). Mode can also be set as \"crown-only-verified-acc\" or \"alpha-crown-only-verified-acc\", which quickly computes the verified accuracy over the entire dataset via CROWN or alpha-CROWN.\n",
        "  complete_verifier: bab  # Complete verification verifier. \"bab\": branch and bound with beta-CROWN; \"mip\": mixed integer programming (MIP) formulation; \"bab-refine\": branch and bound with intermediate layer bounds computed by MIP.\n",
        "  enable_incomplete_verification: true  # Enable/Disable initial alpha-CROWN incomplete verification (this can save GPU memory when disabled).\n",
        "model:\n",
        "  path: null  # Load pretrained model from this specified path.\n",
        "  name: please_specify_model_name  # Name of model. Model must be defined in the load_verification_dataset() function in utils.py.\n",
        "data:\n",
        "  start: 0  # Start from the i-th property in specified dataset.\n",
        "  end: 10000  # End with the (i-1)-th property in the dataset.\n",
        "  num_outputs: 10  # Number of classes for classification problem.\n",
        "  mean: 0.0  # Mean vector used in data preprocessing.\n",
        "  std: 1.0  # Std vector used in data preprocessing.\n",
        "  pkl_path: null  # Load properties to verify from a .pkl file (only used for oval20 dataset).\n",
        "  dataset: CIFAR  # Dataset name. Dataset must be defined in utils.py.\n",
        "  data_idx_file: null  # A text file with a list of example IDs to run.\n",
        "specification:\n",
        "  type: lp  # Type of verification specification. \"lp\" = L_p norm, \"bounds\" = element-wise lower and upper bound provided by dataloader.\n",
        "  norm: .inf  # Lp-norm for epsilon perturbation in robustness verification (1, 2, inf).\n",
        "  epsilon: null  # Set perturbation size (Lp norm). If not set, a default value may be used based on dataset loader.\n",
        "solver:\n",
        "  alpha-crown:\n",
        "    lr_alpha: 0.1  # Learning rate for the optimizable parameter alpha in alpha-CROWN bound.\n",
        "    iteration: 100  # Number of iterations for alpha-CROWN incomplete verifier.\n",
        "    share_slopes: false  # Share some alpha variables to save memory at the cost of slightly looser bounds.\n",
        "    no_joint_opt: false  # Run alpha-CROWN bounds without joint optimization (only optimize alpha for the last layer bound).\n",
        "  beta-crown:\n",
        "    batch_size: 64  # Batch size in beta-CROWN (number of parallel splits).\n",
        "    lr_alpha: 0.01  # Learning rate for optimizing alpha during branch and bound.\n",
        "    lr_beta: 0.05  # Learning rate for optimizing beta during branch and bound.\n",
        "    lr_decay: 0.98  # Learning rate decay factor during optimization. Need to use a larger value like 0.99 or 0.995 when you increase the number of iterations.\n",
        "    optimizer: adam  # Optimizer used for alpha and beta optimization.\n",
        "    iteration: 50  # Number of iteration for optimizing alpha and beta during branch and bound.\n",
        "  mip:\n",
        "    parallel_solvers: null  # Number of multi-processes for mip solver. Each process computes a mip bound for an intermediate neuron. Default (None) is to auto detect the number of CPU cores (note that each process may use multiple threads, see the next option).\n",
        "    solver_threads: 1  # Number of threads for echo mip solver process (default is to use 1 thread for each solver process).\n",
        "    refine_neuron_timeout: 15  # MIP timeout threshold for improving each intermediate layer bound (in seconds).\n",
        "    refine_neuron_time_percentage: 0.8  # Percentage (x100%) of time used for improving all intermediate layer bounds using mip. Default to be 0.8*timeout.\n",
        "bab:\n",
        "  max_domains: 200000  # Max number of subproblems in branch and bound.\n",
        "  decision_thresh: 0  # Decision threshold of lower bounds. When lower bounds are greater than this value, verification is successful. Set to 0 for robustness verification.\n",
        "  timeout: 360  # Timeout (in second) for verifying one image/property.\n",
        "  branching:\n",
        "    method: kfsb  # Branching heuristic. babsr is fast but less accurate; fsb is slow but most accurate; kfsb is usualy a balance.\n",
        "    candidates: 3  # Number of candidates to consider when using fsb or kfsb. More leads to slower but better branching.\n",
        "    reduceop: min  # Reduction operation to compute branching scores from two sides of a branch (min or max). max can work better on some models.\n",
        "attack:\n",
        "  pgd_order: before  # Run PGD before/after incomplete verification, or skip it.\n",
        "  enable_mip_attack: false  # Use MIP (Gurobi) based attack if PGD cannot find a successful adversarial example.\n",
        "  pgd_steps: 100  # Steps of PGD attack.\n",
        "  pgd_restarts: 30  # Number of random PGD restarts.\n",
        "  pgd_early_stop: true  # Early stop PGD when an adversarial example is found.\n",
        "  pgd_lr_decay: 0.99  # Learning rate decay factor used in PGD attack.\n",
        "  pgd_alpha: auto  # Step size of PGD attack. Default (auto) is epsilon/4.\n",
        "  ```\n",
        "\n"
      ],
      "metadata": {
        "id": "qnX_9C1RS9wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's up to you! Try different configuration options and see how it influences the result! \\\\\n",
        "For example: What do you think changes with a changed value for Epsilon? "
      ],
      "metadata": {
        "id": "KV5doog1Tpr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/my_example_config.yaml\n",
        "general:\n",
        "  # device to run verifier\n",
        "  device: cpu \n",
        "  # Complete verification verifier. \n",
        "  # \"bab\": branch and bound with beta-CROWN; \n",
        "  # \"mip\": mixed integer programming (MIP) formulation; \n",
        "  # \"bab-refine\": branch and bound with intermediate layer bounds computed by MIP.\n",
        "  complete_verifier: bab\n",
        "model:\n",
        "  # name of the model (provided by library, see above)\n",
        "  name: mnist_6_100\n",
        "  # Load pretrained model from this specified path.\n",
        "  path: models/eran/mnist_6_100_nat.pth\n",
        "data:\n",
        "  # Dataset name. Dataset must be defined in utils.py.\n",
        "  dataset: MNIST_ERAN_UN\n",
        "  # Std vector used in data preprocessing.\n",
        "  std: [1.0]\n",
        "  # Mean vector used in data preprocessing.\n",
        "  mean: [0.0]\n",
        "specification:\n",
        "  # Set perturbation size (Lp norm). \n",
        "  # If not set, a default value may be used based on dataset loader.\n",
        "  epsilon: 1\n",
        "solver:\n",
        "  alpha-crown:\n",
        "    # Number of iterations for alpha-CROWN incomplete verifier.\n",
        "    iteration: 20  \n",
        "attack:\n",
        "  # Early stop PGD when an adversarial example is found.\n",
        "  pgd_early_stop: true   "
      ],
      "metadata": {
        "id": "9WLtxtU5Vjtr",
        "outputId": "310c9752-820a-4cd1-a08d-35a9eb44173b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting exp_configs/my_example_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./run.sh"
      ],
      "metadata": {
        "id": "S0kp0BGiVwHq",
        "outputId": "82ceb43e-7763-4f58-fd12-8dbd44d7264c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cpu\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: models/eran/mnist_6_100_nat.pth\n",
            "  name: mnist_6_100\n",
            "data:\n",
            "  start: 0\n",
            "  end: 3\n",
            "  num_outputs: 10\n",
            "  mean: [0.0]\n",
            "  std: [1.0]\n",
            "  pkl_path: null\n",
            "  dataset: MNIST_ERAN_UN\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: lp\n",
            "  norm: .inf\n",
            "  epsilon: 1\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 20\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 64\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 50\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 200000\n",
            "  decision_thresh: 0\n",
            "  timeout: 360\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: kfsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: before\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 30\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Sun Jun 12 09:56:13 2022 on 24e6990cabc8\n",
            "Sequential(\n",
            "  (0): Flatten()\n",
            "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (8): ReLU()\n",
            "  (9): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "/content/alpha-beta-CROWN/complete_verifier/utils.py:512: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)\n",
            "############################\n",
            "Sampled data loaded. No normalization used!\n",
            "Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])\n",
            "X range: tensor(1.) tensor(0.) tensor(0.1223)\n",
            "Note runnerup label is empty here!\n",
            "############################\n",
            "epsilon after preprocessing: tensor([[[[1.]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])\n",
            "Task length: 3\n",
            "saving results to Verified_ret_[mnist_6_100]_start=0_end=3_iter=50_b=64_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 7, correct label 7, image norm 72.3686294555664, logits tensor([-2.7419, -1.9715, -0.2067,  1.3752, -0.8952, -3.5481, -7.3186, 13.2074,\n",
            "        -4.4189,  3.8866], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 7, Tested against: ['all'] ######\n",
            "pgd early stop.\n",
            "pgd prediction: tensor([ 0.3085, -1.8811,  0.3734,  2.1301, -2.0824, -0.0710, -2.1629, -1.4916,\n",
            "         4.1524,  0.4288], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([-1.8002,  0.3894, -1.8650, -3.6218,  0.5907, -1.4206,  0.6713,     inf,\n",
            "        -5.6440, -1.9204], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd succeed, label 7, against label 8\n",
            "Result: image 0 attack success!\n",
            "Wall time: 0.03200960159301758\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 1 img ID: 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 2, correct label 2, image norm 113.13725280761719, logits tensor([-2.0595,  1.7575, 10.0782,  1.0748, -0.9482, -4.0839, -2.3911,  0.3436,\n",
            "        -0.9526, -4.9323], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 2, Tested against: ['all'] ######\n",
            "pgd early stop.\n",
            "pgd prediction: tensor([-0.7912, -1.3522, -1.0046,  3.7031, -1.9405,  1.9510, -2.3975, -0.6831,\n",
            "         1.2007,  1.6370], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([-0.2133,  0.3476,     inf, -4.7077,  0.9359, -2.9555,  1.3929, -0.3215,\n",
            "        -2.2053, -2.6415], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd succeed, label 2, against label 3\n",
            "Result: image 1 attack success!\n",
            "Wall time: 0.012104511260986328\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 2 img ID: 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 1, correct label 1, image norm 38.709800720214844, logits tensor([-3.7012,  8.8913,  1.1001, -2.5765,  0.6640, -2.1244, -1.6588,  0.6820,\n",
            "         1.0836, -2.1354], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 1, Tested against: ['all'] ######\n",
            "pgd early stop.\n",
            "pgd prediction: tensor([ 3.2676, -2.9754,  0.6701, -0.7514, -0.7260,  0.5890, -0.7794, -1.3032,\n",
            "         0.8847,  0.6816], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([-6.2431,     inf, -3.6456, -2.2241, -2.2495, -3.5645, -2.1961, -1.6722,\n",
            "        -3.8601, -3.6570], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd succeed, label 1, against label 0\n",
            "Result: image 2 attack success!\n",
            "Wall time: 0.01711130142211914\n",
            "\n",
            "number of correctly classified examples: 3\n",
            "incorrectly classified idx (total 0): []\n",
            "attack success idx (total 3): [0, 1, 2]\n",
            "attack_success rate: 1.0\n",
            "verification success idx (total 0): []\n",
            "verification failure idx (total 0): []\n",
            "final verified acc: 0.0%[3]\n",
            "verifier is called on 0 examples.\n",
            "total verified: 0\n",
            "mean time [cnt:0] (excluding attack success): nan\n",
            "mean time [cnt:3] (including attack success): 0.020383834838867188\n"
          ]
        }
      ]
    }
  ]
}