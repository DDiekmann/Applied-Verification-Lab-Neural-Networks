{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alpha-Beta-Crown.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPPQmEa5u0LsaNzD1PnGJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorials/Alpha_Beta_Crown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# α,β-CROWN ML-Verification Tutorial"
      ],
      "metadata": {
        "id": "aYgyJk_R5281"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This tutorial shows the robustness verification of a neural network trained on the MNIST dataset with use of α,β-CROWN.*"
      ],
      "metadata": {
        "id": "rz2u1ieA8NBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**α,β-CROWN**\n",
        "α,β-CROWN is an open-source neural network verifier. The code can be found on [their website](https://github.com/huanzhang12/alpha-beta-CROWN). "
      ],
      "metadata": {
        "id": "sOpfUe1C8xBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we will first go through the installation of α,β-CROWN and train our own network. This network is to be verified later in the tutorial. Therefore, the verfication must be configured first. "
      ],
      "metadata": {
        "id": "LfF1cvIX70Kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "n0Quth1B5Wbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This installation is based on another [tutorial](https://colab.research.google.com/drive/1mJTOmq2qHxMycHUzBepBN47QWcxda3ov#scrollTo=Y0toepwVIFTG). "
      ],
      "metadata": {
        "id": "Y8neFi6n5da9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will set up our miniconda environment. "
      ],
      "metadata": {
        "id": "A2WnHH7D8QdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "%env PYTHONPATH=\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "JV2OjHuS32CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python in version 3.7 is installed into the environment. "
      ],
      "metadata": {
        "id": "mu9YAbJS8WHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "conda install --channel defaults conda python=3.7 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "id": "2r20b2Wg36Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import sys\n",
        "sys.path\n",
        "!ls /usr/local/lib/python3.7/dist-packages\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ],
      "metadata": {
        "id": "iVia-nO53826"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use the library, we have to clone the corresponding git-repository."
      ],
      "metadata": {
        "id": "clVssA098eAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/huanzhang12/alpha-beta-CROWN.git"
      ],
      "metadata": {
        "id": "R3m60hqD3_sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The environment is created. "
      ],
      "metadata": {
        "id": "3mZvUGSX8rAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "# Remove the old environment, if necessary.\n",
        "conda env remove --name alpha-beta-crown\n",
        "conda env create -f alpha-beta-CROWN/complete_verifier/environment.yml  # install all dependents into the alpha-beta-crown environment"
      ],
      "metadata": {
        "id": "UThlPEBk4Ckw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd alpha-beta-CROWN/complete_verifier/"
      ],
      "metadata": {
        "id": "ssVpobxp4GQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As explained on [the website of the α,β-project](https://github.com/huanzhang12/alpha-beta-CROWN), it is nessasary to create a configuration file in order to load the data. "
      ],
      "metadata": {
        "id": "pgl_rkFY8uvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training of own network"
      ],
      "metadata": {
        "id": "BOZc8RfBMKdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we create our own ML-model, calles my_model. This model is written into the file my_model.py. \n",
        "The network consists of three linear layers with ReLU activation function. \n",
        "Later on, we can use this model in our verification.  "
      ],
      "metadata": {
        "id": "R5jRc2zQ9QAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!wget --no-cache --backups=1 {'https://raw.githubusercontent.com/DDiekmann/Applied-Verification-Lab-Neural-Networks/main/lib/mnist_trainer.py'}"
      ],
      "metadata": {
        "id": "0m0ZKY_Y1S6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_model.py\n",
        "import mnist_trainer\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def my_model(input_dim, output_dim, number_of_neurons):\n",
        "    \"\"\"Simple network with three linear layers and a ReLU activation function.\"\"\"\n",
        "    model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, number_of_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(number_of_neurons, number_of_neurons),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(number_of_neurons, output_dim),\n",
        "        )\n",
        "    return model"
      ],
      "metadata": {
        "id": "k3BZQ9701T01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure verification"
      ],
      "metadata": {
        "id": "LK3JuZPt4-mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have created our model, but this model needs to be verified in the next step. Therefore, we create a file called my_config.yaml which configures parameters for verification. "
      ],
      "metadata": {
        "id": "Z8U-YzCS9yAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/my_config.yaml\n",
        "# This is an example configuration file that contains most useful parameter settings.\n",
        "general:\n",
        "  mode: verified-acc  # Compute verified accuracy.\n",
        "model:\n",
        "  # Use my_model() model in \"my_model.py\".\n",
        "  name: Customized(\"my_model\", \"my_model\", input_dim=10, output_dim=12, number_of_neurons=20)\n",
        "  path: models/cifar10_resnet/resnet2b.pth  # Path to PyTorch checkpoint.\n",
        "data:\n",
        "  dataset: MNIST_ERAN_UN # Dataset name.\n",
        "  std: [1.0] # Std for normalization.\n",
        "  mean: [0.0] # Mean for normalization.\n",
        "specification:\n",
        "  norm: .inf  # Linf norm (can also be 2 or 1).\n",
        "  epsilon: 0.00784313725490196  # epsilon=2./255.\n",
        "attack:  # Currently attack is only implemented for Linf norm.\n",
        "  pgd_steps: 100  # Increase for a stronger attack. A PGD attack will be used before verification to filter on non-robust data examples.\n",
        "  pgd_restarts: 30  # Increase for a stronger attack.\n",
        "solver:\n",
        "  alpha-crown:\n",
        "    iteration: 100   # Number of iterations for alpha-CROWN optimization. Alpha-CROWN is used to compute all intermediate layer bounds before branch and bound starts.\n",
        "    lr_alpha: 0.1    # Learning rate for alpha in alpha-CROWN. The default (0.1) is typically ok.\n",
        "  beta-crown:\n",
        "    batch_size: 2048  # Number of subdomains to compute in parallel in beta-CROWN. Increase if you run out of memory.\n",
        "    lr_alpha: 0.01  # Learning rate for optimizing the alpha parameters, the default (0.01) is typically ok, but you can try to tune this parameter to get better lower bound. \n",
        "    lr_beta: 0.05  # Learning rate for optimizing the beta parameters, the default (0.05) is typically ok, but you can try to tune this parameter to get better lower bound.\n",
        "    iteration: 20  # Number of iterations for beta-CROWN optimization. 20 is often sufficient, 50 or 100 can also be used.\n",
        "bab:\n",
        "  timeout: 120  # Timeout threshold for branch and bound. Increase for verifying more points.\n",
        "  branching:  # Parameters for branching heuristics.\n",
        "    reduceop: min  # Reduction function for the branching heuristic scores, min or max. Using max can be better on some models.\n",
        "    method: kfsb  # babsr is fast but less accurate; fsb is slow but most accurate; kfsb is usualy a balance.\n",
        "    candidates: 3  # Number of candidates to consider in fsb and kfsb. More leads to slower but better branching. 3 is typically good enough."
      ],
      "metadata": {
        "id": "Z7fKFQQV5CmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verification of own network with α,β-CROWN"
      ],
      "metadata": {
        "id": "ivgGYPZUMShY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we only have to run our verification. "
      ],
      "metadata": {
        "id": "y-uwErjZ-T4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we activate our environment."
      ],
      "metadata": {
        "id": "7mM9hCLY-bQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%source activate alpha-beta-crown"
      ],
      "metadata": {
        "id": "cLLJZgqk-ecT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we call the robustness_verifier on our configured yaml-file. "
      ],
      "metadata": {
        "id": "tGVieeo--k2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%python robustness_verifier.py --config exp_configs/my_config.yaml --start 3 --end 4"
      ],
      "metadata": {
        "id": "8qAllf8X-rhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We finish by deactivating the environment. "
      ],
      "metadata": {
        "id": "7Ukm4kx0-t2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%conda deactivate"
      ],
      "metadata": {
        "id": "f3uxJyk57EyU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}