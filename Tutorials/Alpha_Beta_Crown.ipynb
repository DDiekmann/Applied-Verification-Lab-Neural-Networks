{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alpha-Beta-Crown.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDiekmann/Applied-Verification-Lab-Neural-Networks/blob/main/Tutorials/Alpha_Beta_Crown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial for α,β-CROWN Robustness Verification \n",
        "\n"
      ],
      "metadata": {
        "id": "aYgyJk_R5281"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*This tutorial shows the robustness verification of a neural network trained on \n",
        "the MNIST dataset with use of α,β-CROWN.*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rz2u1ieA8NBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**α,β-CROWN**\n",
        "α,β-CROWN is an open-source neural network verifier. The code can be found on [their website](https://github.com/huanzhang12/alpha-beta-CROWN). "
      ],
      "metadata": {
        "id": "sOpfUe1C8xBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we will first go through the installation of α,β-CROWN and train our own network. This network is to be verified later in the tutorial. Therefore, the verfication must be configured first. "
      ],
      "metadata": {
        "id": "LfF1cvIX70Kp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "id": "n0Quth1B5Wbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This installation is based on another [tutorial](https://colab.research.google.com/drive/1mJTOmq2qHxMycHUzBepBN47QWcxda3ov#scrollTo=Y0toepwVIFTG). "
      ],
      "metadata": {
        "id": "Y8neFi6n5da9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will set up our miniconda environment. "
      ],
      "metadata": {
        "id": "A2WnHH7D8QdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "%env PYTHONPATH=\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "JV2OjHuS32CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python in version 3.7 is installed into the environment. "
      ],
      "metadata": {
        "id": "mu9YAbJS8WHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "conda install --channel defaults conda python=3.7 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "id": "2r20b2Wg36Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import sys\n",
        "sys.path\n",
        "!ls /usr/local/lib/python3.7/dist-packages\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ],
      "metadata": {
        "id": "iVia-nO53826"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use the library, we have to clone the corresponding git-repository."
      ],
      "metadata": {
        "id": "clVssA098eAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Uninstall existing Pytorch on Colab, which might be incompatible or buggy.\n",
        "# Note that the alpha beta crown library is tested on Pytorch 1.8.2 LTS, and other versions might be incompatible.(according to reference tutorial)\n",
        "# !pip uninstall --yes torch torchvision torchaudio torchtext\n",
        "!git clone https://github.com/huanzhang12/alpha-beta-CROWN.git"
      ],
      "metadata": {
        "id": "R3m60hqD3_sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The environment is created. "
      ],
      "metadata": {
        "id": "3mZvUGSX8rAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%%bash\n",
        "# Remove the old environment, if necessary.\n",
        "conda env remove --name alpha-beta-crown\n",
        "conda env create -f alpha-beta-CROWN/complete_verifier/environment.yml  # install all dependents into the alpha-beta-crown environment"
      ],
      "metadata": {
        "id": "UThlPEBk4Ckw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd alpha-beta-CROWN/complete_verifier/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssVpobxp4GQa",
        "outputId": "af71efda-d547-4e0a-86f7-3a240f09275b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alpha-beta-CROWN/complete_verifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As explained on [the website of the α,β-project](https://github.com/huanzhang12/alpha-beta-CROWN), it is nessasary to create a configuration file in order to load the data. "
      ],
      "metadata": {
        "id": "pgl_rkFY8uvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure verification"
      ],
      "metadata": {
        "id": "LK3JuZPt4-mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to verifiy a model. Therefore, we create a file called my_example_config.yaml which configures parameters for verification. \n",
        "The model is defined as followed: \n",
        "\n",
        "\n",
        "```\n",
        "def mnist_6_100():\n",
        "    model = nn.Sequential(\n",
        "        Flatten(),\n",
        "        nn.Linear(784,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 10)\n",
        "    )\n",
        "    return model\n",
        "```\n",
        "\n",
        "It contains six linear layers and uses the ReLU activation function."
      ],
      "metadata": {
        "id": "Z8U-YzCS9yAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with a very basic configuration file, which means that most parameters are set to default."
      ],
      "metadata": {
        "id": "fekbamk9Dm82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/my_example_config.yaml\n",
        "general:\n",
        "  # device to run verifier\n",
        "  device: cpu \n",
        "  # Complete verification verifier. \n",
        "  # \"bab\": branch and bound with beta-CROWN; \n",
        "  # \"mip\": mixed integer programming (MIP) formulation; \n",
        "  # \"bab-refine\": branch and bound with intermediate layer bounds computed by MIP.\n",
        "  complete_verifier: bab\n",
        "model:\n",
        "  # name of the model (provided by library, see above)\n",
        "  name: mnist_6_100\n",
        "  # Load pretrained model from this specified path.\n",
        "  path: models/eran/mnist_6_100_nat.pth\n",
        "data:\n",
        "  # Dataset name. Dataset must be defined in utils.py.\n",
        "  dataset: MNIST_ERAN_UN\n",
        "  # Std vector used in data preprocessing.\n",
        "  std: [1.0]\n",
        "  # Mean vector used in data preprocessing.\n",
        "  mean: [0.0]\n",
        "specification:\n",
        "  # Set perturbation size (Lp norm). \n",
        "  # If not set, a default value may be used based on dataset loader.\n",
        "  epsilon: 0.026\n",
        "solver:\n",
        "  alpha-crown:\n",
        "    # Number of iterations for alpha-CROWN incomplete verifier.\n",
        "    iteration: 10\n",
        "attack:\n",
        "  # Early stop PGD when an adversarial example is found.\n",
        "  pgd_early_stop: true  "
      ],
      "metadata": {
        "id": "s1E0j7dbVvGg",
        "outputId": "5c1caa05-9411-47dd-8887-c5fb49ae2113",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting exp_configs/my_example_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verification of network with α,β-CROWN"
      ],
      "metadata": {
        "id": "ivgGYPZUMShY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we only have to run our verification. "
      ],
      "metadata": {
        "id": "y-uwErjZ-T4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we activate our environment.\n",
        "Then we call the robustness_verifier on our configured yaml-file. The robustness_verifier is a class provided by the α,β-CROWN-library for Lp norm robustness verification and is often used to certify the robustness of a neural network. \n",
        "By setting start to 0 and end to 3, we indicate that only images 0 to 3 from the dataset should be verified. This is done for performance reasons. \n",
        "We finish by deactivating the environment.\n"
      ],
      "metadata": {
        "id": "7mM9hCLY-bQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run.sh\n",
        "\n",
        "source activate alpha-beta-crown\n",
        "python robustness_verifier.py --config exp_configs/my_example_config.yaml --start 0 --end 3\n",
        "conda deactivate"
      ],
      "metadata": {
        "id": "1wOCa05uMept",
        "outputId": "163855ee-6e1f-4d49-cc32-3174acc7299b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 777 run.sh\n",
        "!./run.sh"
      ],
      "metadata": {
        "id": "di2IgirTVxO0",
        "outputId": "9ef2f6f3-e6d1-48f1-d8a9-19aeccfab5a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cpu\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: models/eran/mnist_6_100_nat.pth\n",
            "  name: mnist_6_100\n",
            "data:\n",
            "  start: 0\n",
            "  end: 3\n",
            "  num_outputs: 10\n",
            "  mean: [0.0]\n",
            "  std: [1.0]\n",
            "  pkl_path: null\n",
            "  dataset: MNIST_ERAN_UN\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: lp\n",
            "  norm: .inf\n",
            "  epsilon: 0.026\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 1\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 64\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 50\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 200000\n",
            "  decision_thresh: 0\n",
            "  timeout: 360\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: kfsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: before\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 30\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Wed Jun 15 10:23:29 2022 on 767c55996023\n",
            "Sequential(\n",
            "  (0): Flatten()\n",
            "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (8): ReLU()\n",
            "  (9): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "/content/alpha-beta-CROWN/complete_verifier/utils.py:512: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)\n",
            "############################\n",
            "Sampled data loaded. No normalization used!\n",
            "Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])\n",
            "X range: tensor(1.) tensor(0.) tensor(0.1223)\n",
            "Note runnerup label is empty here!\n",
            "############################\n",
            "epsilon after preprocessing: tensor([[[[0.0260]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])\n",
            "Task length: 3\n",
            "saving results to Verified_ret_[mnist_6_100]_start=0_end=3_iter=50_b=64_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 7, correct label 7, image norm 72.3686294555664, logits tensor([-2.7419, -1.9715, -0.2067,  1.3752, -0.8952, -3.5481, -7.3186, 13.2074,\n",
            "        -4.4189,  3.8866], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 7, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([-2.3157, -1.4768, -0.3271,  1.2411, -0.7472, -2.6581, -5.9633, 10.4310,\n",
            "        -3.2570,  3.3437], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([12.7467, 11.9078, 10.7581,  9.1899, 11.1781, 13.0891, 16.3943,     inf,\n",
            "        13.6879,  7.0872], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[-2.7419, -1.9715, -0.2067,  1.3752, -0.8952, -3.5481, -7.3186, 13.2074,\n",
            "         -4.4189,  3.8866]], grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[4.7498, 3.7544, 2.8216, 1.2226, 5.1403, 5.2825, 7.9722, 4.6015, 0.9006]]) None\n",
            "verified with init bound!\n",
            "Result: image 0 verification success (with incomplete verifier)!\n",
            "Wall time: 0.9340779781341553\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 1 img ID: 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 2, correct label 2, image norm 113.13725280761719, logits tensor([-2.0595,  1.7575, 10.0782,  1.0748, -0.9482, -4.0839, -2.3911,  0.3436,\n",
            "        -0.9526, -4.9323], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 2, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([-2.2444,  1.8947,  8.5624,  1.2637, -1.0060, -3.4432, -2.2272,  0.5084,\n",
            "        -0.6859, -4.3616], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([10.8067,  6.6677,     inf,  7.2986,  9.5684, 12.0056, 10.7896,  8.0539,\n",
            "         9.2483, 12.9240], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[-2.0595,  1.7575, 10.0782,  1.0748, -0.9482, -4.0839, -2.3911,  0.3436,\n",
            "         -0.9526, -4.9323]], grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[0.6301, 0.1344, 0.4976, 2.1355, 2.5526, 2.1028, 1.8815, 1.7729, 3.6696]]) None\n",
            "verified with init bound!\n",
            "Result: image 1 verification success (with incomplete verifier)!\n",
            "Wall time: 0.8993825912475586\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 2 img ID: 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 1, correct label 1, image norm 38.709800720214844, logits tensor([-3.7012,  8.8913,  1.1001, -2.5765,  0.6640, -2.1244, -1.6588,  0.6820,\n",
            "         1.0836, -2.1354], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 1, Tested against: ['all'] ######\n",
            "pgd prediction: tensor([-2.5066,  4.6664,  3.0370, -1.3275,  0.3423, -2.1316, -1.4005,  0.8540,\n",
            "         0.2753, -2.5059], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([7.1731,    inf, 1.6294, 5.9940, 4.3241, 6.7981, 6.0669, 3.8125, 4.3912,\n",
            "        7.1723], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd failed\n",
            "Model prediction is: tensor([[-3.7012,  8.8913,  1.1001, -2.5765,  0.6640, -2.1244, -1.6588,  0.6820,\n",
            "          1.0836, -2.1354]], grad_fn=<AddBackward0>)\n",
            "alpha-CROWN optimizable variables initialized.\n",
            "initial CROWN bounds: tensor([[ -96.2690,  -93.0547,  -94.6280,  -90.1884,  -93.8622,  -79.2704,\n",
            "          -82.7055,  -85.5262, -107.9016]]) None\n",
            "best_l after optimization: 823.4061889648438 with beta sum per layer: []\n",
            "alpha/beta optimization time: 0.13439297676086426\n",
            "initial alpha-CROWN bounds: tensor([[ -96.2690,  -93.0547,  -94.6280,  -90.1884,  -93.8622,  -79.2704,\n",
            "          -82.7055,  -85.5262, -107.9016]], grad_fn=<AsStridedBackward>) None\n",
            "Sorted order for labels to attack: [2, 7, 4, 8, 3, 6, 5, 9, 0, 1]\n",
            "##### [2:2] Tested against 2 ######\n",
            "Initial alpha-CROWN with poor bound -107.9016342163086. We will run not branch and bound.\n",
            "Image 2 label 2 verification end, final lower bound -93.05474090576172, upper bound inf, time: 0.00030303001403808594\n",
            "2 -93.05474090576172\n",
            "Result: image 2 verification failure (with branch and bound).\n",
            "Wall time: 1.0694851875305176\n",
            "\n",
            "number of correctly classified examples: 3\n",
            "incorrectly classified idx (total 0): []\n",
            "attack success idx (total 0): []\n",
            "verification success idx (total 2): [0, 1]\n",
            "verification failure idx (total 1): [2]\n",
            "final verified acc: 66.66666666666666%[3]\n",
            "verifier is called on 3 examples.\n",
            "total verified: 2\n",
            "mean time [cnt:3] (excluding attack success): 0.12752604484558105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try configuration options"
      ],
      "metadata": {
        "id": "-3EjCYapS5Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "α,β-CROWN provides a number of different parameters that can be used for verification. An overview is given here: \n",
        "\n",
        "\n",
        "```\n",
        "general:\n",
        "  device: cuda  # Select device to run verifier, cpu or cuda (GPU).\n",
        "  seed: 100  # Random seed.\n",
        "  conv_mode: patches  # Convolution mode during bound propagation: \"patches\" mode (default) is very efficient, but may not support all architecture; \"matrix\" mode is slow but supports all architectures.\n",
        "  deterministic: false  # Run code in CUDA deterministic mode, which has slower performance but better reproducibility.\n",
        "  double_fp: false  # Use double precision floating point. GPUs with good double precision support are preferable (NVIDIA P100, V100, A100; AMD Radeon Instinc MI50, MI100).\n",
        "  loss_reduction_func: sum  # When batch size is not 1, this reduction function is applied to reduce the bounds into a single number (options are \"sum\" and \"min\").\n",
        "  mode: verified-acc  # Verify against all labels (\"verified-acc\" mode), or just the runnerup labels (\"runnerup\" mode), or using a specified label in dataset (\"speicify-target\" mode, only used for oval20). Mode can also be set as \"crown-only-verified-acc\" or \"alpha-crown-only-verified-acc\", which quickly computes the verified accuracy over the entire dataset via CROWN or alpha-CROWN.\n",
        "  complete_verifier: bab  # Complete verification verifier. \"bab\": branch and bound with beta-CROWN; \"mip\": mixed integer programming (MIP) formulation; \"bab-refine\": branch and bound with intermediate layer bounds computed by MIP.\n",
        "  enable_incomplete_verification: true  # Enable/Disable initial alpha-CROWN incomplete verification (this can save GPU memory when disabled).\n",
        "model:\n",
        "  path: null  # Load pretrained model from this specified path.\n",
        "  name: please_specify_model_name  # Name of model. Model must be defined in the load_verification_dataset() function in utils.py.\n",
        "data:\n",
        "  start: 0  # Start from the i-th property in specified dataset.\n",
        "  end: 10000  # End with the (i-1)-th property in the dataset.\n",
        "  num_outputs: 10  # Number of classes for classification problem.\n",
        "  mean: 0.0  # Mean vector used in data preprocessing.\n",
        "  std: 1.0  # Std vector used in data preprocessing.\n",
        "  pkl_path: null  # Load properties to verify from a .pkl file (only used for oval20 dataset).\n",
        "  dataset: CIFAR  # Dataset name. Dataset must be defined in utils.py.\n",
        "  data_idx_file: null  # A text file with a list of example IDs to run.\n",
        "specification:\n",
        "  type: lp  # Type of verification specification. \"lp\" = L_p norm, \"bounds\" = element-wise lower and upper bound provided by dataloader.\n",
        "  norm: .inf  # Lp-norm for epsilon perturbation in robustness verification (1, 2, inf).\n",
        "  epsilon: null  # Set perturbation size (Lp norm). If not set, a default value may be used based on dataset loader.\n",
        "solver:\n",
        "  alpha-crown:\n",
        "    lr_alpha: 0.1  # Learning rate for the optimizable parameter alpha in alpha-CROWN bound.\n",
        "    iteration: 100  # Number of iterations for alpha-CROWN incomplete verifier.\n",
        "    share_slopes: false  # Share some alpha variables to save memory at the cost of slightly looser bounds.\n",
        "    no_joint_opt: false  # Run alpha-CROWN bounds without joint optimization (only optimize alpha for the last layer bound).\n",
        "  beta-crown:\n",
        "    batch_size: 64  # Batch size in beta-CROWN (number of parallel splits).\n",
        "    lr_alpha: 0.01  # Learning rate for optimizing alpha during branch and bound.\n",
        "    lr_beta: 0.05  # Learning rate for optimizing beta during branch and bound.\n",
        "    lr_decay: 0.98  # Learning rate decay factor during optimization. Need to use a larger value like 0.99 or 0.995 when you increase the number of iterations.\n",
        "    optimizer: adam  # Optimizer used for alpha and beta optimization.\n",
        "    iteration: 50  # Number of iteration for optimizing alpha and beta during branch and bound.\n",
        "  mip:\n",
        "    parallel_solvers: null  # Number of multi-processes for mip solver. Each process computes a mip bound for an intermediate neuron. Default (None) is to auto detect the number of CPU cores (note that each process may use multiple threads, see the next option).\n",
        "    solver_threads: 1  # Number of threads for echo mip solver process (default is to use 1 thread for each solver process).\n",
        "    refine_neuron_timeout: 15  # MIP timeout threshold for improving each intermediate layer bound (in seconds).\n",
        "    refine_neuron_time_percentage: 0.8  # Percentage (x100%) of time used for improving all intermediate layer bounds using mip. Default to be 0.8*timeout.\n",
        "bab:\n",
        "  max_domains: 200000  # Max number of subproblems in branch and bound.\n",
        "  decision_thresh: 0  # Decision threshold of lower bounds. When lower bounds are greater than this value, verification is successful. Set to 0 for robustness verification.\n",
        "  timeout: 360  # Timeout (in second) for verifying one image/property.\n",
        "  branching:\n",
        "    method: kfsb  # Branching heuristic. babsr is fast but less accurate; fsb is slow but most accurate; kfsb is usualy a balance.\n",
        "    candidates: 3  # Number of candidates to consider when using fsb or kfsb. More leads to slower but better branching.\n",
        "    reduceop: min  # Reduction operation to compute branching scores from two sides of a branch (min or max). max can work better on some models.\n",
        "attack:\n",
        "  pgd_order: before  # Run PGD before/after incomplete verification, or skip it.\n",
        "  enable_mip_attack: false  # Use MIP (Gurobi) based attack if PGD cannot find a successful adversarial example.\n",
        "  pgd_steps: 100  # Steps of PGD attack.\n",
        "  pgd_restarts: 30  # Number of random PGD restarts.\n",
        "  pgd_early_stop: true  # Early stop PGD when an adversarial example is found.\n",
        "  pgd_lr_decay: 0.99  # Learning rate decay factor used in PGD attack.\n",
        "  pgd_alpha: auto  # Step size of PGD attack. Default (auto) is epsilon/4.\n",
        "  ```\n",
        "\n"
      ],
      "metadata": {
        "id": "qnX_9C1RS9wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Try out another epsilon\n",
        "Now it's up to you! Try different configuration options and see how it influences the result! \\\\\n",
        "For example: What do you think changes with a changed value for Epsilon? \n",
        "(Expand the cell in order to see the resulting configuration file)"
      ],
      "metadata": {
        "id": "KV5doog1Tpr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/my_example_config.yaml\n",
        "general:\n",
        "  # device to run verifier\n",
        "  device: cpu \n",
        "  # Complete verification verifier. \n",
        "  # \"bab\": branch and bound with beta-CROWN; \n",
        "  # \"mip\": mixed integer programming (MIP) formulation; \n",
        "  # \"bab-refine\": branch and bound with intermediate layer bounds computed by MIP.\n",
        "  complete_verifier: bab\n",
        "model:\n",
        "  # name of the model (provided by library, see above)\n",
        "  name: mnist_6_100\n",
        "  # Load pretrained model from this specified path.\n",
        "  path: models/eran/mnist_6_100_nat.pth\n",
        "data:\n",
        "  # Dataset name. Dataset must be defined in utils.py.\n",
        "  dataset: MNIST_ERAN_UN\n",
        "  # Std vector used in data preprocessing.\n",
        "  std: [1.0]\n",
        "  # Mean vector used in data preprocessing.\n",
        "  mean: [0.0]\n",
        "specification:\n",
        "  # Set perturbation size (Lp norm). \n",
        "  # If not set, a default value may be used based on dataset loader.\n",
        "  epsilon: 1\n",
        "solver:\n",
        "  alpha-crown:\n",
        "    # Number of iterations for alpha-CROWN incomplete verifier.\n",
        "    iteration: 10  \n",
        "attack:\n",
        "  # Early stop PGD when an adversarial example is found.\n",
        "  pgd_early_stop: true   "
      ],
      "metadata": {
        "id": "9WLtxtU5Vjtr",
        "outputId": "e03b2c82-63a4-48cd-9fd6-b2c14dea5b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting exp_configs/my_example_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run your new configuration file\n",
        "So, what do you expect with your new epsilon? "
      ],
      "metadata": {
        "id": "xCvUzLBQxwAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./run.sh"
      ],
      "metadata": {
        "id": "S0kp0BGiVwHq",
        "outputId": "4b0944ee-fc96-4b35-c708-83f16a45f427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cpu\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: models/eran/mnist_6_100_nat.pth\n",
            "  name: mnist_6_100\n",
            "data:\n",
            "  start: 0\n",
            "  end: 3\n",
            "  num_outputs: 10\n",
            "  mean: [0.0]\n",
            "  std: [1.0]\n",
            "  pkl_path: null\n",
            "  dataset: MNIST_ERAN_UN\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: lp\n",
            "  norm: .inf\n",
            "  epsilon: 1\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 20\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 64\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 50\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 200000\n",
            "  decision_thresh: 0\n",
            "  timeout: 360\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: kfsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: before\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 30\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Wed Jun 15 10:22:22 2022 on 767c55996023\n",
            "Sequential(\n",
            "  (0): Flatten()\n",
            "  (1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (8): ReLU()\n",
            "  (9): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "/content/alpha-beta-CROWN/complete_verifier/utils.py:512: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)\n",
            "############################\n",
            "Sampled data loaded. No normalization used!\n",
            "Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])\n",
            "X range: tensor(1.) tensor(0.) tensor(0.1223)\n",
            "Note runnerup label is empty here!\n",
            "############################\n",
            "epsilon after preprocessing: tensor([[[[1.]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])\n",
            "Task length: 3\n",
            "saving results to Verified_ret_[mnist_6_100]_start=0_end=3_iter=50_b=64_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 7, correct label 7, image norm 72.3686294555664, logits tensor([-2.7419, -1.9715, -0.2067,  1.3752, -0.8952, -3.5481, -7.3186, 13.2074,\n",
            "        -4.4189,  3.8866], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 7, Tested against: ['all'] ######\n",
            "pgd early stop.\n",
            "pgd prediction: tensor([ 0.3085, -1.8811,  0.3734,  2.1301, -2.0824, -0.0710, -2.1629, -1.4916,\n",
            "         4.1524,  0.4288], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([-1.8002,  0.3894, -1.8650, -3.6218,  0.5907, -1.4206,  0.6713,     inf,\n",
            "        -5.6440, -1.9204], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd succeed, label 7, against label 8\n",
            "Result: image 0 attack success!\n",
            "Wall time: 0.025882959365844727\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 1 img ID: 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 2, correct label 2, image norm 113.13725280761719, logits tensor([-2.0595,  1.7575, 10.0782,  1.0748, -0.9482, -4.0839, -2.3911,  0.3436,\n",
            "        -0.9526, -4.9323], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 2, Tested against: ['all'] ######\n",
            "pgd early stop.\n",
            "pgd prediction: tensor([-0.7912, -1.3522, -1.0046,  3.7031, -1.9405,  1.9510, -2.3975, -0.6831,\n",
            "         1.2007,  1.6370], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([-0.2133,  0.3476,     inf, -4.7077,  0.9359, -2.9555,  1.3929, -0.3215,\n",
            "        -2.2053, -2.6415], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd succeed, label 2, against label 3\n",
            "Result: image 1 attack success!\n",
            "Wall time: 0.012257099151611328\n",
            "\n",
            " %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 2 img ID: 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "predicted label 1, correct label 1, image norm 38.709800720214844, logits tensor([-3.7012,  8.8913,  1.1001, -2.5765,  0.6640, -2.1244, -1.6588,  0.6820,\n",
            "         1.0836, -2.1354], grad_fn=<SelectBackward>)\n",
            "##### PGD attack: True label: 1, Tested against: ['all'] ######\n",
            "pgd early stop.\n",
            "pgd prediction: tensor([ 3.2676, -2.9754,  0.6701, -0.7514, -0.7260,  0.5890, -0.7794, -1.3032,\n",
            "         0.8847,  0.6816], grad_fn=<SqueezeBackward1>)\n",
            "attack margin tensor([-6.2431,     inf, -3.6456, -2.2241, -2.2495, -3.5645, -2.1961, -1.6722,\n",
            "        -3.8601, -3.6570], grad_fn=<RsubBackward1>)\n",
            "untargeted pgd succeed, label 1, against label 0\n",
            "Result: image 2 attack success!\n",
            "Wall time: 0.012015581130981445\n",
            "\n",
            "number of correctly classified examples: 3\n",
            "incorrectly classified idx (total 0): []\n",
            "attack success idx (total 3): [0, 1, 2]\n",
            "attack_success rate: 1.0\n",
            "verification success idx (total 0): []\n",
            "verification failure idx (total 0): []\n",
            "final verified acc: 0.0%[3]\n",
            "verifier is called on 0 examples.\n",
            "total verified: 0\n",
            "mean time [cnt:0] (excluding attack success): nan\n",
            "mean time [cnt:3] (including attack success): 0.0166933536529541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the larger epsilon makes the attack much more likely to succeed. This is because a larger epsilon allows a greater change in the original image."
      ],
      "metadata": {
        "id": "tzSYWTR4x5yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Different norms\n",
        "α,β-CROWN offers the possibility to use different norms for the verification of the networks. \n",
        "###L1 Norm\n",
        "The L1 norm is also known as Manhattan Distance or Taxicab norm. The L1 norm for a vector $x$ is calculated by $||x||_1$=  $\\sum\\nolimits_{i=1}^n |x_i|^2$. In the case of the plot below it is $||a||_1$=  $|a_1| + |a_2|$ = 3 + 4 = 7. \n",
        "\n"
      ],
      "metadata": {
        "id": "phDUvqNO-Ebl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([3], [4], 'ro')\n",
        "plt.axis([0, 4, 0, 5])\n",
        "plt.annotate('$a$ with $a_1=3$ and $a_2=4$', xy=(3, 4), xytext=(2, 3),\n",
        "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
        "             )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SNLodaEtGLMh",
        "outputId": "2738811c-9c08-4b8a-89f9-fd7aaa025f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###L2 Norm\n",
        "The L2 norm is also known as the Euclidean norm. \n",
        "###L3 Norm"
      ],
      "metadata": {
        "id": "cF4O13mvG_Rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customization on custom model and data\n",
        "Alpha beta crown can be easily be run on customized models and data. \n",
        "We will use it on a custom model and the cifar10 dataset. \n",
        "it can as well support other arbitrary datasets. \n"
      ],
      "metadata": {
        "id": "yN28TqGo66qX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile custom_model_data.py\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import arguments\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def simple_conv_model(in_channel, out_dim):\n",
        "    \"\"\"Simple Convolutional Neural Network model.\"\"\"\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, 16, 4, stride=2, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 32, 4, stride=2, padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(32*6*6,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, out_dim)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def cifar10_dataloader(eps, use_bounds=False):\n",
        "    \"\"\"Example dataloader. For MNIST and CIFAR you can actually use existing ones in utils.py.\"\"\"\n",
        "    assert eps is not None\n",
        "    database_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'datasets')\n",
        "    # You can access the mean and std stored in config file.\n",
        "    mean = torch.tensor(arguments.Config[\"data\"][\"mean\"])\n",
        "    std = torch.tensor(arguments.Config[\"data\"][\"std\"])\n",
        "    normalize = transforms.Normalize(mean=mean, std=std)\n",
        "    test_data = datasets.CIFAR10(database_path, train=False, download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
        "    # Load entire dataset.\n",
        "    testloader = torch.utils.data.DataLoader(test_data, batch_size=10000, shuffle=False, num_workers=4)\n",
        "    X, labels = next(iter(testloader))\n",
        "    if use_bounds:\n",
        "        # Option 1: for each example, we return its element-wise lower and upper bounds.\n",
        "        # If you use this option, set --spec_type (\"specifications\"->\"type\" in config) to 'bound'.\n",
        "        absolute_max = torch.reshape((1. - mean) / std, (1, -1, 1, 1))\n",
        "        absolute_min = torch.reshape((0. - mean) / std, (1, -1, 1, 1))\n",
        "        # Be careful with normalization.\n",
        "        new_eps = torch.reshape(eps / std, (1, -1, 1, 1))\n",
        "        data_max = torch.min(X + new_eps, absolute_max)\n",
        "        data_min = torch.max(X - new_eps, absolute_min)\n",
        "        # In this case, the epsilon does not matter here.\n",
        "        ret_eps = None\n",
        "    else:\n",
        "        # Option 2: return a single epsilon for all data examples, as well as clipping lower and upper bounds.\n",
        "        # Set data_max and data_min to be None if no clip. For CIFAR-10 we clip to [0,1].\n",
        "        data_max = torch.reshape((1. - mean) / std, (1, -1, 1, 1))\n",
        "        data_min = torch.reshape((0. - mean) / std, (1, -1, 1, 1))\n",
        "        if eps is None:\n",
        "            raise ValueError('You must specify an epsilon')\n",
        "        # Rescale epsilon.\n",
        "        ret_eps = torch.reshape(eps / std, (1, -1, 1, 1))\n",
        "    return X, labels, data_max, data_min, ret_eps"
      ],
      "metadata": {
        "id": "VoHaCyxm9XL-",
        "outputId": "40dce608-cc26-4f61-b263-8a613c8ac655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting custom_model_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using the configuration for the custom model and data\n"
      ],
      "metadata": {
        "id": "BqJ1lKnT-aJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile exp_configs/tutorial_cifar_example.yaml\n",
        "general:\n",
        "  mode: verified-acc\n",
        "model:\n",
        "  # Use the simple_conv_model() model in \"your_model_data.py\".\n",
        "  name: Customized(\"custom_model_data\", \"simple_conv_model\", in_channel=3, out_dim=10)\n",
        "  path: models/eran/cifar_conv_small_pgd.pth\n",
        "data:\n",
        "  # Use the cifar10_dataloader()  in \"custom_model_data.py\".\n",
        "  dataset: Customized(\"custom_model_data\", \"cifar10_dataloader\")\n",
        "  mean: [0.4914, 0.4822, 0.4465]\n",
        "  std: [0.2023, 0.1994, 0.201]\n",
        "specification:\n",
        "  epsilon: 0.00784313725  # 2./255.\n",
        "attack:\n",
        "  pgd_restarts: 100\n",
        "solver:\n",
        "  beta-crown:\n",
        "    batch_size: 2048\n",
        "    iteration: 20\n",
        "bab:\n",
        "  max_domains: 5000000\n",
        "  timeout: 300"
      ],
      "metadata": {
        "id": "YX8HNd2k-Ybv",
        "outputId": "48ec06ca-d50a-450f-b567-c6087ac61c0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing exp_configs/tutorial_cifar_example.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checking robustness on custom data and model\n"
      ],
      "metadata": {
        "id": "1cIoiuiyBa5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate alpha-beta-crown\n",
        "python robustness_verifier.py --config exp_configs/tutorial_cifar_example.yaml --start 3 --end 4\n",
        "conda deactivate"
      ],
      "metadata": {
        "id": "_ft54GlDBjDb",
        "outputId": "e1c42957-7ff1-42e0-dadc-9630a9faba51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations:\n",
            "\n",
            "general:\n",
            "  device: cuda\n",
            "  seed: 100\n",
            "  conv_mode: patches\n",
            "  deterministic: false\n",
            "  double_fp: false\n",
            "  loss_reduction_func: sum\n",
            "  record_bounds: false\n",
            "  mode: verified-acc\n",
            "  complete_verifier: bab\n",
            "  enable_incomplete_verification: true\n",
            "  get_crown_verified_acc: false\n",
            "model:\n",
            "  path: models/eran/cifar_conv_small_pgd.pth\n",
            "  name: 'Customized(\"custom_model_data\", \"simple_conv_model\", in_channel=3, out_dim=10)'\n",
            "data:\n",
            "  start: 3\n",
            "  end: 4\n",
            "  num_outputs: 10\n",
            "  mean: [0.4914, 0.4822, 0.4465]\n",
            "  std: [0.2023, 0.1994, 0.201]\n",
            "  pkl_path: null\n",
            "  dataset: 'Customized(\"custom_model_data\", \"cifar10_dataloader\")'\n",
            "  data_filter_path: null\n",
            "  data_idx_file: null\n",
            "specification:\n",
            "  type: lp\n",
            "  norm: .inf\n",
            "  epsilon: 0.00784313725\n",
            "solver:\n",
            "  alpha-crown:\n",
            "    lr_alpha: 0.1\n",
            "    iteration: 100\n",
            "    share_slopes: false\n",
            "    no_joint_opt: false\n",
            "  beta-crown:\n",
            "    batch_size: 2048\n",
            "    lr_alpha: 0.01\n",
            "    lr_beta: 0.05\n",
            "    lr_decay: 0.98\n",
            "    optimizer: adam\n",
            "    iteration: 20\n",
            "    beta: true\n",
            "    beta_warmup: true\n",
            "  mip:\n",
            "    parallel_solvers: null\n",
            "    solver_threads: 1\n",
            "    refine_neuron_timeout: 15\n",
            "    refine_neuron_time_percentage: 0.8\n",
            "    early_stop: true\n",
            "bab:\n",
            "  max_domains: 5000000\n",
            "  decision_thresh: 0\n",
            "  timeout: 300\n",
            "  get_upper_bound: false\n",
            "  dfs_percent: 0.0\n",
            "  branching:\n",
            "    method: kfsb\n",
            "    candidates: 3\n",
            "    reduceop: min\n",
            "attack:\n",
            "  pgd_order: before\n",
            "  enable_mip_attack: false\n",
            "  pgd_steps: 100\n",
            "  pgd_restarts: 100\n",
            "  pgd_early_stop: true\n",
            "  pgd_lr_decay: 0.99\n",
            "  pgd_alpha: auto\n",
            "debug:\n",
            "  lp_test: null\n",
            "\n",
            "Experiments at Wed Jun 15 10:22:25 2022 on 767c55996023\n",
            "Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
            "  (3): ReLU()\n",
            "  (4): Flatten(start_dim=1, end_dim=-1)\n",
            "  (5): Linear(in_features=1152, out_features=100, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/alpha-beta-CROWN/complete_verifier/datasets/cifar-10-python.tar.gz\n",
            "Extracting /content/alpha-beta-CROWN/complete_verifier/datasets/cifar-10-python.tar.gz to /content/alpha-beta-CROWN/complete_verifier/datasets\n",
            "epsilon after preprocessing: tensor([[[[0.0388]],\n",
            "\n",
            "         [[0.0393]],\n",
            "\n",
            "         [[0.0390]]]]), data_max = tensor([[[[2.5141]],\n",
            "\n",
            "         [[2.5968]],\n",
            "\n",
            "         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],\n",
            "\n",
            "         [[-2.4183]],\n",
            "\n",
            "         [[-2.2214]]]])\n",
            "Task length: 1\n",
            "saving results to Verified_ret_[Customized(\"custom_model_data\", \"simple_conv_model\", in_channel=3, out_dim=10)]_start=3_end=4_iter=20_b=2048_timeout=300_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/170498071 [00:00<?, ?it/s]\r  0%|          | 1024/170498071 [00:00<7:47:08, 6082.93it/s]\r  0%|          | 33792/170498071 [00:00<24:36, 115454.94it/s]\r  0%|          | 82944/170498071 [00:00<14:40, 193449.96it/s]\r  0%|          | 214016/170498071 [00:00<06:47, 418185.15it/s]\r  0%|          | 443392/170498071 [00:00<03:47, 748079.77it/s]\r  1%|          | 902144/170498071 [00:01<02:01, 1399509.85it/s]\r  1%|          | 1819648/170498071 [00:01<01:02, 2684157.95it/s]\r  2%|▏         | 3671040/170498071 [00:01<00:31, 5250536.38it/s]\r  4%|▍         | 6571008/170498071 [00:01<00:18, 8849879.22it/s]\r  5%|▌         | 9208832/170498071 [00:01<00:14, 10841992.49it/s]\r  7%|▋         | 11944960/170498071 [00:01<00:12, 12386600.64it/s]\r  9%|▊         | 14631936/170498071 [00:02<00:11, 13361744.34it/s]\r 10%|█         | 17466368/170498071 [00:02<00:10, 14300006.34it/s]\r 12%|█▏        | 20153344/170498071 [00:02<00:10, 14688752.65it/s]\r 13%|█▎        | 22987776/170498071 [00:02<00:09, 15219104.90it/s]\r 15%|█▍        | 25396224/170498071 [00:02<00:09, 14848225.80it/s]\r 17%|█▋        | 28492800/170498071 [00:02<00:09, 15763109.77it/s]\r 18%|█▊        | 31163392/170498071 [00:03<00:08, 15701898.99it/s]\r 20%|█▉        | 34063360/170498071 [00:03<00:08, 16037379.22it/s]\r 22%|██▏       | 36865024/170498071 [00:03<00:08, 16102262.32it/s]\r 23%|██▎       | 39601152/170498071 [00:03<00:08, 16033385.14it/s]\r 25%|██▌       | 42681344/170498071 [00:03<00:07, 16588683.94it/s]\r 27%|██▋       | 45827072/170498071 [00:03<00:07, 17057583.67it/s]\r 28%|██▊       | 48071680/170498071 [00:04<00:07, 15872276.65it/s]\r 30%|██▉       | 51119104/170498071 [00:04<00:07, 16422066.74it/s]\r 32%|███▏      | 53986304/170498071 [00:04<00:07, 16485177.47it/s]\r 33%|███▎      | 57000960/170498071 [00:04<00:06, 16787821.11it/s]\r 35%|███▌      | 60015616/170498071 [00:04<00:06, 16868376.77it/s]\r 37%|███▋      | 62997504/170498071 [00:04<00:06, 17030373.33it/s]\r 39%|███▊      | 65733632/170498071 [00:05<00:06, 16692551.11it/s]\r 40%|████      | 68699136/170498071 [00:05<00:06, 16849843.16it/s]\r 42%|████▏     | 71468032/170498071 [00:05<00:05, 16591141.02it/s]\r 44%|████▎     | 74318848/170498071 [00:05<00:05, 16580682.86it/s]\r 45%|████▌     | 77431808/170498071 [00:05<00:05, 17029067.29it/s]\r 47%|████▋     | 80397312/170498071 [00:06<00:05, 17084119.56it/s]\r 49%|████▉     | 83248128/170498071 [00:06<00:05, 16901059.35it/s]\r 51%|█████     | 86246400/170498071 [00:06<00:04, 17048835.40it/s]\r 52%|█████▏    | 89179136/170498071 [00:06<00:04, 17040301.22it/s]\r 54%|█████▍    | 92292096/170498071 [00:06<00:04, 17354296.31it/s]\r 56%|█████▌    | 95028224/170498071 [00:06<00:04, 16909893.79it/s]\r 58%|█████▊    | 98092032/170498071 [00:07<00:04, 17169896.17it/s]\r 59%|█████▉    | 101090304/170498071 [00:07<00:04, 17244335.51it/s]\r 61%|██████    | 104154112/170498071 [00:07<00:03, 17405758.74it/s]\r 63%|██████▎   | 107283456/170498071 [00:07<00:03, 17635846.43it/s]\r 65%|██████▍   | 110068736/170498071 [00:07<00:03, 17128545.07it/s]\r 66%|██████▋   | 113148928/170498071 [00:07<00:03, 17352844.91it/s]\r 68%|██████▊   | 116147200/170498071 [00:08<00:03, 17368099.06it/s]\r 70%|██████▉   | 119178240/170498071 [00:08<00:02, 17438944.74it/s]\r 71%|███████▏  | 121799680/170498071 [00:08<00:02, 16772521.40it/s]\r 73%|███████▎  | 124650496/170498071 [00:08<00:02, 16705100.26it/s]\r 75%|███████▍  | 127632384/170498071 [00:08<00:02, 16870755.90it/s]\r 77%|███████▋  | 130630656/170498071 [00:08<00:02, 17029692.55it/s]\r 78%|███████▊  | 133514240/170498071 [00:09<00:02, 16938779.03it/s]\r 80%|████████  | 136545280/170498071 [00:09<00:01, 17138543.02it/s]\r 82%|████████▏ | 139658240/170498071 [00:09<00:01, 17418248.25it/s]\r 84%|████████▎ | 142705664/170498071 [00:09<00:01, 17496415.32it/s]\r 85%|████████▌ | 145654784/170498071 [00:09<00:01, 17378598.59it/s]\r 87%|████████▋ | 148571136/170498071 [00:09<00:01, 17242648.18it/s]\r 89%|████████▉ | 151438336/170498071 [00:10<00:01, 17032121.67it/s]\r 91%|█████████ | 154485760/170498071 [00:10<00:00, 17230847.95it/s]\r 92%|█████████▏| 157500416/170498071 [00:10<00:00, 17308751.13it/s]\r 94%|█████████▍| 160596992/170498071 [00:10<00:00, 17509406.82it/s]\r 96%|█████████▌| 163628032/170498071 [00:10<00:00, 17533439.03it/s]\r 98%|█████████▊| 166675456/170498071 [00:11<00:00, 17577535.43it/s]\r 99%|█████████▉| 169444352/170498071 [00:11<00:00, 17112657.23it/s]\r170499072it [00:11, 15193853.83it/s]                               \n",
            "/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Traceback (most recent call last):\n",
            "  File \"robustness_verifier.py\", line 599, in <module>\n",
            "    main()\n",
            "  File \"robustness_verifier.py\", line 238, in main\n",
            "    model_ori, all_data_max, all_data_min = model_ori.to(arguments.Config[\"general\"][\"device\"]), data_max.to(arguments.Config[\"general\"][\"device\"]), data_min.to(arguments.Config[\"general\"][\"device\"])\n",
            "  File \"/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 673, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 387, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 409, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 671, in convert\n",
            "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
            "  File \"/usr/local/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 170, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: No CUDA GPUs are available\n"
          ]
        }
      ]
    }
  ]
}